{
  "endpoint_name": "nasa-dataset-selector-02-1",
  "description": "Your Toolkit for Text Generation.",
  "id": "e5a6ccad-1aa6-458b-abcc-ed9b9809b5ff",
  "name": "Dataset Retrieval - v1.0.3",
  "data": {
    "nodes": [
      {
        "id": "ChatInput-5ouAc",
        "type": "genericNode",
        "position": {
          "x": 457.9076021166384,
          "y": -1034.53501376734
        },
        "data": {
          "id": "ChatInput-5ouAc",
          "node": {
            "template": {
              "_type": "Component",
              "files": {
                "trace_as_metadata": true,
                "file_path": "",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "files",
                "value": "",
                "display_name": "Files",
                "advanced": true,
                "dynamic": false,
                "info": "Files to be sent with the message.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput"
              },
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_USER, MESSAGE_SENDER_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        _background_color = self.background_color\n        _text_color = self.text_color\n        _icon = self.chat_icon\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\"background_color\": _background_color, \"text_color\": _text_color, \"icon\": _icon},\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "all bad, MIP is wrong should be tasmax ",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "User",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Get chat inputs from the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Dataset Description",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "ChatInput",
          "description": "Get chat inputs from the Playground.",
          "display_name": "Dataset Description"
        },
        "selected": false,
        "width": 320,
        "height": 231,
        "positionAbsolute": {
          "x": 457.9076021166384,
          "y": -1034.53501376734
        },
        "dragging": false
      },
      {
        "id": "CMIP6DatasetProcessorComponent-hmgKP",
        "type": "genericNode",
        "position": {
          "x": 2135.035516520518,
          "y": -2745.459932836808
        },
        "data": {
          "type": "CMIP6DatasetProcessorComponent",
          "node": {
            "template": {
              "_type": "Component",
              "csv_file": {
                "trace_as_metadata": true,
                "file_path": "6bf38571-d37c-4854-a333-df15dc3504c9/2024-11-30_00-03-50_model_experiment_fields_ScenarioMIP_CMIP_filename_dates (1).csv",
                "fileTypes": [
                  "csv"
                ],
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "csv_file",
                "value": "",
                "display_name": "CSV File",
                "advanced": false,
                "dynamic": false,
                "info": "Upload the CSV file containing CMIP6 dataset information.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput",
                "load_from_db": false
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import pandas as pd\r\nimport numpy as np\r\nfrom pathlib import Path\r\nfrom langflow.custom import Component\r\nfrom langflow.io import FileInput, MessageTextInput, Output\r\nfrom langflow.schema.data import Data\r\n\r\nclass CMIP6DatasetProcessorComponent(Component):\r\n    display_name = \"CMIP6 Dataset Processor\"\r\n    description = \"Process a CSV file containing CMIP6 dataset information into a usable DataFrame.\"\r\n    icon = \"table\"\r\n    \r\n    inputs = [\r\n        FileInput(\r\n            name=\"csv_file\",\r\n            display_name=\"CSV File\",\r\n            file_types=[\"csv\"],\r\n            info=\"Upload the CSV file containing CMIP6 dataset information.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"csv_path\",\r\n            display_name=\"CSV File Path\",\r\n            info=\"Provide the path to the CSV file as pure text\",\r\n        ),\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(display_name=\"Processed DataFrame\", name=\"processed_df\", method=\"process_csv\"),\r\n        Output(display_name=\"Unique MIPs\", name=\"unique_mips\", method=\"get_unique_mips\"),\r\n        Output(display_name=\"Unique Experiments\", name=\"unique_experiments\", method=\"get_unique_experiments\"),\r\n    ]\r\n\r\n    def _process_dataframe(self):\r\n        \"\"\"Helper method to process the dataframe and cache it for multiple outputs\"\"\"\r\n        if not hasattr(self, '_cached_df'):\r\n            if sum(bool(field) for field in [self.csv_file, self.csv_path]) != 1:\r\n                raise ValueError(\"Please provide exactly one of: CSV file or file path.\")\r\n            \r\n            try:\r\n                # Read the CSV file based on input type\r\n                if self.csv_file:\r\n                    df = pd.read_csv(self.csv_file)\r\n                else:\r\n                    if not Path(self.csv_path).exists():\r\n                        raise FileNotFoundError(f\"File not found: {self.csv_path}\")\r\n                    df = pd.read_csv(self.csv_path)\r\n                \r\n                # Process the DataFrame as before\r\n                df['collection'] = 'giss_cmip6'\r\n                df['org'] = 'NASA-GISS'\r\n                \r\n                # Select and rename columns\r\n                df = df[['collection', 'MIP', 'org', 'model', 'experiment', 'variant', \r\n                         'tableID', 'variable', 'grid', 'version', 'start_YM', 'end_YM', 'filename']]\r\n                df.columns = ['collection', 'MIP', 'org', 'model', 'experiment', 'variant', \r\n                             'temporal resolution', 'variable', 'grid', 'version', 'start year', 'end year', 'filename']\r\n                \r\n                # Rest of the processing...\r\n                df = df.astype(str)\r\n                \r\n                def generate_url(x):\r\n                    cols = '/'.join([val for val in x])\r\n                    return 'https://portal.nccs.nasa.gov/datashare/' + cols\r\n                \r\n                url_col_names = df.columns[:-3].to_list() + ['filename']\r\n                urldf = df[url_col_names]\r\n                df['URL'] = urldf.apply(lambda x: generate_url(x), axis=1)\r\n                \r\n                def safe_year_convert(x):\r\n                    try:\r\n                        return int(x[:4])\r\n                    except ValueError:\r\n                        return np.nan\r\n                \r\n                df['start year'] = df['start year'].apply(safe_year_convert)\r\n                df['end year'] = df['end year'].apply(safe_year_convert)\r\n                \r\n                df = df.sort_values(df.columns.to_list(), ascending=True).drop_duplicates(\r\n                    subset=set(df.columns.to_list()) - set(['version', 'filename', 'URL']),\r\n                    ignore_index=True, keep='last')\r\n                \r\n                def clean_resolution(reso):\r\n                    resos = ['hr', 'day', 'mon']\r\n                    for q in resos:\r\n                        if q in reso:\r\n                            return q\r\n                    return 'NA'\r\n                \r\n                df['temporal resolution'] = df.apply(lambda x: clean_resolution(x['temporal resolution']), axis=1)\r\n                \r\n                self._cached_df = df\r\n                \r\n            except Exception as e:\r\n                raise ValueError(f\"Error processing CSV: {str(e)}\")\r\n        \r\n        return self._cached_df\r\n\r\n    def process_csv(self) -> Data:\r\n        try:\r\n            df = self._process_dataframe()\r\n            self.status = f\"DataFrame processed successfully. Shape: {df.shape}\"\r\n            return Data(data={\"df\": df})\r\n        except Exception as e:\r\n            error_message = f\"Error processing CSV: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})\r\n\r\n    def get_unique_mips(self) -> list[Data]:\r\n        \"\"\"Return a list of Data objects containing unique MIP values\"\"\"\r\n        try:\r\n            df = self._process_dataframe()\r\n            unique_mips = df['MIP'].unique().tolist()\r\n            return [Data(data={\"MIP\": mip}) for mip in sorted(unique_mips)]\r\n        except Exception as e:\r\n            error_message = f\"Error getting unique MIPs: {str(e)}\"\r\n            self.status = error_message\r\n            return [Data(data={\"error\": error_message})]\r\n\r\n    def get_unique_experiments(self) -> list[Data]:\r\n        \"\"\"Return a list of Data objects containing unique experiment values\"\"\"\r\n        try:\r\n            df = self._process_dataframe()\r\n            unique_experiments = df['experiment'].unique().tolist()\r\n            return [Data(data={\"experiment\": exp}) for exp in sorted(unique_experiments)]\r\n        except Exception as e:\r\n            error_message = f\"Error getting unique experiments: {str(e)}\"\r\n            self.status = error_message\r\n            return [Data(data={\"error\": error_message})]",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "csv_path": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "csv_path",
                "value": "",
                "display_name": "CSV File Path",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Provide the path to the CSV file as pure text",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Process a CSV file containing CMIP6 dataset information into a usable DataFrame.",
            "icon": "table",
            "base_classes": [
              "Data"
            ],
            "display_name": "CMIP6 Dataset Processor",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": true,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "processed_df",
                "display_name": "Processed DataFrame",
                "method": "process_csv",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "unique_mips",
                "display_name": "Unique MIPs",
                "method": "get_unique_mips",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "unique_experiments",
                "display_name": "Unique Experiments",
                "method": "get_unique_experiments",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "csv_file",
              "csv_path"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.1.1"
          },
          "id": "CMIP6DatasetProcessorComponent-hmgKP"
        },
        "selected": false,
        "width": 320,
        "height": 432,
        "dragging": false,
        "positionAbsolute": {
          "x": 2135.035516520518,
          "y": -2745.459932836808
        }
      },
      {
        "id": "CMIP6VariableProcessorFromZip-rKSeA",
        "type": "genericNode",
        "position": {
          "x": 3249.743385806226,
          "y": -2877.5011036218298
        },
        "data": {
          "type": "CMIP6VariableProcessorFromZip",
          "node": {
            "template": {
              "_type": "Component",
              "dataset_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dataset_info",
                "value": "",
                "display_name": "Dataset Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Processed CMIP6 dataset information for filtering variables.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "embeddings": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embeddings",
                "value": "",
                "display_name": "Embeddings",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "Embeddings component for generating embeddings.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "zip_file": {
                "trace_as_metadata": true,
                "file_path": "6bf38571-d37c-4854-a333-df15dc3504c9/2024-11-30_00-03-54_cmip6-cmor-tables-main (1).zip",
                "fileTypes": [
                  "zip"
                ],
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "zip_file",
                "value": "",
                "display_name": "Zip File",
                "advanced": false,
                "dynamic": false,
                "info": "Upload a zip file containing CMIP6 JSON files.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput",
                "load_from_db": false
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import zipfile\r\nimport json\r\nimport pandas as pd\r\nimport numpy as np\r\nfrom pathlib import Path\r\nfrom langflow.custom import Component\r\nfrom langflow.io import FileInput, HandleInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass CMIP6VariableProcessorFromZip(Component):\r\n    display_name = \"CMIP6 Variable Processor (Zip)\"\r\n    description = \"Processes CMIP6 variable information JSON files from a zip file and generates embeddings.\"\r\n    icon = \"file-zip\"\r\n    \r\n    inputs = [\r\n        FileInput(\r\n            name=\"zip_file\",\r\n            display_name=\"Zip File\",\r\n            file_types=[\"zip\"],\r\n            info=\"Upload a zip file containing CMIP6 JSON files.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"zip_path\",\r\n            display_name=\"Zip File Path\",\r\n            info=\"Provide the path to the zip file as pure text\",\r\n        ),\r\n        HandleInput(\r\n            name=\"dataset_info\",\r\n            display_name=\"Dataset Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Processed CMIP6 dataset information for filtering variables.\",\r\n        ),\r\n        HandleInput(\r\n            name=\"embeddings\",\r\n            display_name=\"Embeddings\",\r\n            input_types=[\"Embeddings\"],\r\n            info=\"Embeddings component for generating embeddings.\",\r\n        ),\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(display_name=\"CMIP6 Variable Info\", name=\"variable_info\", method=\"process_zip_file\"),\r\n    ]\r\n\r\n    def process_zip_file(self) -> Data:\r\n        # Validate inputs\r\n        if sum(bool(field) for field in [self.zip_file, self.zip_path]) != 1:\r\n            raise ValueError(\"Please provide exactly one of: zip file or file path.\")\r\n\r\n        try:\r\n            # Get the correct file path\r\n            if self.zip_file:\r\n                file_path = self.resolve_path(self.zip_file)\r\n            else:\r\n                file_path = self.zip_path\r\n                if not Path(file_path).exists():\r\n                    raise FileNotFoundError(f\"File not found: {file_path}\")\r\n\r\n            # Process the zip file\r\n            jdfs = []\r\n            with zipfile.ZipFile(file_path, 'r') as zip_ref:\r\n                for file_name in zip_ref.namelist():\r\n                    if file_name.endswith('.json') and 'Tables' in file_name:\r\n                        self.log(f\"Processing file: {file_name}\")\r\n                        with zip_ref.open(file_name) as file:\r\n                            content = file.read()\r\n                            d = json.loads(content.decode('utf-8'))\r\n                            try:\r\n                                jdf = pd.DataFrame.from_dict(d['variable_entry'], orient='index')\r\n                                jdf['temporal resolution'] = file_name.split('_')[-1].split('.')[0]\r\n                                jdfs.append(jdf)\r\n                            except KeyError:\r\n                                self.log(f\"Skipping {file_name} due to formatting issue\")\r\n\r\n            if not jdfs:\r\n                raise ValueError(\"No valid JSON files were found in the zip file\")\r\n\r\n            # Create the combined DataFrame\r\n            varsdf = pd.concat(jdfs)\r\n            varsdf.rename(columns={'out_name': 'variable'}, inplace=True)\r\n            varsdf = varsdf.loc[:, ['long_name', 'comment', 'variable']]\r\n            varsdf.drop_duplicates(inplace=True)\r\n            \r\n            # Create extended comment\r\n            varsdf['extended_comment'] = varsdf.apply(\r\n                lambda x: f\"{x['long_name']} ({x['variable']}): {x['comment']}\", \r\n                axis=1\r\n            )\r\n            \r\n            # Filter variables based on the dataset_info\r\n            if isinstance(self.dataset_info, Data) and 'df' in self.dataset_info.data:\r\n                df = pd.DataFrame(self.dataset_info.data['df'])\r\n                varsdf = varsdf[varsdf['variable'].isin(df['variable'].unique())]\r\n            else:\r\n                self.log(\"Warning: No dataset info provided for filtering variables.\")\r\n\r\n            # Generate embeddings\r\n            varsdf.loc[varsdf['extended_comment'].isna(), 'extended_comment'] = ''\r\n            varsdf['embeds'] = list(np.asarray(\r\n                self.embeddings.embed_documents(varsdf['extended_comment'].tolist())\r\n            ))\r\n\r\n            self.status = f\"Variable info processed and embeddings generated successfully. Shape: {varsdf.shape}\"\r\n            return Data(data={\"variable_info\": varsdf})\r\n\r\n        except Exception as e:\r\n            error_message = f\"Error processing zip file or generating embeddings: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "zip_path": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "zip_path",
                "value": "",
                "display_name": "Zip File Path",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Provide the path to the zip file as pure text",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Processes CMIP6 variable information JSON files from a zip file and generates embeddings.",
            "icon": "file-zip",
            "base_classes": [
              "Data"
            ],
            "display_name": "CMIP6 Variable Processor (Zip)",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": true,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "variable_info",
                "display_name": "CMIP6 Variable Info",
                "method": "process_zip_file",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "zip_file",
              "zip_path",
              "dataset_info",
              "embeddings"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.1.1"
          },
          "id": "CMIP6VariableProcessorFromZip-rKSeA"
        },
        "selected": false,
        "width": 320,
        "height": 366,
        "positionAbsolute": {
          "x": 3249.743385806226,
          "y": -2877.5011036218298
        },
        "dragging": false
      },
      {
        "id": "variable_matcher-GzLTK",
        "type": "genericNode",
        "position": {
          "x": 5643.319471179704,
          "y": -1459.7994934350872
        },
        "data": {
          "type": "variable_matcher",
          "node": {
            "template": {
              "_type": "Component",
              "variable_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "variable_info",
                "value": "",
                "display_name": "Variable Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Processed CMIP6 variable information from the previous component.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import List, Dict, Any\r\nfrom pydantic import BaseModel, Field\r\nimport pandas as pd\r\n\r\nfrom langflow.base.langchain_utilities.model import LCToolComponent\r\nfrom langflow.io import HandleInput, MessageTextInput, IntInput, Output\r\nfrom langflow.schema import Data\r\nfrom langflow.field_typing import Tool\r\nfrom langchain.tools import StructuredTool\r\n\r\nclass VariableMatcherToolComponent(LCToolComponent):\r\n    display_name = \"CMIP6 Variable Matcher\"\r\n    description = \"Filters CMIP6 variables based on exact variable name matches.\"\r\n    icon = \"match\"\r\n    name = \"variable_matcher\"\r\n    \r\n    inputs = [\r\n        HandleInput(\r\n            name=\"variable_info\",\r\n            display_name=\"Variable Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Processed CMIP6 variable information from the previous component.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"variable_name\",\r\n            display_name=\"Variable Name\",\r\n            info=\"The exact variable name to filter for (e.g., 'tas').\",\r\n        ),\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(display_name=\"Matched Variables\", name=\"matched_variables\", method=\"match_variables\"),\r\n        Output(display_name=\"Tool\", name=\"tool\", method=\"build_tool\"),\r\n    ]\r\n\r\n    class VariableMatcherSchema(BaseModel):\r\n        variable_name: str = Field(\r\n            ..., \r\n            description=\"The exact variable name to filter for (e.g., 'tas')\"\r\n        )\r\n\r\n    def _process_matches(self, variable_name: str) -> List[Dict[str, Any]]:\r\n        \"\"\"Internal method to filter variables by exact name match\"\"\"\r\n        if not isinstance(self.variable_info, Data) or 'variable_info' not in self.variable_info.data:\r\n            raise ValueError(\"Invalid variable info input. Expected Data object with 'variable_info' key.\")\r\n        \r\n        varsdf = self.variable_info.data['variable_info']\r\n        \r\n        try:\r\n            # Filter for exact matches\r\n            filtered_df = varsdf[varsdf['variable'].str.lower() == variable_name.lower()]\r\n            \r\n            if filtered_df.empty:\r\n                return [{\"message\": f\"No matches found for variable '{variable_name}'\"}]\r\n            \r\n            # Convert results to list of dictionaries\r\n            results = [\r\n                {\r\n                    'variable': row['variable'],\r\n                    'long_name': row['long_name'],\r\n                    'comment': row['comment'],\r\n                }\r\n                for _, row in filtered_df.iterrows()\r\n            ]\r\n            \r\n            return results\r\n\r\n        except Exception as e:\r\n            return [{\"error\": f\"Error filtering variables: {str(e)}\"}]\r\n\r\n    def match_variables(self) -> List[Data]:\r\n        \"\"\"Method for component output\"\"\"\r\n        try:\r\n            results = self._process_matches(self.variable_name)\r\n            data_list = [Data(data=result) for result in results]\r\n            self.status = data_list\r\n            return data_list\r\n            \r\n        except Exception as e:\r\n            error_message = f\"Error matching variables: {str(e)}\"\r\n            self.status = error_message\r\n            return [Data(data={\"error\": error_message})]\r\n\r\n    def build_tool(self) -> Tool:\r\n        \"\"\"Build and return the tool\"\"\"\r\n        return StructuredTool.from_function(\r\n            name=\"variable_matcher\",\r\n            description=\"Filter CMIP6 variables by exact variable name match. \"\r\n                      \"Input should be the exact variable name (e.g., 'tas').\",\r\n            func=self._tool_function,\r\n            args_schema=self.VariableMatcherSchema,\r\n        )\r\n\r\n    def _tool_function(self, variable_name: str) -> List[Dict[str, Any]]:\r\n        \"\"\"Function to be called by the tool\"\"\"\r\n        try:\r\n            return self._process_matches(variable_name)\r\n        except Exception as e:\r\n            return [{\"error\": f\"Error matching variables: {str(e)}\"}]",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "variable_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "variable_name",
                "value": "",
                "display_name": "Variable Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The exact variable name to filter for (e.g., 'tas').",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Filters CMIP6 variables based on exact variable name matches.",
            "icon": "match",
            "base_classes": [
              "Data",
              "Tool"
            ],
            "display_name": "CMIP6 Variable Matcher",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "matched_variables",
                "display_name": "Matched Variables",
                "method": "match_variables",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              }
            ],
            "field_order": [
              "variable_info",
              "variable_name"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.1.1"
          },
          "id": "variable_matcher-GzLTK"
        },
        "selected": false,
        "width": 320,
        "height": 300,
        "dragging": false,
        "positionAbsolute": {
          "x": 5643.319471179704,
          "y": -1459.7994934350872
        }
      },
      {
        "id": "OpenAIEmbeddings-sXTEV",
        "type": "genericNode",
        "position": {
          "x": 2888.1600442024533,
          "y": -2819.285701514933
        },
        "data": {
          "type": "OpenAIEmbeddings",
          "node": {
            "template": {
              "_type": "Component",
              "chunk_size": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_size",
                "value": 1000,
                "display_name": "Chunk Size",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "client": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "client",
                "value": "",
                "display_name": "Client",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_openai import OpenAIEmbeddings\n\nfrom langflow.base.embeddings.model import LCEmbeddingsModel\nfrom langflow.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass OpenAIEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIEmbeddings\"\n\n    inputs = [\n        DictInput(\n            name=\"default_headers\",\n            display_name=\"Default Headers\",\n            advanced=True,\n            info=\"Default headers to use for the API request.\",\n        ),\n        DictInput(\n            name=\"default_query\",\n            display_name=\"Default Query\",\n            advanced=True,\n            info=\"Default query parameters to use for the API request.\",\n        ),\n        IntInput(name=\"chunk_size\", display_name=\"Chunk Size\", advanced=True, value=1000),\n        MessageTextInput(name=\"client\", display_name=\"Client\", advanced=True),\n        MessageTextInput(name=\"deployment\", display_name=\"Deployment\", advanced=True),\n        IntInput(name=\"embedding_ctx_length\", display_name=\"Embedding Context Length\", advanced=True, value=1536),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=\"text-embedding-3-small\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\n        MessageTextInput(name=\"openai_api_base\", display_name=\"OpenAI API Base\", advanced=True),\n        MessageTextInput(name=\"openai_api_type\", display_name=\"OpenAI API Type\", advanced=True),\n        MessageTextInput(name=\"openai_api_version\", display_name=\"OpenAI API Version\", advanced=True),\n        MessageTextInput(\n            name=\"openai_organization\",\n            display_name=\"OpenAI Organization\",\n            advanced=True,\n        ),\n        MessageTextInput(name=\"openai_proxy\", display_name=\"OpenAI Proxy\", advanced=True),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n        BoolInput(name=\"show_progress_bar\", display_name=\"Show Progress Bar\", advanced=True),\n        BoolInput(name=\"skip_empty\", display_name=\"Skip Empty\", advanced=True),\n        MessageTextInput(\n            name=\"tiktoken_model_name\",\n            display_name=\"TikToken Model Name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tiktoken_enable\",\n            display_name=\"TikToken Enable\",\n            advanced=True,\n            value=True,\n            info=\"If False, you must have transformers installed.\",\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. \"\n            \"Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return OpenAIEmbeddings(\n            client=self.client or None,\n            model=self.model,\n            dimensions=self.dimensions or None,\n            deployment=self.deployment or None,\n            api_version=self.openai_api_version or None,\n            base_url=self.openai_api_base or None,\n            openai_api_type=self.openai_api_type or None,\n            openai_proxy=self.openai_proxy or None,\n            embedding_ctx_length=self.embedding_ctx_length,\n            api_key=self.openai_api_key or None,\n            organization=self.openai_organization or None,\n            allowed_special=\"all\",\n            disallowed_special=\"all\",\n            chunk_size=self.chunk_size,\n            max_retries=self.max_retries,\n            timeout=self.request_timeout or None,\n            tiktoken_enabled=self.tiktoken_enable,\n            tiktoken_model_name=self.tiktoken_model_name or None,\n            show_progress_bar=self.show_progress_bar,\n            model_kwargs=self.model_kwargs,\n            skip_empty=self.skip_empty,\n            default_headers=self.default_headers or None,\n            default_query=self.default_query or None,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "default_headers": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "default_headers",
                "value": {},
                "display_name": "Default Headers",
                "advanced": true,
                "dynamic": false,
                "info": "Default headers to use for the API request.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "default_query": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "default_query",
                "value": {},
                "display_name": "Default Query",
                "advanced": true,
                "dynamic": false,
                "info": "Default query parameters to use for the API request.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "deployment": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "deployment",
                "value": "",
                "display_name": "Deployment",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "dimensions": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dimensions",
                "value": "",
                "display_name": "Dimensions",
                "advanced": true,
                "dynamic": false,
                "info": "The number of dimensions the resulting output embeddings should have. Only supported by certain models.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "embedding_ctx_length": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embedding_ctx_length",
                "value": 1536,
                "display_name": "Embedding Context Length",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "max_retries": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_retries",
                "value": 3,
                "display_name": "Max Retries",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "text-embedding-3-small",
                  "text-embedding-3-large",
                  "text-embedding-ada-002"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "text-embedding-3-large",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "openai_api_base": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "openai_api_type": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_type",
                "value": "",
                "display_name": "OpenAI API Type",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_api_version": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_version",
                "value": "",
                "display_name": "OpenAI API Version",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_organization": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_organization",
                "value": "",
                "display_name": "OpenAI Organization",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_proxy": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_proxy",
                "value": "",
                "display_name": "OpenAI Proxy",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "request_timeout": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "request_timeout",
                "value": "",
                "display_name": "Request Timeout",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "show_progress_bar": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "show_progress_bar",
                "value": false,
                "display_name": "Show Progress Bar",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "skip_empty": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "skip_empty",
                "value": false,
                "display_name": "Skip Empty",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "tiktoken_enable": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tiktoken_enable",
                "value": true,
                "display_name": "TikToken Enable",
                "advanced": true,
                "dynamic": false,
                "info": "If False, you must have transformers installed.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "tiktoken_model_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tiktoken_model_name",
                "value": "",
                "display_name": "TikToken Model Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Generate embeddings using OpenAI models.",
            "icon": "OpenAI",
            "base_classes": [
              "Embeddings"
            ],
            "display_name": "OpenAI Embeddings",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": true,
            "outputs": [
              {
                "types": [
                  "Embeddings"
                ],
                "selected": "Embeddings",
                "name": "embeddings",
                "display_name": "Embeddings",
                "method": "build_embeddings",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              }
            ],
            "field_order": [
              "default_headers",
              "default_query",
              "chunk_size",
              "client",
              "deployment",
              "embedding_ctx_length",
              "max_retries",
              "model",
              "model_kwargs",
              "openai_api_key",
              "openai_api_base",
              "openai_api_type",
              "openai_api_version",
              "openai_organization",
              "openai_proxy",
              "request_timeout",
              "show_progress_bar",
              "skip_empty",
              "tiktoken_model_name",
              "tiktoken_enable",
              "dimensions"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "id": "OpenAIEmbeddings-sXTEV",
          "description": "Generate embeddings using OpenAI models.",
          "display_name": "OpenAI Embeddings"
        },
        "selected": false,
        "width": 320,
        "height": 317,
        "dragging": false,
        "positionAbsolute": {
          "x": 2888.1600442024533,
          "y": -2819.285701514933
        }
      },
      {
        "id": "TemporalResolutionFilterComponent-MLtJu",
        "type": "genericNode",
        "position": {
          "x": 6114.570741928117,
          "y": -1225.2071671185627
        },
        "data": {
          "type": "TemporalResolutionFilterComponent",
          "node": {
            "template": {
              "_type": "Component",
              "dataset_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dataset_info",
                "value": "",
                "display_name": "Dataset Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Processed CMIP6 dataset information from the CMIP6 Dataset Processor.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "matched_variables": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "matched_variables",
                "value": "",
                "display_name": "Matched Variables",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Matched variables from the CMIP6 Variable Matcher.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\r\nfrom langflow.io import HandleInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass TemporalResolutionFilterComponent(Component):\r\n    display_name = \"Temporal Resolution Filter\"\r\n    description = \"Filters CMIP6 datasets based on temporal resolution and matched variables.\"\r\n    icon = \"filter\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"dataset_info\",\r\n            display_name=\"Dataset Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Processed CMIP6 dataset information from the CMIP6 Dataset Processor.\",\r\n        ),\r\n        HandleInput(\r\n            name=\"matched_variables\",\r\n            display_name=\"Matched Variables\",\r\n            input_types=[\"Data\"],\r\n            info=\"Matched variables from the CMIP6 Variable Matcher.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"resolution\",\r\n            display_name=\"Temporal Resolution\",\r\n            info=\"Enter the desired temporal resolution (e.g., hr, day, mon, fx).\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Filtered Datasets\", name=\"filtered_datasets\", method=\"filter_datasets\"),\r\n    ]\r\n\r\n    def filter_datasets(self) -> Data:\r\n        if not isinstance(self.dataset_info, Data) or 'df' not in self.dataset_info.data:\r\n            raise ValueError(\"Invalid dataset info input. Expected Data object with 'df' key.\")\r\n\r\n        if not isinstance(self.matched_variables, list) or not all(isinstance(x, Data) for x in self.matched_variables):\r\n            raise ValueError(\"Invalid matched variables input. Expected list of Data objects.\")\r\n\r\n        df = self.dataset_info.data['df']\r\n\r\n        if 'temporal resolution' not in df.columns or 'variable' not in df.columns:\r\n            raise ValueError(\"Expected 'temporal resolution' and 'variable' columns in dataset info DataFrame.\")\r\n\r\n        try:\r\n            resolution = self.resolution.strip().lower()\r\n            \r\n            # Get the list of matched variable names\r\n            matched_var_names = [v.data['variable'] for v in self.matched_variables if 'variable' in v.data]\r\n            \r\n            # Filter the dataset\r\n            filtered_df = df[\r\n                (df['temporal resolution'] == resolution) &\r\n                (df['variable'].isin(matched_var_names))\r\n            ]\r\n            \r\n            self.status = f\"Filtered {len(filtered_df)} datasets with {resolution} temporal resolution and matching variables.\"\r\n            return Data(data={\"filtered_df\": filtered_df})\r\n\r\n        except Exception as e:\r\n            error_message = f\"Error filtering datasets: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "resolution": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "resolution",
                "value": "",
                "display_name": "Temporal Resolution",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the desired temporal resolution (e.g., hr, day, mon, fx).",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Filters CMIP6 datasets based on temporal resolution and matched variables.",
            "icon": "filter",
            "base_classes": [
              "Data"
            ],
            "display_name": "Temporal Resolution Filter",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "filtered_datasets",
                "display_name": "Filtered Datasets",
                "method": "filter_datasets",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "dataset_info",
              "matched_variables",
              "resolution"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.1.1"
          },
          "id": "TemporalResolutionFilterComponent-MLtJu"
        },
        "selected": false,
        "width": 320,
        "height": 348,
        "dragging": false,
        "positionAbsolute": {
          "x": 6114.570741928117,
          "y": -1225.2071671185627
        }
      },
      {
        "id": "YearRangeFilterComponent-bEvwF",
        "type": "genericNode",
        "position": {
          "x": 6572.064522169262,
          "y": -1009.1006848302384
        },
        "data": {
          "type": "YearRangeFilterComponent",
          "node": {
            "template": {
              "_type": "Component",
              "dataset_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dataset_info",
                "value": "",
                "display_name": "Dataset Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Processed CMIP6 dataset information from the previous filter.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\r\nfrom langflow.io import HandleInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass YearRangeFilterComponent(Component):\r\n    display_name = \"Year Range Filter\"\r\n    description = \"Filters CMIP6 datasets based on a specified year range.\"\r\n    icon = \"calendar\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"dataset_info\",\r\n            display_name=\"Dataset Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Processed CMIP6 dataset information from the previous filter.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"year_range\",\r\n            display_name=\"Year Range\",\r\n            info=\"The year range for filtering (format: START-END, e.g., '1980-2014' or '1000-NA' or 'NA-2100').\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Filtered Datasets\", name=\"filtered_datasets\", method=\"filter_datasets\"),\r\n    ]\r\n\r\n    def parse_year_range(self, year_range: str):\r\n        start, end = year_range.split('-')\r\n        start = int(start) if start.lower() != 'na' else None\r\n        end = int(end) if end.lower() != 'na' else None\r\n        return start, end\r\n\r\n    def filter_datasets(self) -> Data:\r\n        if not isinstance(self.dataset_info, Data) or 'filtered_df' not in self.dataset_info.data:\r\n            raise ValueError(\"Invalid dataset info input. Expected Data object with 'filtered_df' key.\")\r\n\r\n        df = self.dataset_info.data['filtered_df']\r\n\r\n        if 'start year' not in df.columns or 'end year' not in df.columns:\r\n            raise ValueError(\"Expected 'start year' and 'end year' columns in dataset info DataFrame.\")\r\n\r\n        try:\r\n            start_year, end_year = self.parse_year_range(self.year_range.strip())\r\n            \r\n            if start_year is not None:\r\n                df = df[df['end year'] >= start_year]\r\n            if end_year is not None:\r\n                df = df[df['start year'] <= end_year]\r\n            \r\n            year_range_str = f\"{start_year if start_year else 'NA'}-{end_year if end_year else 'NA'}\"\r\n            self.status = f\"Filtered datasets within the year range {year_range_str}. {len(df)} datasets remain.\"\r\n            return Data(data={\"filtered_df\": df})\r\n\r\n        except ValueError:\r\n            error_message = \"Invalid year range input. Please enter a valid range (e.g., '1980-2014' or '1000-NA' or 'NA-2100').\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})\r\n        except Exception as e:\r\n            error_message = f\"Error filtering datasets: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "year_range": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "year_range",
                "value": "",
                "display_name": "Year Range",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The year range for filtering (format: START-END, e.g., '1980-2014' or '1000-NA' or 'NA-2100').",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Filters CMIP6 datasets based on a specified year range.",
            "icon": "calendar",
            "base_classes": [
              "Data"
            ],
            "display_name": "Year Range Filter",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "filtered_datasets",
                "display_name": "Filtered Datasets",
                "method": "filter_datasets",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "dataset_info",
              "year_range"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.1.1"
          },
          "id": "YearRangeFilterComponent-bEvwF"
        },
        "selected": false,
        "width": 320,
        "height": 300,
        "dragging": false,
        "positionAbsolute": {
          "x": 6572.064522169262,
          "y": -1009.1006848302384
        }
      },
      {
        "id": "URLExtractorComponent-fE6vL",
        "type": "genericNode",
        "position": {
          "x": 6990.787869759375,
          "y": -749.5272132244486
        },
        "data": {
          "type": "URLExtractorComponent",
          "node": {
            "template": {
              "_type": "Component",
              "dataset_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dataset_info",
                "value": "",
                "display_name": "Filtered Dataset Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Filtered CMIP6 dataset information from the previous filters.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\r\nfrom langflow.io import HandleInput, IntInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass URLExtractorComponent(Component):\r\n    display_name = \"URL Extractor\"\r\n    description = \"Extracts URLs from filtered CMIP6 datasets.\"\r\n    icon = \"link\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"dataset_info\",\r\n            display_name=\"Filtered Dataset Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Filtered CMIP6 dataset information from the previous filters.\",\r\n        ),\r\n        IntInput(\r\n            name=\"max_urls\",\r\n            display_name=\"Maximum URLs\",\r\n            info=\"Maximum number of URLs to extract (0 for all).\",\r\n            value=5,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Extracted URLs\", name=\"extracted_urls\", method=\"extract_urls\"),\r\n    ]\r\n\r\n    def extract_urls(self) -> Data:\r\n        if not isinstance(self.dataset_info, Data) or 'filtered_df' not in self.dataset_info.data:\r\n            raise ValueError(\"Invalid dataset info input. Expected Data object with 'filtered_df' key.\")\r\n\r\n        df = self.dataset_info.data['filtered_df']\r\n\r\n        if 'URL' not in df.columns:\r\n            raise ValueError(\"Expected 'URL' column in dataset info DataFrame.\")\r\n\r\n        try:\r\n            if self.max_urls > 0:\r\n                urls = df['URL'].head(self.max_urls).tolist()\r\n            else:\r\n                urls = df['URL'].tolist()\r\n\r\n            result = []\r\n            for i, url in enumerate(urls, 1):\r\n                result.append(Data(data={\r\n                    \"url\": url,\r\n                    \"index\": i,\r\n                    \"filename\": url.split('/')[-1]\r\n                }))\r\n\r\n            self.status = result\r\n            return result\r\n\r\n        except Exception as e:\r\n            error_message = f\"Error extracting URLs: {str(e)}\"\r\n            self.status = error_message\r\n            return [Data(data={\"error\": error_message})]",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "max_urls": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_urls",
                "value": 1,
                "display_name": "Maximum URLs",
                "advanced": false,
                "dynamic": false,
                "info": "Maximum number of URLs to extract (0 for all).",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput",
                "load_from_db": false
              }
            },
            "description": "Extracts URLs from filtered CMIP6 datasets.",
            "icon": "link",
            "base_classes": [
              "Data"
            ],
            "display_name": "URL Extractor",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "extracted_urls",
                "display_name": "Extracted URLs",
                "method": "extract_urls",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "dataset_info",
              "max_urls"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.1.1"
          },
          "id": "URLExtractorComponent-fE6vL"
        },
        "selected": false,
        "width": 320,
        "height": 279,
        "positionAbsolute": {
          "x": 6990.787869759375,
          "y": -749.5272132244486
        },
        "dragging": false
      },
      {
        "id": "Prompt-z9f1V",
        "type": "genericNode",
        "position": {
          "x": 3264.4647752945025,
          "y": -123.01349579960996
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "You are an expert climate scientist. \n\nDoes the following CMIP6 query require or specify a year range for the data required to answer.\n\nQuery: {query}\n\nIf yes, provide the year range in format START-END, for instance 1960-1970 or 2100-3100. If no, respond NA-NA. \n\nIf only the start or end is specified, provide just that year in format START-NA (eg 2100-NA) or NA-END (eg NA-1900).\n\nProvide only the year range in this format and nothing else.\n\nToday is: {current_date}",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput",
                "load_from_db": false
              },
              "query": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "query",
                "display_name": "query",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "current_date": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "current_date",
                "display_name": "current_date",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "base_classes": [
              "Message"
            ],
            "display_name": "Date Range Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "query",
                "current_date"
              ]
            },
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "id": "Prompt-z9f1V",
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Date Range Prompt"
        },
        "selected": false,
        "width": 320,
        "height": 429,
        "dragging": false,
        "positionAbsolute": {
          "x": 3264.4647752945025,
          "y": -123.01349579960996
        }
      },
      {
        "id": "OpenAIModel-mGQfP",
        "type": "genericNode",
        "position": {
          "x": 3619.843933794377,
          "y": -29.190755612016034
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "OPENAI_API_KEY",
                "display_name": "OpenAI API Key",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\nfrom langflow.inputs.inputs import HandleInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. \"\n            \"You must pass the word JSON in the prompt. \"\n            \"If left blank, JSON mode will be disabled. [DEPRECATED]\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o",
                "display_name": "Model Name",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled. [DEPRECATED]",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "RangeSelector",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [],
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "output_parser"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "id": "OpenAIModel-mGQfP",
          "description": "Generates text using OpenAI LLMs.",
          "display_name": "RangeSelector"
        },
        "selected": false,
        "width": 320,
        "height": 232,
        "dragging": false,
        "positionAbsolute": {
          "x": 3619.843933794377,
          "y": -29.190755612016034
        }
      },
      {
        "id": "Prompt-L0LEg",
        "type": "genericNode",
        "position": {
          "x": 3266.07640414577,
          "y": -598.5560148810174
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "You are an expert climate scientist. Is the following CMIP6-related query best answered using data gathered at which of the following resolutions: \n\n- 'hr': hour\n- 'day': day\n- 'mon': month\n- 'NA': not applicable, none of the above, or unclear\n\n\nRespond with only the short term of one following corresponding to your choice and nothing else. \n\nIf a query does not specify any given temporal resolution, like the query \"plot average temperature\", then choose \noption NA\n\n\nQuery: {query}\n",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput",
                "load_from_db": false
              },
              "query": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "query",
                "display_name": "query",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "base_classes": [
              "Message"
            ],
            "display_name": "Temporal Resolution Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "query"
              ]
            },
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "id": "Prompt-L0LEg",
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Temporal Resolution Prompt"
        },
        "selected": false,
        "width": 320,
        "height": 343,
        "positionAbsolute": {
          "x": 3266.07640414577,
          "y": -598.5560148810174
        },
        "dragging": false
      },
      {
        "id": "OpenAIModel-nbPZx",
        "type": "genericNode",
        "position": {
          "x": 3613.7156540479637,
          "y": -566.2205990195372
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "OPENAI_API_KEY",
                "display_name": "OpenAI API Key",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\nfrom langflow.inputs.inputs import HandleInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. \"\n            \"You must pass the word JSON in the prompt. \"\n            \"If left blank, JSON mode will be disabled. [DEPRECATED]\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o-mini",
                "display_name": "Model Name",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled. [DEPRECATED]",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "TemporalSelector",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [],
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "output_parser"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "id": "OpenAIModel-nbPZx",
          "description": "Generates text using OpenAI LLMs.",
          "display_name": "TemporalSelector"
        },
        "selected": false,
        "width": 320,
        "height": 232,
        "dragging": false,
        "positionAbsolute": {
          "x": 3613.7156540479637,
          "y": -566.2205990195372
        }
      },
      {
        "id": "Prompt-sXSLK",
        "type": "genericNode",
        "position": {
          "x": 3262.920008885303,
          "y": -1045.856817683067
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "You are a climate scientist and expert on the CMIP6 dataset. Given a colleague's query, find CMIP6 **variables** most likely to help answer the query. \n\nTo find these variables: \n\n1. summarize the variable-related keywords in the query (e.g. \"rain\", not analysis words like \"plot\") using words that are useful for describing the CMIP 6 datasets. For instance, instead of \"weather month\", say temperature precipitation wind\", because \"month\" is not relevant to the variable choice and temperature precipitation wind\" is more specific than \"weather\". \nIf the query relates to whether a variable surpasses some threshold, you may wish to search for the \"min\" or \"max\" versions of variables.\n\n2. connect your list of summary words into one comma separated string.\n\nAdd as much as relevant, don't be shy\n\nUse the tool to check the variables, and at the end output the actual needed query. \n\nYour output should be only the variable name that you found most accurate for the query. No explanations\n\nQuery: {query}",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput",
                "load_from_db": false
              },
              "query": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "query",
                "display_name": "query",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "base_classes": [
              "Message"
            ],
            "display_name": "DPrompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "query"
              ]
            },
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "id": "Prompt-sXSLK",
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Variables Prompt"
        },
        "selected": false,
        "width": 320,
        "height": 343,
        "positionAbsolute": {
          "x": 3262.920008885303,
          "y": -1045.856817683067
        },
        "dragging": false
      },
      {
        "id": "ParseData-kqy2r",
        "type": "genericNode",
        "position": {
          "x": 7405.218374802683,
          "y": -653.5235787135279
        },
        "data": {
          "type": "ParseData",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{url}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "Parse Data",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "edited": false,
            "metadata": {},
            "lf_version": "1.1.1"
          },
          "id": "ParseData-kqy2r",
          "description": "Convert Data into plain text following a specified template.",
          "display_name": "Parse Data"
        },
        "selected": false,
        "width": 320,
        "height": 299,
        "positionAbsolute": {
          "x": 7405.218374802683,
          "y": -653.5235787135279
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-V9dwj",
        "type": "genericNode",
        "position": {
          "x": 9056.991656519713,
          "y": -491.37815579242806
        },
        "data": {
          "type": "ChatOutput",
          "node": {
            "template": {
              "_type": "Component",
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "🤖",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, _id: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if _id:\n            source_dict[\"id\"] = _id\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    def message_response(self) -> Message:\n        _source, _icon, _display_name, _source_id = self.get_properties_from_source_component()\n        _background_color = self.background_color\n        _text_color = self.text_color\n        if self.chat_icon:\n            _icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(_source_id, _display_name, _source)\n        message.properties.icon = _icon\n        message.properties.background_color = _background_color\n        message.properties.text_color = _text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "Dataset Selector",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Dataset Selector",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "id": "ChatOutput-V9dwj",
          "description": "Display a chat message in the Playground.",
          "display_name": "Dataset Selector"
        },
        "selected": false,
        "width": 320,
        "height": 232,
        "positionAbsolute": {
          "x": 9056.991656519713,
          "y": -491.37815579242806
        },
        "dragging": false
      },
      {
        "id": "GroqModel-EFDIv",
        "type": "genericNode",
        "position": {
          "x": 8689.192804800765,
          "y": -833.9346327053804
        },
        "data": {
          "type": "GroqModel",
          "node": {
            "template": {
              "_type": "Component",
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import requests\nfrom pydantic.v1 import SecretStr\nfrom typing_extensions import override\n\nfrom langflow.base.models.groq_constants import GROQ_MODELS\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass GroqModel(LCModelComponent):\n    display_name: str = \"Groq\"\n    description: str = \"Generate text using Groq.\"\n    icon = \"Groq\"\n    name = \"GroqModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        SecretStrInput(name=\"groq_api_key\", display_name=\"Groq API Key\", info=\"API key for the Groq API.\"),\n        MessageTextInput(\n            name=\"groq_api_base\",\n            display_name=\"Groq API Base\",\n            info=\"Base URL path for API requests, leave blank if not using a proxy or service emulator.\",\n            advanced=True,\n            value=\"https://api.groq.com\",\n        ),\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Output Tokens\",\n            info=\"The maximum number of tokens to generate.\",\n            advanced=True,\n        ),\n        FloatInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            info=\"Run inference with this temperature. Must by in the closed interval [0.0, 1.0].\",\n            value=0.1,\n        ),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. \"\n            \"Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model\",\n            info=\"The name of the model to use.\",\n            options=GROQ_MODELS,\n            value=\"llama-3.1-8b-instant\",\n            refresh_button=True,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def get_models(self) -> list[str]:\n        api_key = self.groq_api_key\n        base_url = self.groq_api_base or \"https://api.groq.com\"\n        url = f\"{base_url}/openai/v1/models\"\n\n        headers = {\"Authorization\": f\"Bearer {api_key}\", \"Content-Type\": \"application/json\"}\n\n        try:\n            response = requests.get(url, headers=headers, timeout=10)\n            response.raise_for_status()\n            model_list = response.json()\n            return [model[\"id\"] for model in model_list.get(\"data\", [])]\n        except requests.RequestException as e:\n            self.status = f\"Error fetching models: {e}\"\n            return GROQ_MODELS\n\n    @override\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None):\n        if field_name in {\"groq_api_key\", \"groq_api_base\", \"model_name\"}:\n            models = self.get_models()\n            build_config[\"model_name\"][\"options\"] = models\n        return build_config\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_groq import ChatGroq\n        except ImportError as e:\n            msg = \"langchain-groq is not installed. Please install it with `pip install langchain-groq`.\"\n            raise ImportError(msg) from e\n\n        groq_api_key = self.groq_api_key\n        model_name = self.model_name\n        max_tokens = self.max_tokens\n        temperature = self.temperature\n        groq_api_base = self.groq_api_base\n        n = self.n\n        stream = self.stream\n\n        return ChatGroq(\n            model=model_name,\n            max_tokens=max_tokens or None,\n            temperature=temperature,\n            base_url=groq_api_base,\n            n=n or 1,\n            api_key=SecretStr(groq_api_key).get_secret_value(),\n            streaming=stream,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "groq_api_base": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "groq_api_base",
                "value": "https://api.groq.com",
                "display_name": "Groq API Base",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Base URL path for API requests, leave blank if not using a proxy or service emulator.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "groq_api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "groq_api_key",
                "value": "GROQ_API_KEY",
                "display_name": "Groq API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "API key for the Groq API.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Output Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "distil-whisper-large-v3-en",
                  "gemma2-9b-it",
                  "gemma-7b-it",
                  "llama3-groq-70b-8192-tool-use-preview",
                  "llama3-groq-8b-8192-tool-use-preview",
                  "llama-3.1-70b-versatile",
                  "llama-3.1-8b-instant",
                  "llama-3.2-1b-preview",
                  "llama-3.2-3b-preview",
                  "llama-3.2-11b-vision-preview",
                  "llama-3.2-90b-vision-preview",
                  "llama-guard-3-8b",
                  "llama3-70b-8192",
                  "llama3-8b-8192",
                  "mixtral-8x7b-32768",
                  "whisper-large-v3",
                  "whisper-large-v3-turbo"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "llama-3.2-3b-preview",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "The name of the model to use.",
                "refresh_button": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "n": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "n",
                "value": "",
                "display_name": "N",
                "advanced": true,
                "dynamic": false,
                "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": false,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.3,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "Run inference with this temperature. Must by in the closed interval [0.0, 1.0].",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput",
                "load_from_db": false
              }
            },
            "description": "Generate text using Groq.",
            "icon": "Groq",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "Groq",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [],
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "groq_api_key",
              "groq_api_base",
              "max_tokens",
              "temperature",
              "n",
              "model_name",
              "output_parser"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "id": "GroqModel-EFDIv",
          "description": "Generate text using Groq.",
          "display_name": "Groq"
        },
        "selected": false,
        "width": 320,
        "height": 619,
        "positionAbsolute": {
          "x": 8689.192804800765,
          "y": -833.9346327053804
        },
        "dragging": false
      },
      {
        "id": "ParseData-vEXGs",
        "type": "genericNode",
        "position": {
          "x": 8306.776545605306,
          "y": -1016.2922074450323
        },
        "data": {
          "type": "ParseData",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "User Query: {user_query} \n\n** System Results: **\n\nMIP: {mip} \nExperiment: {experiment}\nVariable: {variable}\nDate Range: {date_range} \nTemporal Resolution: {temporal_resolution} \nSelected URL: {url}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "Parse Data",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "edited": false,
            "metadata": {},
            "lf_version": "1.1.1"
          },
          "id": "ParseData-vEXGs",
          "description": "Convert Data into plain text following a specified template.",
          "display_name": "Parse Data"
        },
        "selected": false,
        "width": 320,
        "height": 299,
        "positionAbsolute": {
          "x": 8306.776545605306,
          "y": -1016.2922074450323
        },
        "dragging": false
      },
      {
        "id": "ParseData-8PcnD",
        "type": "genericNode",
        "position": {
          "x": 2511.0347784734704,
          "y": -2439.1016070685455
        },
        "data": {
          "type": "ParseData",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{experiment}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "Experiment",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "edited": false,
            "metadata": {},
            "lf_version": "1.1.1"
          },
          "id": "ParseData-8PcnD",
          "description": "Convert Data into plain text following a specified template.",
          "display_name": "Experiment"
        },
        "selected": false,
        "width": 320,
        "height": 299,
        "positionAbsolute": {
          "x": 2511.0347784734704,
          "y": -2439.1016070685455
        },
        "dragging": false
      },
      {
        "id": "ParseData-QDFBy",
        "type": "genericNode",
        "position": {
          "x": 2503.418552215972,
          "y": -2796.495319491069
        },
        "data": {
          "type": "ParseData",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{MIP}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "MIP",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "edited": false,
            "metadata": {},
            "lf_version": "1.1.1"
          },
          "id": "ParseData-QDFBy",
          "description": "Convert Data into plain text following a specified template.",
          "display_name": "MIP"
        },
        "selected": false,
        "width": 320,
        "height": 299,
        "dragging": false,
        "positionAbsolute": {
          "x": 2503.418552215972,
          "y": -2796.495319491069
        }
      },
      {
        "id": "Prompt-5OXEm",
        "type": "genericNode",
        "position": {
          "x": 3267.897612365564,
          "y": -2095.6402967966023
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "You are an expert climate scientist working with CMIP6.\n\nHere is a list of the MIPs you work with:\n<MIP_LIST>\n{mip_list}\n</MIP_LIST>\n\nBased on the following query, which of the above MIPs would you use? Return ONLY the name of the MIP and nothing else. If the choice of MIP does not matter, return 'None'.\n\nQuery: {query}\n",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput",
                "load_from_db": false
              },
              "mip_list": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "mip_list",
                "display_name": "mip_list",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "query": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "query",
                "display_name": "query",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "base_classes": [
              "Message"
            ],
            "display_name": "MIP Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "mip_list",
                "query"
              ]
            },
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "id": "Prompt-5OXEm",
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Date Range Prompt"
        },
        "selected": false,
        "width": 320,
        "height": 429,
        "dragging": false,
        "positionAbsolute": {
          "x": 3267.897612365564,
          "y": -2095.6402967966023
        }
      },
      {
        "id": "OpenAIModel-zpTTy",
        "type": "genericNode",
        "position": {
          "x": 3630.1633108226492,
          "y": -2019.7750795794166
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "OPENAI_API_KEY",
                "display_name": "OpenAI API Key",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\nfrom langflow.inputs.inputs import HandleInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. \"\n            \"You must pass the word JSON in the prompt. \"\n            \"If left blank, JSON mode will be disabled. [DEPRECATED]\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o",
                "display_name": "Model Name",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled. [DEPRECATED]",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "MIPSelector",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [],
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "output_parser"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "id": "OpenAIModel-zpTTy",
          "description": "Generates text using OpenAI LLMs.",
          "display_name": "MIPSelector"
        },
        "selected": false,
        "width": 320,
        "height": 232,
        "dragging": false,
        "positionAbsolute": {
          "x": 3630.1633108226492,
          "y": -2019.7750795794166
        }
      },
      {
        "id": "Prompt-xAiEq",
        "type": "genericNode",
        "position": {
          "x": 3267.2895934065823,
          "y": -1570.378785358372
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "You are an expert climate scientist working with CMIP6.\n\nHere is a list of the experiments you work with:\n<EXPERIMENT_LIST>\n{EXPERIMENT_LIST}\n</EXPERIMENT_LIST>\nBased on the following query, which of the above experiments would you use? Return ONLY the name of the experiment and nothing else. If the choice of experiment does not matter, return 'None'.\n\nQuery: {query}",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput",
                "load_from_db": false
              },
              "EXPERIMENT_LIST": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "EXPERIMENT_LIST",
                "display_name": "EXPERIMENT_LIST",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "query": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "query",
                "display_name": "query",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "base_classes": [
              "Message"
            ],
            "display_name": "Experiment Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "EXPERIMENT_LIST",
                "query"
              ]
            },
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "id": "Prompt-xAiEq",
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Date Range Prompt"
        },
        "selected": false,
        "width": 320,
        "height": 429,
        "dragging": false,
        "positionAbsolute": {
          "x": 3267.2895934065823,
          "y": -1570.378785358372
        }
      },
      {
        "id": "OpenAIModel-oZik5",
        "type": "genericNode",
        "position": {
          "x": 3627.126468560398,
          "y": -1485.4427972933431
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "OPENAI_API_KEY",
                "display_name": "OpenAI API Key",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\nfrom langflow.inputs.inputs import HandleInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. \"\n            \"You must pass the word JSON in the prompt. \"\n            \"If left blank, JSON mode will be disabled. [DEPRECATED]\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o",
                "display_name": "Model Name",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled. [DEPRECATED]",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "ExperimentSelector",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [],
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "output_parser"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "id": "OpenAIModel-oZik5",
          "description": "Generates text using OpenAI LLMs.",
          "display_name": "MIPSelector"
        },
        "selected": false,
        "width": 320,
        "height": 232,
        "dragging": false,
        "positionAbsolute": {
          "x": 3627.126468560398,
          "y": -1485.4427972933431
        }
      },
      {
        "id": "note-M413d",
        "type": "noteNode",
        "position": {
          "x": 3244.3440273878914,
          "y": -1620.348533861517
        },
        "data": {
          "node": {
            "description": "# Experiment Selector",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note",
          "id": "note-M413d"
        },
        "selected": false,
        "width": 600,
        "height": 369,
        "positionAbsolute": {
          "x": 3244.3440273878914,
          "y": -1620.348533861517
        },
        "dragging": false,
        "style": {
          "width": 600,
          "height": 369
        },
        "resizing": false
      },
      {
        "id": "note-HUL2S",
        "type": "noteNode",
        "position": {
          "x": 3251.2064453977755,
          "y": -2156.8080171949077
        },
        "data": {
          "node": {
            "description": "# MIP Selector",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note",
          "id": "note-HUL2S"
        },
        "selected": false,
        "width": 600,
        "height": 324,
        "positionAbsolute": {
          "x": 3251.2064453977755,
          "y": -2156.8080171949077
        },
        "dragging": false,
        "style": {
          "width": 600,
          "height": 324
        },
        "resizing": false
      },
      {
        "id": "note-aylGt",
        "type": "noteNode",
        "position": {
          "x": 3251.2235651114934,
          "y": -1111.928915575845
        },
        "data": {
          "node": {
            "description": "# Variables Selector",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note",
          "id": "note-aylGt"
        },
        "selected": false,
        "width": 600,
        "height": 349,
        "positionAbsolute": {
          "x": 3251.2235651114934,
          "y": -1111.928915575845
        },
        "dragging": false,
        "style": {
          "width": 600,
          "height": 349
        },
        "resizing": false
      },
      {
        "id": "note-FUWgw",
        "type": "noteNode",
        "position": {
          "x": 3241.700118210881,
          "y": -672.7835776147137
        },
        "data": {
          "node": {
            "description": "# Temporal Selector",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note",
          "id": "note-FUWgw"
        },
        "selected": false,
        "width": 600,
        "height": 324,
        "positionAbsolute": {
          "x": 3241.700118210881,
          "y": -672.7835776147137
        },
        "dragging": false,
        "resizing": false,
        "style": {
          "width": 600,
          "height": 324
        }
      },
      {
        "id": "note-pL5z5",
        "type": "noteNode",
        "position": {
          "x": 3242.4078436029895,
          "y": -193.87950720208156
        },
        "data": {
          "node": {
            "description": "# Range Selector",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note",
          "id": "note-pL5z5"
        },
        "selected": false,
        "width": 600,
        "height": 324,
        "positionAbsolute": {
          "x": 3242.4078436029895,
          "y": -193.87950720208156
        },
        "dragging": false,
        "style": {
          "width": 600,
          "height": 324
        },
        "resizing": false
      },
      {
        "id": "note-5YmH5",
        "type": "noteNode",
        "position": {
          "x": 2104.4217981304396,
          "y": -2840.3587680822898
        },
        "data": {
          "node": {
            "description": "# Load CMIP6 Datasets",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "blue"
            }
          },
          "type": "note",
          "id": "note-5YmH5"
        },
        "selected": false,
        "width": 600,
        "height": 344,
        "positionAbsolute": {
          "x": 2104.4217981304396,
          "y": -2840.3587680822898
        },
        "dragging": false,
        "style": {
          "width": 600,
          "height": 344
        },
        "resizing": false
      },
      {
        "id": "note-0vqGA",
        "type": "noteNode",
        "position": {
          "x": 2876.2126877207456,
          "y": -2921.831798449466
        },
        "data": {
          "node": {
            "description": "# Load CMIP6 JSON Tables",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "blue"
            }
          },
          "type": "note",
          "id": "note-0vqGA"
        },
        "selected": false,
        "width": 600,
        "height": 324,
        "dragging": false,
        "positionAbsolute": {
          "x": 2876.2126877207456,
          "y": -2921.831798449466
        },
        "resizing": false,
        "style": {
          "width": 600,
          "height": 324
        }
      },
      {
        "id": "note-NuP2B",
        "type": "noteNode",
        "position": {
          "x": 411.4411617951864,
          "y": -1118.1843029534914
        },
        "data": {
          "node": {
            "description": "# Chat Start",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "lime"
            }
          },
          "type": "note",
          "id": "note-NuP2B"
        },
        "selected": false,
        "width": 324,
        "height": 324,
        "positionAbsolute": {
          "x": 411.4411617951864,
          "y": -1118.1843029534914
        },
        "dragging": false
      },
      {
        "id": "MIPFilterComponent-K59pp",
        "type": "genericNode",
        "position": {
          "x": 4308.5991434316675,
          "y": -2286.042075504498
        },
        "data": {
          "type": "MIPFilterComponent",
          "node": {
            "template": {
              "_type": "Component",
              "dataset_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dataset_info",
                "value": "",
                "display_name": "Dataset Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Processed CMIP6 dataset information from the previous component.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# MIPFilterComponent.py\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import HandleInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass MIPFilterComponent(Component):\r\n    display_name = \"MIP Filter\"\r\n    description = \"Filters CMIP6 datasets based on the predicted MIP.\"\r\n    icon = \"filter\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"dataset_info\",\r\n            display_name=\"Dataset Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Processed CMIP6 dataset information from the previous component.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"mip_value\",\r\n            display_name=\"MIP Value\",\r\n            info=\"The MIP value predicted by the LLM.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Filtered Datasets\", name=\"filtered_datasets\", method=\"filter_datasets_by_mip\"),\r\n    ]\r\n\r\n    def filter_datasets_by_mip(self) -> Data:\r\n        if not isinstance(self.dataset_info, Data) or 'df' not in self.dataset_info.data:\r\n            raise ValueError(\"Invalid dataset info input. Expected Data object with 'df' key.\")\r\n\r\n        df = self.dataset_info.data['df']\r\n\r\n        if 'MIP' not in df.columns:\r\n            raise ValueError(\"Expected 'MIP' column in dataset info DataFrame.\")\r\n\r\n        try:\r\n            mip_value = self.mip_value.strip()\r\n            if mip_value.lower() == 'none':\r\n                # No filtering; pass all datasets\r\n                filtered_df = df\r\n                self.status = \"No MIP filtering applied.\"\r\n            else:\r\n                # Filter the dataframe\r\n                filtered_df = df[df['MIP'] == mip_value]\r\n\r\n                if filtered_df.empty:\r\n                    self.status = f\"No datasets found for MIP '{mip_value}'.\"\r\n                else:\r\n                    self.status = f\"Filtered datasets by MIP '{mip_value}'. Remaining datasets: {len(filtered_df)}\"\r\n\r\n            return Data(data={\"filtered_df\": filtered_df})\r\n\r\n        except Exception as e:\r\n            error_message = f\"Error filtering datasets by MIP: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "mip_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "mip_value",
                "value": "",
                "display_name": "MIP Value",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The MIP value predicted by the LLM.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Filters CMIP6 datasets based on the predicted MIP.",
            "icon": "filter",
            "base_classes": [
              "Data"
            ],
            "display_name": "MIP Filter",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "filtered_datasets",
                "display_name": "Filtered Datasets",
                "method": "filter_datasets_by_mip",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "dataset_info",
              "mip_value"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.1.1"
          },
          "id": "MIPFilterComponent-K59pp"
        },
        "selected": false,
        "width": 320,
        "height": 300,
        "positionAbsolute": {
          "x": 4308.5991434316675,
          "y": -2286.042075504498
        },
        "dragging": false
      },
      {
        "id": "ExperimentFilterComponent-IlfCZ",
        "type": "genericNode",
        "position": {
          "x": 4720.720971626717,
          "y": -1965.9139769291764
        },
        "data": {
          "type": "ExperimentFilterComponent",
          "node": {
            "template": {
              "_type": "Component",
              "dataset_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dataset_info",
                "value": "",
                "display_name": "Dataset Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Dataset information from the previous component (after MIP filtering).",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# ExperimentFilterComponent.py\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import HandleInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass ExperimentFilterComponent(Component):\r\n    display_name = \"Experiment Filter\"\r\n    description = \"Filters CMIP6 datasets based on the predicted Experiment.\"\r\n    icon = \"filter\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"dataset_info\",\r\n            display_name=\"Dataset Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Dataset information from the previous component (after MIP filtering).\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"experiment_value\",\r\n            display_name=\"Experiment Value\",\r\n            info=\"The Experiment value predicted by the LLM.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Filtered Datasets\", name=\"filtered_datasets\", method=\"filter_datasets_by_experiment\"),\r\n    ]\r\n\r\n    def filter_datasets_by_experiment(self) -> Data:\r\n        if not isinstance(self.dataset_info, Data) or 'filtered_df' not in self.dataset_info.data:\r\n            raise ValueError(\"Invalid dataset info input. Expected Data object with 'filtered_df' key.\")\r\n\r\n        df = self.dataset_info.data['filtered_df']\r\n\r\n        if 'experiment' not in df.columns:\r\n            raise ValueError(\"Expected 'experiment' column in dataset info DataFrame.\")\r\n\r\n        try:\r\n            experiment_value = self.experiment_value.strip()\r\n            if experiment_value.lower() == 'none':\r\n                # No filtering; pass all datasets\r\n                filtered_df = df\r\n                self.status = \"No Experiment filtering applied.\"\r\n            else:\r\n                # Filter the dataframe\r\n                filtered_df = df[df['experiment'] == experiment_value]\r\n\r\n                if filtered_df.empty:\r\n                    self.status = f\"No datasets found for Experiment '{experiment_value}'.\"\r\n                else:\r\n                    self.status = f\"Filtered datasets by Experiment '{experiment_value}'. Remaining datasets: {len(filtered_df)}\"\r\n\r\n            return Data(data={\"filtered_df\": filtered_df})\r\n\r\n        except Exception as e:\r\n            error_message = f\"Error filtering datasets by Experiment: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "experiment_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "experiment_value",
                "value": "",
                "display_name": "Experiment Value",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The Experiment value predicted by the LLM.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Filters CMIP6 datasets based on the predicted Experiment.",
            "icon": "filter",
            "base_classes": [
              "Data"
            ],
            "display_name": "Experiment Filter",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "filtered_datasets",
                "display_name": "Filtered Datasets",
                "method": "filter_datasets_by_experiment",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "dataset_info",
              "experiment_value"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.1.1"
          },
          "id": "ExperimentFilterComponent-IlfCZ"
        },
        "selected": false,
        "width": 320,
        "height": 300,
        "positionAbsolute": {
          "x": 4720.720971626717,
          "y": -1965.9139769291764
        },
        "dragging": false
      },
      {
        "id": "FilteredVariableInfoComponent-ALgo2",
        "type": "genericNode",
        "position": {
          "x": 5150.778223745258,
          "y": -1649.2561807049508
        },
        "data": {
          "type": "FilteredVariableInfoComponent",
          "node": {
            "template": {
              "_type": "Component",
              "filtered_datasets": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "filtered_datasets",
                "value": "",
                "display_name": "Filtered Datasets",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Filtered datasets after MIP and Experiment filters.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "variable_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "variable_info",
                "value": "",
                "display_name": "Variable Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Original CMIP6 variable information.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# FilteredVariableInfoComponent.py\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import HandleInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass FilteredVariableInfoComponent(Component):\r\n    display_name = \"Filtered Variable Info\"\r\n    description = \"Filters variable info based on variables present in filtered datasets.\"\r\n    icon = \"filter\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"variable_info\",\r\n            display_name=\"Variable Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Original CMIP6 variable information.\",\r\n        ),\r\n        HandleInput(\r\n            name=\"filtered_datasets\",\r\n            display_name=\"Filtered Datasets\",\r\n            input_types=[\"Data\"],\r\n            info=\"Filtered datasets after MIP and Experiment filters.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(\r\n            display_name=\"Filtered Variable Info\",\r\n            name=\"filtered_variable_info\",\r\n            method=\"filter_variable_info\",\r\n        ),\r\n    ]\r\n\r\n    def filter_variable_info(self) -> Data:\r\n        if not isinstance(self.variable_info, Data) or 'variable_info' not in self.variable_info.data:\r\n            raise ValueError(\"Invalid variable info input. Expected Data object with 'variable_info' key.\")\r\n\r\n        if not isinstance(self.filtered_datasets, Data) or 'filtered_df' not in self.filtered_datasets.data:\r\n            raise ValueError(\"Invalid filtered datasets input. Expected Data object with 'filtered_df' key.\")\r\n\r\n        variable_info_df = self.variable_info.data['variable_info']\r\n        filtered_df = self.filtered_datasets.data['filtered_df']\r\n\r\n        try:\r\n            # Get the list of variables present in the filtered datasets\r\n            variables_in_filtered_datasets = filtered_df['variable'].unique().tolist()\r\n\r\n            # Filter variable info to only include these variables\r\n            filtered_variable_info_df = variable_info_df[variable_info_df['variable'].isin(variables_in_filtered_datasets)]\r\n\r\n            self.status = f\"Filtered variable info. Remaining variables: {len(filtered_variable_info_df)}\"\r\n            return Data(data={\"variable_info\": filtered_variable_info_df})\r\n\r\n        except Exception as e:\r\n            error_message = f\"Error filtering variable info: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Filters variable info based on variables present in filtered datasets.",
            "icon": "filter",
            "base_classes": [
              "Data"
            ],
            "display_name": "Filtered Variable Info",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "filtered_variable_info",
                "display_name": "Filtered Variable Info",
                "method": "filter_variable_info",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "variable_info",
              "filtered_datasets"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.1.1"
          },
          "id": "FilteredVariableInfoComponent-ALgo2"
        },
        "selected": false,
        "width": 320,
        "height": 262,
        "dragging": false,
        "positionAbsolute": {
          "x": 5150.778223745258,
          "y": -1649.2561807049508
        }
      },
      {
        "id": "variable_matcher-ngdqz",
        "type": "genericNode",
        "position": {
          "x": 3666.3057680460593,
          "y": -1060.990373856476
        },
        "data": {
          "type": "variable_matcher",
          "node": {
            "template": {
              "_type": "Component",
              "embeddings": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embeddings",
                "value": "",
                "display_name": "Embeddings",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "Embeddings component for generating query embeddings.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "variable_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "variable_info",
                "value": "",
                "display_name": "Variable Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Processed CMIP6 variable information from the previous component.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import numpy as np\r\nfrom typing import List, Dict, Any\r\nfrom pydantic import BaseModel, Field\r\n\r\nfrom langflow.base.langchain_utilities.model import LCToolComponent\r\nfrom langflow.io import HandleInput, MessageTextInput, IntInput, Output\r\nfrom langflow.schema import Data\r\nfrom langflow.field_typing import Tool\r\nfrom langchain.tools import StructuredTool\r\n\r\nclass VariableMatcherToolComponent(LCToolComponent):\r\n    display_name = \"CMIP6 Variable Matcher\"\r\n    description = \"Matches CMIP6 variables based on LLM output using cosine similarity.\"\r\n    icon = \"match\"\r\n    name = \"variable_matcher\"\r\n    variable_embeddings = None\r\n    variables_data = None\r\n    \r\n    inputs = [\r\n        HandleInput(\r\n            name=\"variable_info\",\r\n            display_name=\"Variable Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Processed CMIP6 variable information from the previous component.\",\r\n        ),\r\n        HandleInput(\r\n            name=\"embeddings\",\r\n            display_name=\"Embeddings\",\r\n            input_types=[\"Embeddings\"],\r\n            info=\"Embeddings component for generating query embeddings.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"llm_output\",\r\n            display_name=\"LLM Output\",\r\n            info=\"Output from the LLM containing variable-related keywords. Can be a single string or comma-separated list.\",\r\n        ),\r\n        IntInput(\r\n            name=\"top_n\",\r\n            display_name=\"Number of Results\",\r\n            info=\"Number of top matching variables to return.\",\r\n            value=5,\r\n        ),\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(display_name=\"Matched Variables\", name=\"matched_variables\", method=\"match_variables\"),\r\n        Output(display_name=\"Tool\", name=\"tool\", method=\"build_tool\"),\r\n    ]\r\n\r\n    class VariableMatcherSchema(BaseModel):\r\n        keywords: str = Field(\r\n            ..., \r\n            description=\"Keywords or description of the variable(s) to search for. Can be a comma-separated list.\"\r\n        )\r\n        top_n: int = Field(\r\n            5, \r\n            description=\"Number of top matching variables to return.\"\r\n        )\r\n\r\n    def cosine_similarity(self, a, b):\r\n        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\r\n\r\n    def _process_matches(self, keywords: str, top_n: int) -> List[Dict[str, Any]]:\r\n        \"\"\"Internal method to process variable matches\"\"\"\r\n        if not isinstance(self.variable_info, Data) or 'variable_info' not in self.variable_info.data:\r\n            raise ValueError(\"Invalid variable info input. Expected Data object with 'variable_info' key.\")\r\n        \r\n        varsdf = self.variable_info.data['variable_info']\r\n        \r\n        if 'embeds' not in varsdf.columns:\r\n            raise ValueError(\"Expected 'embeds' column in variable info DataFrame.\")\r\n\r\n        # Initialize variable embeddings if not already done\r\n        if self.variable_embeddings is None:\r\n            self.variable_embeddings = np.array(varsdf['embeds'].tolist())\r\n            self.variables_data = varsdf.drop('embeds', axis=1)\r\n\r\n        # Split keywords\r\n        keyword_list = [kw.strip() for kw in keywords.split(',')]\r\n        \r\n        # Generate embeddings for each keyword\r\n        keyword_embeddings = [self.embeddings.embed_query(kw) for kw in keyword_list]\r\n        \r\n        # Use the average embedding as the query\r\n        query_embedding = np.mean(keyword_embeddings, axis=0)\r\n        \r\n        # Calculate cosine similarity\r\n        similarities = np.array([\r\n            self.cosine_similarity(query_embedding, vec) \r\n            for vec in self.variable_embeddings\r\n        ])\r\n        \r\n        # Get top N matches\r\n        top_indices = np.argsort(similarities)[-top_n:][::-1]\r\n        \r\n        # Prepare results\r\n        results = self.variables_data.iloc[top_indices].copy()\r\n        results['similarity_score'] = similarities[top_indices]\r\n        \r\n        # Convert to list of dictionaries\r\n        return [\r\n            {\r\n                'variable': row['variable'],\r\n                'long_name': row['long_name'],\r\n                'comment': row['comment'],\r\n                'similarity_score': float(row['similarity_score'])\r\n            }\r\n            for _, row in results.iterrows()\r\n        ]\r\n\r\n    def match_variables(self) -> List[Data]:\r\n        \"\"\"Method for component output\"\"\"\r\n        try:\r\n            results = self._process_matches(self.llm_output, self.top_n)\r\n            data_list = [Data(data=result) for result in results]\r\n            self.status = data_list\r\n            return data_list\r\n            \r\n        except Exception as e:\r\n            error_message = f\"Error matching variables: {str(e)}\"\r\n            self.status = error_message\r\n            return [Data(data={\"error\": error_message})]\r\n\r\n    def build_tool(self) -> Tool:\r\n        \"\"\"Build and return the tool\"\"\"\r\n        return StructuredTool.from_function(\r\n            name=\"variable_matcher\",\r\n            description=\"Match CMIP6 variables based on keywords using semantic similarity. \"\r\n                      \"Input should be keywords or descriptions of the variables you're looking for.\",\r\n            func=self._tool_function,\r\n            args_schema=self.VariableMatcherSchema,\r\n        )\r\n\r\n    def _tool_function(self, keywords: str, top_n: int = 5) -> List[Dict[str, Any]]:\r\n        \"\"\"Function to be called by the tool\"\"\"\r\n        try:\r\n            return self._process_matches(keywords, top_n)\r\n        except Exception as e:\r\n            return [{\"error\": f\"Error matching variables: {str(e)}\"}]",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "llm_output": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "llm_output",
                "value": "",
                "display_name": "LLM Output",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Output from the LLM containing variable-related keywords. Can be a single string or comma-separated list.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "top_n": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "top_n",
                "value": 10,
                "display_name": "Number of Results",
                "advanced": false,
                "dynamic": false,
                "info": "Number of top matching variables to return.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput",
                "load_from_db": false
              }
            },
            "description": "Matches CMIP6 variables based on LLM output using cosine similarity.",
            "icon": "match",
            "base_classes": [
              "Data",
              "Tool"
            ],
            "display_name": "CMIP Variable Tool Check",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "matched_variables",
                "display_name": "Matched Variables",
                "method": "match_variables",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              },
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "variable_info",
              "embeddings",
              "llm_output",
              "top_n"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.1.1"
          },
          "id": "variable_matcher-ngdqz"
        },
        "selected": false,
        "width": 320,
        "height": 347,
        "positionAbsolute": {
          "x": 3666.3057680460593,
          "y": -1060.990373856476
        },
        "dragging": false
      },
      {
        "id": "note-y0HuE",
        "type": "noteNode",
        "position": {
          "x": 3804.112527509932,
          "y": -1112.5000011889613
        },
        "data": {
          "node": {
            "description": " ",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note",
          "id": "note-y0HuE"
        },
        "selected": false,
        "width": 600,
        "height": 355,
        "dragging": false,
        "style": {
          "width": 600,
          "height": 355
        },
        "resizing": false,
        "positionAbsolute": {
          "x": 3804.112527509932,
          "y": -1112.5000011889613
        }
      },
      {
        "id": "CurrentDateComponent-XMdiV",
        "type": "genericNode",
        "position": {
          "x": 3005.1083801447135,
          "y": 93.71069763839861
        },
        "data": {
          "type": "CurrentDateComponent",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from datetime import datetime\r\nfrom zoneinfo import ZoneInfo\r\nfrom typing import List\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import DropdownInput, Output\r\nfrom langflow.schema.message import Message\r\n\r\nclass CurrentDateComponent(Component):\r\n    display_name = \"Current Date 🕰️\"\r\n    description = \"Returns the current date and time in the selected timezone.\"\r\n    icon = \"clock\"\r\n\r\n    inputs = [\r\n        DropdownInput(\r\n            name=\"timezone\",\r\n            display_name=\"Timezone\",\r\n            options=[\r\n                \"UTC\",\r\n                \"US/Eastern\",\r\n                \"US/Central\",\r\n                \"US/Mountain\",\r\n                \"US/Pacific\",\r\n                \"Europe/London\",\r\n                \"Europe/Paris\",\r\n                \"Asia/Tokyo\",\r\n                \"Australia/Sydney\",\r\n                \"America/Sao_Paulo\",\r\n                \"America/Cuiaba\",\r\n            ],\r\n            value=\"UTC\",\r\n            info=\"Select the timezone for the current date and time.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Current Date\", name=\"current_date\", method=\"get_current_date\"),\r\n    ]\r\n\r\n    def get_current_date(self) -> Message:\r\n        try:\r\n            tz = ZoneInfo(self.timezone)\r\n            current_date = datetime.now(tz).strftime(\"%Y-%m-%d %H:%M:%S %Z\")\r\n            result = f\"Current date and time in {self.timezone}: {current_date}\"\r\n            self.status = result\r\n            return Message(text=result)\r\n        except Exception as e:\r\n            error_message = f\"Error: {str(e)}\"\r\n            self.status = error_message\r\n            return Message(text=error_message)",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "timezone": {
                "trace_as_metadata": true,
                "options": [
                  "UTC",
                  "US/Eastern",
                  "US/Central",
                  "US/Mountain",
                  "US/Pacific",
                  "Europe/London",
                  "Europe/Paris",
                  "Asia/Tokyo",
                  "Australia/Sydney",
                  "America/Sao_Paulo",
                  "America/Cuiaba"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "timezone",
                "value": "America/Sao_Paulo",
                "display_name": "Timezone",
                "advanced": false,
                "dynamic": false,
                "info": "Select the timezone for the current date and time.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              }
            },
            "description": "Returns the current date and time in the selected timezone.",
            "icon": "clock",
            "base_classes": [
              "Message"
            ],
            "display_name": "Current Date",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "current_date",
                "display_name": "Current Date",
                "method": "get_current_date",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "timezone"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.18",
            "official": false
          },
          "id": "CurrentDateComponent-XMdiV",
          "showNode": false
        },
        "selected": false,
        "width": 192,
        "height": 65,
        "positionAbsolute": {
          "x": 3005.1083801447135,
          "y": 93.71069763839861
        },
        "dragging": false
      },
      {
        "id": "note-HCeRl",
        "type": "noteNode",
        "position": {
          "x": 4280.8973999719465,
          "y": -2415.3972398695923
        },
        "data": {
          "node": {
            "description": "# Dataset Filtering Process",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "lime"
            }
          },
          "type": "note",
          "id": "note-HCeRl"
        },
        "selected": false,
        "width": 600,
        "height": 334,
        "positionAbsolute": {
          "x": 4280.8973999719465,
          "y": -2415.3972398695923
        },
        "dragging": false,
        "style": {
          "width": 600,
          "height": 334
        },
        "resizing": false
      },
      {
        "id": "note-HadNu",
        "type": "noteNode",
        "position": {
          "x": 8278.773012290505,
          "y": -1121.3999497626141
        },
        "data": {
          "node": {
            "description": "# Final Message Analysis ",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "lime"
            }
          },
          "type": "note",
          "id": "note-HadNu"
        },
        "selected": false,
        "width": 600,
        "height": 324,
        "positionAbsolute": {
          "x": 8278.773012290505,
          "y": -1121.3999497626141
        },
        "dragging": false,
        "style": {
          "width": 600,
          "height": 324
        },
        "resizing": false
      },
      {
        "id": "Agent-P843R",
        "type": "genericNode",
        "position": {
          "x": 4048.5987473550076,
          "y": -1060.7208915189365
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": "",
                "display_name": "External Memory",
                "advanced": true,
                "input_types": [
                  "BaseChatMessageHistory"
                ],
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "tools": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools",
                "value": "",
                "display_name": "Tools",
                "advanced": false,
                "input_types": [
                  "Tool",
                  "BaseTool",
                  "StructuredTool"
                ],
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "add_current_date_tool": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "add_current_date_tool",
                "value": true,
                "display_name": "Add tool Current Date",
                "advanced": true,
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "agent_description": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_description",
                "value": "A helpful assistant with access to the following tools:",
                "display_name": "Agent Description",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "agent_llm": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Amazon Bedrock",
                  "Anthropic",
                  "Azure OpenAI",
                  "Groq",
                  "NVIDIA",
                  "OpenAI",
                  "Custom"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_llm",
                "value": "OpenAI",
                "display_name": "Model Provider",
                "advanced": true,
                "input_types": [],
                "dynamic": false,
                "info": "The provider of the language model that the agent will use to generate responses.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "OPENAI_API_KEY",
                "display_name": "OpenAI API Key",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_core.tools import StructuredTool\n\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.base.models.model_input_constants import ALL_PROVIDER_FIELDS, MODEL_PROVIDERS_DICT\nfrom langflow.base.models.model_utils import get_model_name\nfrom langflow.components.helpers import CurrentDateComponent\nfrom langflow.components.helpers.memory import MemoryComponent\nfrom langflow.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom langflow.io import BoolInput, DropdownInput, MultilineInput, Output\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            input_types=[],\n        ),\n        *MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"],\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        *LCToolsAgentComponent._base_inputs,\n        *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Add tool Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [Output(name=\"response\", display_name=\"Response\", method=\"message_response\")]\n\n    async def message_response(self) -> Message:\n        llm_model, display_name = self.get_llm()\n        self.model_name = get_model_name(llm_model, display_name=display_name)\n        if llm_model is None:\n            msg = \"No language model selected\"\n            raise ValueError(msg)\n        self.chat_history = self.get_memory_data()\n\n        if self.add_current_date_tool:\n            if not isinstance(self.tools, list):  # type: ignore[has-type]\n                self.tools = []\n            # Convert CurrentDateComponent to a StructuredTool\n            current_date_tool = CurrentDateComponent().to_toolkit()[0]\n            if isinstance(current_date_tool, StructuredTool):\n                self.tools.append(current_date_tool)\n            else:\n                msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                raise ValueError(msg)\n\n        if not self.tools:\n            msg = \"Tools are required to run the agent.\"\n            raise ValueError(msg)\n        self.set(\n            llm=llm_model,\n            tools=self.tools,\n            chat_history=self.chat_history,\n            input_value=self.input_value,\n            system_prompt=self.system_prompt,\n        )\n        agent = self.create_agent_runnable()\n        return await self.run_agent(agent)\n\n    def get_memory_data(self):\n        memory_kwargs = {\n            component_input.name: getattr(self, f\"{component_input.name}\") for component_input in self.memory_inputs\n        }\n\n        return MemoryComponent().set(**memory_kwargs).retrieve_messages()\n\n    def get_llm(self):\n        if isinstance(self.agent_llm, str):\n            try:\n                provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n                if provider_info:\n                    component_class = provider_info.get(\"component_class\")\n                    display_name = component_class.display_name\n                    inputs = provider_info.get(\"inputs\")\n                    prefix = provider_info.get(\"prefix\", \"\")\n                    return self._build_llm_model(component_class, inputs, prefix), display_name\n            except Exception as e:\n                msg = f\"Error building {self.agent_llm} language model\"\n                raise ValueError(msg) from e\n        return self.agent_llm, None\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n        return component.set(**model_kwargs).build_model()\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    def update_build_config(self, build_config: dotdict, field_value: str, field_name: str | None = None) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name == \"agent_llm\":\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = component_class.update_build_config(build_config, field_value, field_name)\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n            elif field_value == \"Custom\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n                    value=\"Custom\",\n                    real_time_refresh=True,\n                    input_types=[\"LanguageModel\"],\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if isinstance(self.agent_llm, str) and self.agent_llm in MODEL_PROVIDERS_DICT:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = component_class.update_build_config(build_config, field_value, field_name)\n\n        return build_config\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "handle_parsing_errors": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "handle_parsing_errors",
                "value": true,
                "display_name": "Handle Parse Errors",
                "advanced": true,
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "input_value": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_iterations": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_iterations",
                "value": 15,
                "display_name": "Max Iterations",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o-mini",
                "display_name": "Model Name",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "n_messages": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "n_messages",
                "value": 100,
                "display_name": "Number of Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "order": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "order",
                "value": "Ascending",
                "display_name": "Order",
                "advanced": true,
                "dynamic": false,
                "info": "Order of the messages.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled. [DEPRECATED]",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine and User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Filter by sender type.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Filter by sender name.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "system_prompt": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_prompt",
                "value": "You are a helpful assistant that can use tools to answer questions and perform tasks.",
                "display_name": "Agent Instructions",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{sender_name}: {text}",
                "display_name": "Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "verbose": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "verbose",
                "value": true,
                "display_name": "Verbose",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "icon": "bot",
            "base_classes": [
              "Message"
            ],
            "display_name": "VariableSelector",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "response",
                "display_name": "Response",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "agent_llm",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "output_parser",
              "system_prompt",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template",
              "add_current_date_tool"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "agents",
            "key": "Agent",
            "score": 1.1732828199964098e-19,
            "lf_version": "1.1.1"
          },
          "type": "Agent",
          "id": "Agent-P843R"
        },
        "selected": false,
        "width": 320,
        "height": 385,
        "positionAbsolute": {
          "x": 4048.5987473550076,
          "y": -1060.7208915189365
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-aPZ0p",
        "type": "genericNode",
        "position": {
          "x": 4023.225274127163,
          "y": -1387.9401682772288
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "🧪",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, _id: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if _id:\n            source_dict[\"id\"] = _id\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    def message_response(self) -> Message:\n        _source, _icon, _display_name, _source_id = self.get_properties_from_source_component()\n        _background_color = self.background_color\n        _text_color = self.text_color\n        if self.chat_icon:\n            _icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(_source_id, _display_name, _source)\n        message.properties.icon = _icon\n        message.properties.background_color = _background_color\n        message.properties.text_color = _text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "Experiment",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "ExperimentSelector Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "ChatOutput",
          "id": "ChatOutput-aPZ0p",
          "showNode": false
        },
        "selected": false,
        "width": 192,
        "height": 65,
        "positionAbsolute": {
          "x": 4023.225274127163,
          "y": -1387.9401682772288
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-B0h63",
        "type": "genericNode",
        "position": {
          "x": 3990.090987621923,
          "y": -1849.081183813862
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "🧪",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, _id: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if _id:\n            source_dict[\"id\"] = _id\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    def message_response(self) -> Message:\n        _source, _icon, _display_name, _source_id = self.get_properties_from_source_component()\n        _background_color = self.background_color\n        _text_color = self.text_color\n        if self.chat_icon:\n            _icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(_source_id, _display_name, _source)\n        message.properties.icon = _icon\n        message.properties.background_color = _background_color\n        message.properties.text_color = _text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "MIP",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "MIPSelector Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "ChatOutput",
          "id": "ChatOutput-B0h63",
          "showNode": false
        },
        "selected": false,
        "width": 192,
        "height": 65,
        "positionAbsolute": {
          "x": 3990.090987621923,
          "y": -1849.081183813862
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-pojIY",
        "type": "genericNode",
        "position": {
          "x": 4420.290209494043,
          "y": -760.6068921644619
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "🧪",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, _id: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if _id:\n            source_dict[\"id\"] = _id\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    def message_response(self) -> Message:\n        _source, _icon, _display_name, _source_id = self.get_properties_from_source_component()\n        _background_color = self.background_color\n        _text_color = self.text_color\n        if self.chat_icon:\n            _icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(_source_id, _display_name, _source)\n        message.properties.icon = _icon\n        message.properties.background_color = _background_color\n        message.properties.text_color = _text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "Variable",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "VariableSelector Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "ChatOutput",
          "id": "ChatOutput-pojIY",
          "showNode": false
        },
        "selected": false,
        "width": 192,
        "height": 65,
        "positionAbsolute": {
          "x": 4420.290209494043,
          "y": -760.6068921644619
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-e9BH2",
        "type": "genericNode",
        "position": {
          "x": 3975.5057365391876,
          "y": -420.05443882834027
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "🧪",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, _id: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if _id:\n            source_dict[\"id\"] = _id\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    def message_response(self) -> Message:\n        _source, _icon, _display_name, _source_id = self.get_properties_from_source_component()\n        _background_color = self.background_color\n        _text_color = self.text_color\n        if self.chat_icon:\n            _icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(_source_id, _display_name, _source)\n        message.properties.icon = _icon\n        message.properties.background_color = _background_color\n        message.properties.text_color = _text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "Temporal Resolution",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "TemporalSelector Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "ChatOutput",
          "id": "ChatOutput-e9BH2",
          "showNode": false
        },
        "selected": false,
        "width": 192,
        "height": 65,
        "positionAbsolute": {
          "x": 3975.5057365391876,
          "y": -420.05443882834027
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-GzJ1x",
        "type": "genericNode",
        "position": {
          "x": 4001.302322677998,
          "y": 136.59348434065427
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "🧪",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, _id: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if _id:\n            source_dict[\"id\"] = _id\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    def message_response(self) -> Message:\n        _source, _icon, _display_name, _source_id = self.get_properties_from_source_component()\n        _background_color = self.background_color\n        _text_color = self.text_color\n        if self.chat_icon:\n            _icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(_source_id, _display_name, _source)\n        message.properties.icon = _icon\n        message.properties.background_color = _background_color\n        message.properties.text_color = _text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "Date Range",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "RangeSelector Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "ChatOutput",
          "id": "ChatOutput-GzJ1x",
          "showNode": false
        },
        "selected": false,
        "width": 192,
        "height": 65,
        "positionAbsolute": {
          "x": 4001.302322677998,
          "y": 136.59348434065427
        },
        "dragging": false
      },
      {
        "id": "CustomComponent-CYsb7",
        "type": "genericNode",
        "position": {
          "x": 842.0325342605774,
          "y": -711.9498001671886
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "clear_file": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "clear_file",
                "value": false,
                "display_name": "Clear File",
                "advanced": false,
                "dynamic": false,
                "info": "If set to true, the file contents will be cleared instead of read",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\r\nfrom langflow.io import MessageTextInput, BoolInput, Output\r\nfrom langflow.schema import Data\r\nimport json\r\nimport os\r\n\r\nclass ReadOrClearConfigComponent(Component):\r\n    display_name = \"Read or Clear Search Configuration\"\r\n    description = \"Read search configuration from a JSON file, clear its contents, or return empty values if the file doesn't exist\"\r\n    icon = \"file-json\"\r\n    \r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"file_name\",\r\n            display_name=\"File Name\",\r\n            info=\"The name of the JSON file to read or clear (without .json extension)\",\r\n            value=\"search_config\"\r\n        ),\r\n        BoolInput(\r\n            name=\"clear_file\",\r\n            display_name=\"Clear File\",\r\n            info=\"If set to true, the file contents will be cleared instead of read\",\r\n            value=False\r\n        ),\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(name=\"config_data\", display_name=\"Configuration Data\", method=\"read_or_clear_config\"),\r\n    ]\r\n\r\n    def get_empty_config(self):\r\n        return {\r\n            \"url\": \"\",\r\n            \"temporal_resolution\": \"\",\r\n            \"date_range\": \"\",\r\n            \"mip\": \"\",\r\n            \"experiment\": \"\",\r\n            \"variable\": \"\",\r\n            \"user_query\": \"\"\r\n        }\r\n\r\n    def read_or_clear_config(self) -> Data:\r\n        try:\r\n            file_name = f\"{self.file_name}.json\" if self.file_name else \"search_config.json\"\r\n            \r\n            if self.clear_file:\r\n                # Clear the file with empty values for all fields\r\n                empty_config = self.get_empty_config()\r\n                with open(file_name, 'w') as json_file:\r\n                    json.dump(empty_config, json_file, indent=2)\r\n                self.log(f\"File {file_name} has been cleared\")\r\n                return Data(data={**empty_config, \"file_name\": file_name, \"action\": \"cleared\"})\r\n            else:\r\n                # Read the file or return empty config if it doesn't exist\r\n                if not os.path.exists(file_name):\r\n                    self.log(f\"File {file_name} not found. Returning empty configuration.\")\r\n                    empty_config = self.get_empty_config()\r\n                    return Data(data={\r\n                        **empty_config,\r\n                        \"file_name\": file_name,\r\n                        \"action\": \"file_not_found\"\r\n                    })\r\n                \r\n                with open(file_name, 'r') as json_file:\r\n                    data = json.load(json_file)\r\n                \r\n                # Ensure all expected fields are present, use empty string if missing\r\n                config = {\r\n                    \"url\": data.get('url', ''),\r\n                    \"temporal_resolution\": data.get('temporal_resolution', ''),\r\n                    \"date_range\": data.get('date_range', ''),\r\n                    \"mip\": data.get('mip', ''),\r\n                    \"experiment\": data.get('experiment', ''),\r\n                    \"variable\": data.get('variable', ''),\r\n                    \"user_query\": data.get('user_query', ''),\r\n                    \"run_id\": data.get('run_id', '')\r\n                }\r\n                \r\n                self.log(f\"Configuration read from {file_name}\")\r\n                \r\n                return Data(data={\r\n                    **config,\r\n                    \"file_name\": file_name,\r\n                    \"action\": \"read\"\r\n                })\r\n        \r\n        except json.JSONDecodeError:\r\n            error_message = f\"Error decoding JSON from {file_name}. File may be empty or contain invalid JSON.\"\r\n            self.log(error_message)\r\n            empty_config = self.get_empty_config()\r\n            return Data(data={\r\n                **empty_config,\r\n                \"file_name\": file_name,\r\n                \"action\": \"json_error\",\r\n                \"error\": error_message\r\n            })\r\n        \r\n        except Exception as e:\r\n            error_message = f\"An error occurred: {str(e)}\"\r\n            self.log(error_message)\r\n            self.status = error_message\r\n            empty_config = self.get_empty_config()\r\n            return Data(data={\r\n                **empty_config,\r\n                \"file_name\": file_name,\r\n                \"action\": \"error\",\r\n                \"error\": error_message\r\n            })",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "file_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "file_name",
                "value": "url_data",
                "display_name": "File Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The name of the JSON file to read or clear (without .json extension)",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Read search configuration from a JSON file, clear its contents, or return empty values if the file doesn't exist",
            "icon": "file-json",
            "base_classes": [
              "Data"
            ],
            "display_name": "Read or Clear URL from JSON",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "config_data",
                "display_name": "Configuration Data",
                "method": "read_or_clear_config",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "file_name",
              "clear_file"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "CustomComponent",
          "id": "CustomComponent-CYsb7"
        },
        "selected": false,
        "width": 320,
        "height": 316,
        "dragging": false,
        "positionAbsolute": {
          "x": 842.0325342605774,
          "y": -711.9498001671886
        }
      },
      {
        "id": "CustomComponent-2VOTD",
        "type": "genericNode",
        "position": {
          "x": 1338.5764875995933,
          "y": -1064.6024254896874
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "input_data",
                "value": "",
                "display_name": "Input Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The Data object to be routed",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\r\nfrom langflow.io import DataInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass URLDataRouterComponent(Component):\r\n    display_name = \"URL Data Router\"\r\n    description = \"Route Data objects based on the presence of a URL, including additional message.\"\r\n    icon = \"git-branch\"\r\n    \r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"message\",\r\n            display_name=\"Message\",\r\n            info=\"Additional message to be added to the Data object\",\r\n            required=True,\r\n        ),\r\n        DataInput(\r\n            name=\"input_data\",\r\n            display_name=\"Input Data\",\r\n            info=\"The Data object to be routed\",\r\n            required=True,\r\n        ),\r\n        \r\n    ]\r\n    \r\n    outputs = [\r\n        Output(display_name=\"URL Absent\", name=\"url_absent\", method=\"route_url_absent\"),\r\n        Output(display_name=\"URL Present\", name=\"url_present\", method=\"route_url_present\"),\r\n    ]\r\n\r\n    def validate_input(self):\r\n        if not isinstance(self.input_data, Data):\r\n            raise ValueError(\"Input is not a Data object\")\r\n\r\n    def url_exists(self):\r\n        url = self.input_data.data.get('url', '')\r\n        return url and isinstance(url, str) and url.strip()\r\n\r\n    def _add_message_to_data(self) -> Data:\r\n        \"\"\"Add the message to the Data object\"\"\"\r\n        if isinstance(self.input_data.data, dict):\r\n            data_dict = self.input_data.data.copy()\r\n            data_dict['message'] = self.message\r\n            return Data(data=data_dict)\r\n        return self.input_data\r\n\r\n    def route_url_present(self) -> Data:\r\n        try:\r\n            self.validate_input()\r\n            \r\n            if self.url_exists():\r\n                return self._add_message_to_data()\r\n            else:\r\n                self.stop(\"url_present\")\r\n                return None\r\n                \r\n        except Exception as e:\r\n            error_message = f\"An error occurred in URL Present route: {str(e)}\"\r\n            self.log(error_message)\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})\r\n\r\n    def route_url_absent(self) -> Data:\r\n        try:\r\n            self.validate_input()\r\n            \r\n            if not self.url_exists():\r\n                return self._add_message_to_data()\r\n            else:\r\n                self.stop(\"url_absent\")\r\n                return None\r\n                \r\n        except Exception as e:\r\n            error_message = f\"An error occurred in URL Absent route: {str(e)}\"\r\n            self.log(error_message)\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "message": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "message",
                "value": "",
                "display_name": "Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Additional message to be added to the Data object",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Route Data objects based on the presence of a URL, including additional message.",
            "icon": "git-branch",
            "base_classes": [
              "Data"
            ],
            "display_name": "URL Message Router",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "url_absent",
                "display_name": "URL Absent",
                "method": "route_url_absent",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "url_present",
                "display_name": "URL Present",
                "method": "route_url_present",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "message",
              "input_data"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "CustomComponent",
          "id": "CustomComponent-2VOTD"
        },
        "selected": false,
        "width": 320,
        "height": 348,
        "dragging": false,
        "positionAbsolute": {
          "x": 1338.5764875995933,
          "y": -1064.6024254896874
        }
      },
      {
        "id": "CustomComponent-kZxYb",
        "type": "genericNode",
        "position": {
          "x": 7848.567957355622,
          "y": -408.7624322074041
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\r\nfrom langflow.io import MessageTextInput, Output\r\nfrom langflow.schema import Data\r\nimport json\r\nimport os\r\n\r\nclass SaveConfigComponent(Component):\r\n    display_name = \"Save Search Configuration\"\r\n    description = \"Save search configuration parameters including URL, temporal resolution, date range, MIP, experiment, variable, and user query to a JSON file\"\r\n    icon = \"save\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"url\",\r\n            display_name=\"URL\",\r\n            info=\"The URL to save in the JSON file\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"temporal_resolution\",\r\n            display_name=\"Temporal Resolution\",\r\n            info=\"The temporal resolution of the data\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"date_range\",\r\n            display_name=\"Date Range\",\r\n            info=\"The date range for the data\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"mip\",\r\n            display_name=\"MIP\",\r\n            info=\"The MIP (Model Intercomparison Project) identifier\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"experiment\",\r\n            display_name=\"Experiment\",\r\n            info=\"The experiment name or identifier\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"variable\",\r\n            display_name=\"Variable\",\r\n            info=\"The variable name or identifier\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"user_query\",\r\n            display_name=\"User Query\",\r\n            info=\"The original user query\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"file_name\",\r\n            display_name=\"File Name\",\r\n            info=\"The name of the JSON file to save (without .json extension)\",\r\n            advanced=True,\r\n            value=\"search_config\"\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(name=\"saved_data\", display_name=\"Saved Data\", method=\"save_config\"),\r\n    ]\r\n\r\n    def save_config(self) -> Data:\r\n        try:\r\n            # Validate required fields\r\n            if not self.url:\r\n                url = \"No Match\"\r\n            else:\r\n                url = self.url\r\n            # Prepare the data dictionary\r\n            data = {\r\n                \"url\": url,\r\n                \"temporal_resolution\": self.temporal_resolution,\r\n                \"date_range\": self.date_range,\r\n                \"mip\": self.mip,\r\n                \"experiment\": self.experiment,\r\n                \"variable\": self.variable,\r\n                \"user_query\": self.user_query,\r\n                \"run_id\": self.graph.run_id,\r\n                \"session_id\": self.graph.session_id\r\n            }\r\n\r\n            # Clean the data dictionary by removing None values\r\n            data = {k: v for k, v in data.items() if v is not None}\r\n\r\n            # Prepare file name\r\n            file_name = f\"{self.file_name}.json\" if self.file_name else \"search_config.json\"\r\n\r\n            # Save to JSON file\r\n            with open(file_name, 'w') as json_file:\r\n                json.dump(data, json_file, indent=2)\r\n\r\n            self.log(f\"Configuration saved to {file_name}\")\r\n            \r\n            return Data(data=data)\r\n\r\n        except Exception as e:\r\n            error_message = f\"An error occurred while saving the configuration: {str(e)}\"\r\n            self.log(error_message)\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "date_range": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "date_range",
                "value": "",
                "display_name": "Date Range",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The date range for the data",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "experiment": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "experiment",
                "value": "",
                "display_name": "Experiment",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The experiment name or identifier",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "file_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "file_name",
                "value": "url_data",
                "display_name": "File Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The name of the JSON file to save (without .json extension)",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "mip": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "mip",
                "value": "",
                "display_name": "MIP",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The MIP (Model Intercomparison Project) identifier",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temporal_resolution": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temporal_resolution",
                "value": "",
                "display_name": "Temporal Resolution",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The temporal resolution of the data",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "url": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "url",
                "value": "",
                "display_name": "URL",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The URL to save in the JSON file",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "user_query": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "user_query",
                "value": "",
                "display_name": "User Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The original user query",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "variable": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "variable",
                "value": "",
                "display_name": "Variable",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The variable name or identifier",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Save search configuration parameters including URL, temporal resolution, date range, MIP, experiment, variable, and user query to a JSON file",
            "icon": "save",
            "base_classes": [
              "Data"
            ],
            "display_name": "Save Search Configuration",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "saved_data",
                "display_name": "Saved Data",
                "method": "save_config",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "url",
              "temporal_resolution",
              "date_range",
              "mip",
              "experiment",
              "variable",
              "user_query",
              "file_name"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "CustomComponent",
          "id": "CustomComponent-kZxYb"
        },
        "selected": false,
        "width": 320,
        "height": 808,
        "positionAbsolute": {
          "x": 7848.567957355622,
          "y": -408.7624322074041
        },
        "dragging": false
      },
      {
        "id": "StructuredOutputComponent-YApUs",
        "type": "genericNode",
        "position": {
          "x": 2944.815772367211,
          "y": 658.6546950831621
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "llm": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "llm",
                "value": "",
                "display_name": "Language Model",
                "advanced": false,
                "input_types": [
                  "LanguageModel"
                ],
                "dynamic": false,
                "info": "The language model to use to generate the structured output.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import cast\n\nfrom pydantic import BaseModel, Field, create_model\n\nfrom langflow.base.models.chat_result import get_chat_result\nfrom langflow.custom import Component\nfrom langflow.field_typing.constants import LanguageModel\nfrom langflow.helpers.base_model import build_model_from_schema\nfrom langflow.io import BoolInput, HandleInput, MessageTextInput, Output, StrInput, TableInput\nfrom langflow.schema.data import Data\n\n\nclass StructuredOutputComponent(Component):\n    display_name = \"Structured Output\"\n    description = (\n        \"Transforms LLM responses into **structured data formats**. Ideal for extracting specific information \"\n        \"or creating consistent outputs.\"\n    )\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"The language model to use to generate the structured output.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        MessageTextInput(name=\"input_value\", display_name=\"Input message\"),\n        StrInput(\n            name=\"schema_name\",\n            display_name=\"Schema Name\",\n            info=\"Provide a name for the output data schema.\",\n        ),\n        TableInput(\n            name=\"output_schema\",\n            display_name=\"Output Schema\",\n            info=\"Define the structure and data types for the model's output.\",\n            table_schema=[\n                {\n                    \"name\": \"name\",\n                    \"display_name\": \"Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Specify the name of the output field.\",\n                },\n                {\n                    \"name\": \"description\",\n                    \"display_name\": \"Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Describe the purpose of the output field.\",\n                },\n                {\n                    \"name\": \"type\",\n                    \"display_name\": \"Type\",\n                    \"type\": \"str\",\n                    \"description\": (\n                        \"Indicate the data type of the output field \" \"(e.g., str, int, float, bool, list, dict).\"\n                    ),\n                    \"default\": \"text\",\n                },\n                {\n                    \"name\": \"multiple\",\n                    \"display_name\": \"Multiple\",\n                    \"type\": \"boolean\",\n                    \"description\": \"Set to True if this output field should be a list of the specified type.\",\n                    \"default\": \"False\",\n                },\n            ],\n        ),\n        BoolInput(\n            name=\"multiple\",\n            display_name=\"Generate Multiple\",\n            info=\"Set to True if the model should generate a list of outputs instead of a single output.\",\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"structured_output\", display_name=\"Structured Output\", method=\"build_structured_output\"),\n    ]\n\n    def build_structured_output(self) -> Data:\n        if not hasattr(self.llm, \"with_structured_output\"):\n            msg = \"Language model does not support structured output.\"\n            raise TypeError(msg)\n        if not self.output_schema:\n            msg = \"Output schema cannot be empty\"\n            raise ValueError(msg)\n\n        _output_model = build_model_from_schema(self.output_schema)\n        if self.multiple:\n            output_model = create_model(\n                self.schema_name,\n                objects=(list[_output_model], Field(description=f\"A list of {self.schema_name}.\")),  # type: ignore[valid-type]\n            )\n        else:\n            output_model = _output_model\n        try:\n            llm_with_structured_output = cast(LanguageModel, self.llm).with_structured_output(schema=output_model)  # type: ignore[valid-type, attr-defined]\n\n        except NotImplementedError as exc:\n            msg = f\"{self.llm.__class__.__name__} does not support structured output.\"\n            raise TypeError(msg) from exc\n        config_dict = {\n            \"run_name\": self.display_name,\n            \"project_name\": self.get_project_name(),\n            \"callbacks\": self.get_langchain_callbacks(),\n        }\n        output = get_chat_result(runnable=llm_with_structured_output, input_value=self.input_value, config=config_dict)\n        if isinstance(output, BaseModel):\n            output_dict = output.model_dump()\n        else:\n            msg = f\"Output should be a Pydantic BaseModel, got {type(output)} ({output})\"\n            raise TypeError(msg)\n        return Data(data=output_dict)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "multiple": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "multiple",
                "value": false,
                "display_name": "Generate Multiple",
                "advanced": false,
                "dynamic": false,
                "info": "Set to True if the model should generate a list of outputs instead of a single output.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "output_schema": {
                "is_list": true,
                "table_schema": {
                  "columns": [
                    {
                      "name": "name",
                      "display_name": "Name",
                      "sortable": true,
                      "filterable": true,
                      "type": "text",
                      "description": "Specify the name of the output field.",
                      "formatter": "text"
                    },
                    {
                      "name": "description",
                      "display_name": "Description",
                      "sortable": true,
                      "filterable": true,
                      "type": "text",
                      "description": "Describe the purpose of the output field.",
                      "formatter": "text"
                    },
                    {
                      "name": "type",
                      "display_name": "Type",
                      "sortable": true,
                      "filterable": true,
                      "type": "text",
                      "description": "Indicate the data type of the output field (e.g., str, int, float, bool, list, dict).",
                      "default": "text",
                      "formatter": "text"
                    },
                    {
                      "name": "multiple",
                      "display_name": "Multiple",
                      "sortable": true,
                      "filterable": true,
                      "type": "boolean",
                      "description": "Set to True if this output field should be a list of the specified type.",
                      "default": "False",
                      "formatter": "text"
                    }
                  ]
                },
                "trace_as_metadata": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": [
                  {
                    "name": "search_result_sentiment",
                    "description": "The Overall sentiment the user provided on the feedback",
                    "type": "text",
                    "multiple": "False"
                  },
                  {
                    "name": "variable_sentiment",
                    "description": "Sentiment for Variable Selection",
                    "type": "text",
                    "multiple": "False"
                  },
                  {
                    "name": "experiment_sentiment",
                    "description": "Sentiment for Experiment Selection",
                    "type": "text",
                    "multiple": "False"
                  },
                  {
                    "name": "mip_sentiment",
                    "description": "Sentiment for MIP Selection",
                    "type": "text",
                    "multiple": "False"
                  },
                  {
                    "name": "date_range_sentiment",
                    "description": "Sentiment for Date Range Selection",
                    "type": "text",
                    "multiple": "False"
                  },
                  {
                    "name": "temporal_resolution_sentiment",
                    "description": "Sentiment for Temporal Resolution Selection",
                    "type": "text",
                    "multiple": "False"
                  },
                  {
                    "name": "extra_feedback",
                    "description": "A description containing any extra feedback from the user",
                    "type": "text",
                    "multiple": "False"
                  },
                  {
                    "name": "url_sentiment",
                    "description": "Sentiment for URL Selection",
                    "type": "text",
                    "multiple": "False"
                  },
                  {
                    "name": "search_result_feedback",
                    "description": "Feedback on the result for CMIP Search system ",
                    "type": "text",
                    "multiple": "False"
                  }
                ],
                "display_name": "Output Schema",
                "advanced": false,
                "dynamic": false,
                "info": "Define the structure and data types for the model's output.",
                "title_case": false,
                "type": "table",
                "_input_type": "TableInput"
              },
              "schema_name": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "schema_name",
                "value": "user_feedback",
                "display_name": "Schema Name",
                "advanced": false,
                "dynamic": false,
                "info": "Provide a name for the output data schema.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              }
            },
            "description": "Transforms LLM responses into **structured data formats**. Ideal for extracting specific information or creating consistent outputs.",
            "icon": "braces",
            "base_classes": [
              "Data"
            ],
            "display_name": "Structured Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "structured_output",
                "display_name": "Structured Output",
                "method": "build_structured_output",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "llm",
              "input_value",
              "schema_name",
              "output_schema",
              "multiple"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "helpers",
            "key": "StructuredOutputComponent",
            "score": 0.575901449065324,
            "lf_version": "1.1.1"
          },
          "type": "StructuredOutputComponent",
          "id": "StructuredOutputComponent-YApUs"
        },
        "selected": false,
        "width": 320,
        "height": 538,
        "positionAbsolute": {
          "x": 2944.815772367211,
          "y": 658.6546950831621
        },
        "dragging": false
      },
      {
        "id": "OpenAIModel-IDP4D",
        "type": "genericNode",
        "position": {
          "x": 2536.7724366090497,
          "y": 573.7670572392733
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "OPENAI_API_KEY",
                "display_name": "OpenAI API Key",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\nfrom langflow.inputs.inputs import HandleInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. \"\n            \"You must pass the word JSON in the prompt. \"\n            \"If left blank, JSON mode will be disabled. [DEPRECATED]\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o-mini",
                "display_name": "Model Name",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled. [DEPRECATED]",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "Feedback Processor",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "output_parser"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "models",
            "key": "OpenAIModel",
            "score": 0.001,
            "lf_version": "1.1.1"
          },
          "type": "OpenAIModel",
          "id": "OpenAIModel-IDP4D"
        },
        "selected": false,
        "width": 320,
        "height": 366,
        "dragging": false,
        "positionAbsolute": {
          "x": 2536.7724366090497,
          "y": 573.7670572392733
        }
      },
      {
        "id": "Prompt-sniLH",
        "type": "genericNode",
        "position": {
          "x": 2131.4392185281686,
          "y": 715.4520386917652
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "<Instructions>\nYou are analyzing feedback for a CMIP dataset search system. The search configurations and the user's feedback are provided below. Your task is to classify the sentiment (positive, negative, or neutral) for each configuration and summarize all reasoning or additional comments into an \"Extra Feedback\" section.\n\n<SearchConfig>\n{search_config}\n</SearchConfig>\n\nSteps to follow:\n1. For each configuration (MIP, Experiment, Variable, Date Range, Temporal Resolution, Selected URL):\n   - If the user comments on the configuration, classify the sentiment as **positive**, **negative**, or **neutral**.\n   - If no feedback is provided for the configuration, classify it as **neutral**.\n2. Summarize any reasoning, specific comments, or suggestions from the user into the \"Extra Feedback\" section.\n3. Determine the overall sentiment:\n   - If most configurations are positive, classify the overall sentiment as **positive**.\n   - If most configurations are negative, classify the overall sentiment as **negative**.\n   - If feedback is mixed or mostly neutral, classify the overall sentiment as **neutral**.\n\nYour response should be structured as follows:\n<analysis>\n**MIP**: [Positive/Negative/Neutral]  \n**Experiment**: [Positive/Negative/Neutral]  \n**Variable**: [Positive/Negative/Neutral]  \n**Date Range**: [Positive/Negative/Neutral]  \n**Temporal Resolution**: [Positive/Negative/Neutral]  \n**Selected URL**: [Positive/Negative/Neutral]  \n\n**Overall Sentiment**: [Positive/Negative/Neutral]  \n\n**Extra Feedback**: [Summarize all reasoning, detailed comments, or suggestions here. If none provided, write \"None provided.\"]\n</analysis>\n\nOnly include the above analysis and summary in your response. Do not include any commentary or conversational elements outside of this structure. This is specifically for analyzing CMIP dataset search feedback.\n</Instructions>\n\n\nHere is the user's feedback:",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              },
              "search_config": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "search_config",
                "display_name": "search_config",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "search_config"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "legacy": false,
            "error": null,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "Prompt",
          "id": "Prompt-sniLH"
        },
        "selected": false,
        "width": 320,
        "height": 343,
        "positionAbsolute": {
          "x": 2131.4392185281686,
          "y": 715.4520386917652
        },
        "dragging": false
      },
      {
        "id": "ParseData-Ia8kl",
        "type": "genericNode",
        "position": {
          "x": 1757.5639942178286,
          "y": 685.8945902366149
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "User Query: {user_query} \nMIP: {mip} \nExperiment: {experiment}\nVariable: {variable}\nDate Range: {date_range} \nTemporal Resolution: {temporal_resolution} \nSelected URL: {url}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "Parse Data",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "processing",
            "key": "ParseData",
            "score": 0.007568328950209746,
            "lf_version": "1.1.1"
          },
          "type": "ParseData",
          "id": "ParseData-Ia8kl"
        },
        "selected": false,
        "width": 320,
        "height": 299,
        "dragging": false,
        "positionAbsolute": {
          "x": 1757.5639942178286,
          "y": 685.8945902366149
        }
      },
      {
        "id": "CustomComponent-J5dzH",
        "type": "genericNode",
        "position": {
          "x": 3327.2576649232615,
          "y": 814.6815012683637
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "trigger_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "trigger_data",
                "value": "",
                "display_name": "Trigger Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Any Data input that will trigger the clearing operation (content is ignored)",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\r\nfrom langflow.io import DataInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\nimport json\r\n\r\nclass ClearConfigTriggerComponent(Component):\r\n    display_name = \"Clear Config Trigger\"\r\n    description = \"Receives any Data input and clears the specified JSON configuration file\"\r\n    icon = \"trash-2\"\r\n    \r\n    inputs = [\r\n        DataInput(\r\n            name=\"trigger_data\",\r\n            display_name=\"Trigger Data\",\r\n            info=\"Any Data input that will trigger the clearing operation (content is ignored)\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"file_name\",\r\n            display_name=\"File Name\",\r\n            info=\"The name of the JSON file to clear (without .json extension)\",\r\n            advanced=True,\r\n            value=\"search_config\"\r\n        ),\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(name=\"cleared_status\", display_name=\"Cleared Status\", method=\"clear_config\"),\r\n    ]\r\n\r\n    def get_empty_config(self):\r\n        return {\r\n            \"url\": \"\",\r\n            \"temporal_resolution\": \"\",\r\n            \"date_range\": \"\",\r\n            \"mip\": \"\",\r\n            \"experiment\": \"\",\r\n            \"variable\": \"\",\r\n            \"user_query\": \"\"\r\n        }\r\n\r\n    def clear_config(self) -> Data:\r\n        try:\r\n            # Add .json extension if not provided\r\n            file_name = f\"{self.file_name}.json\" if self.file_name else \"search_config.json\"\r\n            \r\n            # Clear the file with empty values\r\n            empty_config = self.get_empty_config()\r\n            with open(file_name, 'w') as json_file:\r\n                json.dump(empty_config, json_file, indent=2)\r\n            \r\n            self.log(f\"Configuration file {file_name} has been cleared\")\r\n            self.status = f\"Successfully cleared {file_name}\"\r\n            \r\n            return Data(data={\r\n                \"file_name\": file_name,\r\n                \"status\": \"cleared\",\r\n                \"success\": True\r\n            })\r\n            \r\n        except Exception as e:\r\n            error_message = f\"Error clearing configuration file: {str(e)}\"\r\n            self.log(error_message)\r\n            self.status = error_message\r\n            \r\n            return Data(data={\r\n                \"file_name\": file_name,\r\n                \"status\": \"error\",\r\n                \"success\": False,\r\n                \"error\": error_message\r\n            })",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "file_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "file_name",
                "value": "url_data",
                "display_name": "File Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The name of the JSON file to clear (without .json extension)",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Receives any Data input and clears the specified JSON configuration file",
            "icon": "trash-2",
            "base_classes": [
              "Data"
            ],
            "display_name": "Read or Clear URL from JSON",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "cleared_status",
                "display_name": "Cleared Status",
                "method": "clear_config",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "trigger_data",
              "file_name"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "CustomComponent",
          "id": "CustomComponent-J5dzH"
        },
        "selected": false,
        "width": 320,
        "height": 300,
        "positionAbsolute": {
          "x": 3327.2576649232615,
          "y": 814.6815012683637
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-so6Rv",
        "type": "genericNode",
        "position": {
          "x": 4426.523488687803,
          "y": 961.0325344311311
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, _id: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if _id:\n            source_dict[\"id\"] = _id\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    def message_response(self) -> Message:\n        _source, _icon, _display_name, _source_id = self.get_properties_from_source_component()\n        _background_color = self.background_color\n        _text_color = self.text_color\n        if self.chat_icon:\n            _icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(_source_id, _display_name, _source)\n        message.properties.icon = _icon\n        message.properties.background_color = _background_color\n        message.properties.text_color = _text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "AI",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Thank you Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "outputs",
            "key": "ChatOutput",
            "score": 0.003169567463043492,
            "lf_version": "1.1.1"
          },
          "type": "ChatOutput",
          "id": "ChatOutput-so6Rv"
        },
        "selected": false,
        "width": 320,
        "height": 232,
        "positionAbsolute": {
          "x": 4426.523488687803,
          "y": 961.0325344311311
        },
        "dragging": false
      },
      {
        "id": "OpenAIModel-b0JqM",
        "type": "genericNode",
        "position": {
          "x": 4055.277214312021,
          "y": 839.2607840202859
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "OPENAI_API_KEY",
                "display_name": "OpenAI API Key",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\nfrom langflow.inputs.inputs import HandleInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. \"\n            \"You must pass the word JSON in the prompt. \"\n            \"If left blank, JSON mode will be disabled. [DEPRECATED]\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o-mini",
                "display_name": "Model Name",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled. [DEPRECATED]",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "ThanksMessage ",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [],
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "output_parser"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "models",
            "key": "OpenAIModel",
            "score": 0.001,
            "lf_version": "1.1.1"
          },
          "type": "OpenAIModel",
          "id": "OpenAIModel-b0JqM"
        },
        "selected": false,
        "width": 320,
        "height": 318,
        "dragging": false,
        "positionAbsolute": {
          "x": 4055.277214312021,
          "y": 839.2607840202859
        }
      },
      {
        "id": "ParseData-himFj",
        "type": "genericNode",
        "position": {
          "x": 3691.7220403030774,
          "y": 830.9406450199953
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "The user has provided feedback on the system's performance. \n\nYour task is to acknowledge the feedback, thank the user, and let them know that the system is ready to receive a new search query for CMIP datasets. \n\nDo not include any additional comments or engage in further conversation.",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "Parse Data",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "processing",
            "key": "ParseData",
            "score": 0.007568328950209746,
            "lf_version": "1.1.1"
          },
          "type": "ParseData",
          "id": "ParseData-himFj"
        },
        "selected": false,
        "width": 320,
        "height": 299,
        "positionAbsolute": {
          "x": 3691.7220403030774,
          "y": 830.9406450199953
        },
        "dragging": false
      },
      {
        "id": "CustomComponent-22zyT",
        "type": "genericNode",
        "position": {
          "x": 8290.414147396416,
          "y": -272.7302405586324
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "config_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "config_data",
                "value": "",
                "display_name": "Configuration Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The configuration data to save",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Dict\r\nfrom supabase import create_client, Client\r\nfrom langflow.custom import Component\r\nfrom langflow.io import SecretStrInput, MessageTextInput, DataInput, Output\r\nfrom langflow.schema import Data\r\nfrom loguru import logger\r\nfrom datetime import datetime\r\nimport uuid\r\n\r\nclass SaveConfigToDBComponent(Component):\r\n    display_name = \"Supabase Save Configuration\"\r\n    description = \"Save search configuration to Supabase database with unique ID and timestamp\"\r\n    icon = \"Supabase\"\r\n    \r\n    inputs = [\r\n        SecretStrInput(\r\n            name=\"supabase_url\",\r\n            display_name=\"Supabase URL\",\r\n            info=\"Your Supabase project URL\",\r\n            required=True,\r\n        ),\r\n        SecretStrInput(\r\n            name=\"supabase_key\",\r\n            display_name=\"Supabase Key\",\r\n            info=\"Your Supabase API key\",\r\n            required=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"table_name\",\r\n            display_name=\"Table Name\",\r\n            info=\"The name of the table to save the configuration to\",\r\n            required=True,\r\n        ),\r\n        DataInput(\r\n            name=\"config_data\",\r\n            display_name=\"Configuration Data\",\r\n            info=\"The configuration data to save\",\r\n            required=True,\r\n        ),\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(name=\"saved_record\", display_name=\"Saved Record\", method=\"save_config\"),\r\n    ]\r\n\r\n    def _init_client(self) -> Client:\r\n        \"\"\"Initialize Supabase client\"\"\"\r\n        try:\r\n            return create_client(self.supabase_url, self.supabase_key)\r\n        except Exception as e:\r\n            error_msg = f\"Error initializing Supabase client: {str(e)}\"\r\n            logger.error(error_msg)\r\n            raise ValueError(error_msg)\r\n\r\n    def _prepare_record(self) -> Dict:\r\n        \"\"\"Prepare the record to be saved with additional fields\"\"\"\r\n        # Generate unique ID\r\n        unique_id = str(uuid.uuid4())\r\n        \r\n        # Get current timestamp in ISO format\r\n        timestamp = datetime.utcnow().isoformat()\r\n\r\n        # Start with the original configuration data\r\n        if isinstance(self.config_data, Data):\r\n            record = self.config_data.data\r\n        else:\r\n            record = self.config_data\r\n\r\n        # Add the additional fields\r\n        record.update({\r\n            \"id\": unique_id,\r\n            \"created_at\": timestamp,\r\n        })\r\n\r\n        return record\r\n\r\n    def save_config(self) -> Data:\r\n        \"\"\"Save the configuration to the database\"\"\"\r\n        try:\r\n            client = self._init_client()\r\n            \r\n            # Prepare the record with all required fields\r\n            record = self._prepare_record()\r\n            \r\n            # Insert the record into the database\r\n            response = client.table(self.table_name).insert(record).execute()\r\n            \r\n            if not response.data:\r\n                raise ValueError(\"No data returned from insert operation\")\r\n            \r\n            # Return the saved record\r\n            saved_data = Data(data=response.data[0])\r\n            self.status = saved_data\r\n            \r\n            logger.info(f\"Configuration saved successfully with ID: {record['id']}\")\r\n            return saved_data\r\n            \r\n        except Exception as e:\r\n            error_msg = f\"Error saving configuration: {str(e)}\"\r\n            logger.error(error_msg)\r\n            return Data(data={\"error\": error_msg})",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "supabase_key": {
                "load_from_db": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "supabase_key",
                "value": "",
                "display_name": "Supabase Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Your Supabase API key",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "supabase_url": {
                "load_from_db": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "supabase_url",
                "value": "https://vghwqkmlwsvvoqmwpihr.supabase.co",
                "display_name": "Supabase URL",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Your Supabase project URL",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "table_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "table_name",
                "value": "search_configs",
                "display_name": "Table Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The name of the table to save the configuration to",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Save search configuration to Supabase database with unique ID and timestamp",
            "icon": "Supabase",
            "base_classes": [
              "Data"
            ],
            "display_name": "Save Search Configuration",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "saved_record",
                "display_name": "Saved Record",
                "method": "save_config",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "supabase_url",
              "supabase_key",
              "table_name",
              "config_data"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "CustomComponent",
          "id": "CustomComponent-22zyT"
        },
        "selected": false,
        "width": 320,
        "height": 472,
        "positionAbsolute": {
          "x": 8290.414147396416,
          "y": -272.7302405586324
        },
        "dragging": false
      },
      {
        "id": "ParseData-LlMXM",
        "type": "genericNode",
        "position": {
          "x": 2545.1993783093367,
          "y": 1147.9816086809524
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{run_id}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "Previous Run ID",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "processing",
            "key": "ParseData",
            "score": 0.007568328950209746,
            "lf_version": "1.1.1"
          },
          "type": "ParseData",
          "id": "ParseData-LlMXM"
        },
        "selected": false,
        "width": 320,
        "height": 299,
        "positionAbsolute": {
          "x": 2545.1993783093367,
          "y": 1147.9816086809524
        },
        "dragging": false
      },
      {
        "id": "CustomComponent-AJAcN",
        "type": "genericNode",
        "position": {
          "x": 3324.8757113100205,
          "y": 1203.7479141736462
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "sentiment_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "sentiment_data",
                "value": "",
                "display_name": "Sentiment Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The sentiment feedback data",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import Dict\r\nfrom supabase import create_client, Client\r\nfrom langflow.custom import Component\r\nfrom langflow.io import SecretStrInput, DataInput, Output, MessageTextInput\r\nfrom langflow.schema import Data\r\nfrom loguru import logger\r\nfrom datetime import datetime\r\nimport uuid\r\n\r\nclass SaveSentimentFeedbackComponent(Component):\r\n    display_name = \"Supabase Save Sentiment Feedback\"\r\n    description = \"Save search result sentiment feedback and link it to the search configuration\"\r\n    icon = \"Supabase\"\r\n    \r\n    inputs = [\r\n        SecretStrInput(\r\n            name=\"supabase_url\",\r\n            display_name=\"Supabase URL\",\r\n            info=\"Your Supabase project URL\",\r\n            required=True,\r\n        ),\r\n        SecretStrInput(\r\n            name=\"supabase_key\",\r\n            display_name=\"Supabase Key\",\r\n            info=\"Your Supabase API key\",\r\n            required=True,\r\n        ),\r\n        DataInput(\r\n            name=\"sentiment_data\",\r\n            display_name=\"Sentiment Data\",\r\n            info=\"The sentiment feedback data\",\r\n            required=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"search_run_id\",\r\n            display_name=\"Search Run ID\",\r\n            info=\"The ID of the search configuration to link to\",\r\n            required=True,\r\n        )\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(name=\"saved_feedback\", display_name=\"Saved Feedback\", method=\"save_sentiment\"),\r\n    ]\r\n\r\n    def _init_client(self) -> Client:\r\n        \"\"\"Initialize Supabase client\"\"\"\r\n        try:\r\n            return create_client(self.supabase_url, self.supabase_key)\r\n        except Exception as e:\r\n            error_msg = f\"Error initializing Supabase client: {str(e)}\"\r\n            logger.error(error_msg)\r\n            raise ValueError(error_msg)\r\n\r\n    def _prepare_sentiment_record(self) -> Dict:\r\n        \"\"\"Prepare the sentiment feedback record\"\"\"\r\n        # Generate unique ID\r\n        feedback_id = str(uuid.uuid4())\r\n        timestamp = datetime.utcnow().isoformat()\r\n\r\n        if not isinstance(self.sentiment_data, Data):\r\n            raise ValueError(\"Sentiment data must be a Data object\")\r\n\r\n        sentiment_dict = self.sentiment_data.data\r\n        \r\n        # Create the feedback record\r\n        record = {\r\n            \"id\": feedback_id,\r\n            \"created_at\": timestamp,\r\n            \"search_config_run_id\": self.search_run_id,\r\n            \r\n            # Sentiment fields\r\n            \"search_result_sentiment\": sentiment_dict.get(\"search_result_sentiment\"),\r\n            \"variable_sentiment\": sentiment_dict.get(\"variable_sentiment\"),\r\n            \"experiment_sentiment\": sentiment_dict.get(\"experiment_sentiment\"),\r\n            \"mip_sentiment\": sentiment_dict.get(\"mip_sentiment\"),\r\n            \"date_range_sentiment\": sentiment_dict.get(\"date_range_sentiment\"),\r\n            \"temporal_resolution_sentiment\": sentiment_dict.get(\"temporal_resolution_sentiment\"),\r\n            \"url_sentiment\": sentiment_dict.get(\"url_sentiment\"),\r\n            \"extra_feedback\": sentiment_dict.get(\"extra_feedback\")\r\n        }\r\n\r\n        return record\r\n\r\n    def save_sentiment(self) -> Data:\r\n        \"\"\"Save the sentiment feedback to the database\"\"\"\r\n        try:\r\n            client = self._init_client()\r\n            \r\n            # First verify the search_run_id exists\r\n            verify = client.table(\"search_configs\") \\\r\n                          .select(\"id\") \\\r\n                          .eq(\"run_id\", self.search_run_id) \\\r\n                          .execute()\r\n            \r\n            if not verify.data:\r\n                raise ValueError(f\"No search configuration found with run_id: {self.search_run_id}\")\r\n            \r\n            # Prepare and save the sentiment record\r\n            record = self._prepare_sentiment_record()\r\n            \r\n            # Insert the record into the sentiment_feedback table\r\n            response = client.table(\"sentiment_feedback\").insert(record).execute()\r\n            \r\n            if not response.data:\r\n                raise ValueError(\"No data returned from insert operation\")\r\n            \r\n            # Return the saved record\r\n            saved_data = Data(data=response.data[0])\r\n            self.status = saved_data\r\n            \r\n            logger.info(f\"Sentiment feedback saved successfully with ID: {record['id']}\")\r\n            return saved_data\r\n            \r\n        except Exception as e:\r\n            error_msg = f\"Error saving sentiment feedback: {str(e)}\"\r\n            logger.error(error_msg)\r\n            return Data(data={\r\n                \"error\": error_msg,\r\n                \"status\": \"error\",\r\n                \"success\": False\r\n            })",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "search_run_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "search_run_id",
                "value": "",
                "display_name": "Search Run ID",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The ID of the search configuration to link to",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "supabase_key": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "supabase_key",
                "value": "SUPABASE_KEY",
                "display_name": "Supabase Key",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Your Supabase API key",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "supabase_url": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "supabase_url",
                "value": "SUPABASE_URL",
                "display_name": "Supabase URL",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Your Supabase project URL",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              }
            },
            "description": "Save search result sentiment feedback and link it to the search configuration",
            "icon": "Supabase",
            "base_classes": [
              "Data"
            ],
            "display_name": "Supabase Save Sentiment Feedback",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "saved_feedback",
                "display_name": "Saved Feedback",
                "method": "save_sentiment",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "supabase_url",
              "supabase_key",
              "sentiment_data",
              "search_run_id"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "CustomComponent",
          "id": "CustomComponent-AJAcN"
        },
        "selected": false,
        "width": 320,
        "height": 300,
        "positionAbsolute": {
          "x": 3324.8757113100205,
          "y": 1203.7479141736462
        },
        "dragging": false
      },
      {
        "id": "ParseData-3O8KR",
        "type": "genericNode",
        "position": {
          "x": 2117.4988669157246,
          "y": -1519.1432643033322
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{message}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "Search Query",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "processing",
            "key": "ParseData",
            "score": 0.007568328950209746,
            "lf_version": "1.1.1"
          },
          "type": "ParseData",
          "id": "ParseData-3O8KR"
        },
        "selected": false,
        "width": 320,
        "height": 299,
        "dragging": false,
        "positionAbsolute": {
          "x": 2117.4988669157246,
          "y": -1519.1432643033322
        }
      },
      {
        "id": "ParseData-6qzNm",
        "type": "genericNode",
        "position": {
          "x": 2126.8683505670833,
          "y": 349.9392208918457
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{message}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "User Message",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "processing",
            "key": "ParseData",
            "score": 0.007568328950209746,
            "lf_version": "1.1.1"
          },
          "type": "ParseData",
          "id": "ParseData-6qzNm"
        },
        "selected": false,
        "width": 320,
        "height": 299,
        "positionAbsolute": {
          "x": 2126.8683505670833,
          "y": 349.9392208918457
        },
        "dragging": false
      },
      {
        "id": "Prompt-dLMFP",
        "type": "genericNode",
        "position": {
          "x": 8309.357575368325,
          "y": -669.4134897994322
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "You are assisting in gathering feedback for a CMIP Dataset selector system. The user will provide a query, and the system will generate selections based on the query. \n\nYour task is to present the results of the system's selection and ask for feedback to help improve the system. \n\nDo not attempt to answer the user's query or provide additional information beyond the system's output.\n\nEG: \n\nPlease provide feedback on the following:\n1. **Positive Feedback**: What aspects of the selection are accurate or meet your expectations?\n2. **Negative Feedback**: What aspects of the selection are inaccurate, irrelevant, or do not meet your expectations?\n3. **Neutral Feedback**: Are there any aspects that are acceptable but could be improved?\n4. **Additional Suggestions**: Do you have any other comments or recommendations that could help improve the system's search and selection process?\n\nYour feedback will be used to fine-tune the system and enhance its performance. \n\n\n",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "custom_fields": {
              "template": []
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "legacy": false,
            "error": null,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "Prompt",
          "id": "Prompt-dLMFP"
        },
        "selected": false,
        "width": 320,
        "height": 258,
        "positionAbsolute": {
          "x": 8309.357575368325,
          "y": -669.4134897994322
        },
        "dragging": false
      },
      {
        "id": "note-0twiz",
        "type": "noteNode",
        "position": {
          "x": 2041.0292122345072,
          "y": 245.7497887305908
        },
        "data": {
          "node": {
            "description": "# User Feedback System",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note",
          "id": "note-0twiz"
        },
        "width": 600,
        "height": 324,
        "selected": false,
        "dragging": false,
        "style": {
          "width": 600,
          "height": 324
        },
        "resizing": false,
        "positionAbsolute": {
          "x": 2041.0292122345072,
          "y": 245.7497887305908
        }
      },
      {
        "id": "note-MYIGp",
        "type": "noteNode",
        "position": {
          "x": 2039.5844260837744,
          "y": -1604.1485298807581
        },
        "data": {
          "node": {
            "description": "# Dataset Search System",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note",
          "id": "note-MYIGp"
        },
        "selected": false,
        "width": 600,
        "height": 324,
        "positionAbsolute": {
          "x": 2039.5844260837744,
          "y": -1604.1485298807581
        },
        "dragging": false,
        "style": {
          "width": 600,
          "height": 324
        },
        "resizing": false
      },
      {
        "id": "note-2VfcN",
        "type": "noteNode",
        "position": {
          "x": 7842.0084292551865,
          "y": -480.80259983764756
        },
        "data": {
          "node": {
            "description": "# Save Search Config",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "blue"
            }
          },
          "type": "note",
          "id": "note-2VfcN"
        },
        "selected": false,
        "width": 421,
        "height": 324,
        "positionAbsolute": {
          "x": 7842.0084292551865,
          "y": -480.80259983764756
        },
        "dragging": false,
        "resizing": false,
        "style": {
          "width": 421,
          "height": 324
        }
      },
      {
        "id": "note-Js9r6",
        "type": "noteNode",
        "position": {
          "x": 825.17698253957,
          "y": -771.6237037867004
        },
        "data": {
          "node": {
            "description": "## Load System State",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "blue"
            }
          },
          "type": "note",
          "id": "note-Js9r6"
        },
        "width": 324,
        "height": 324,
        "selected": false,
        "dragging": false,
        "resizing": false,
        "positionAbsolute": {
          "x": 825.17698253957,
          "y": -771.6237037867004
        }
      },
      {
        "id": "TextInput-fjFRL",
        "type": "genericNode",
        "position": {
          "x": 4071.7582301793736,
          "y": 361.3230474342012
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get text inputs from the Playground.\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        StrInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_metadata": true,
                "load_from_db": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "SUPABASE_URL",
                "display_name": "Text",
                "advanced": false,
                "dynamic": false,
                "info": "Text to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              }
            },
            "description": "Get text inputs from the Playground.",
            "icon": "type",
            "base_classes": [
              "Message"
            ],
            "display_name": "Text Input",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "TextInput",
          "id": "TextInput-fjFRL"
        },
        "selected": true,
        "width": 320,
        "height": 233,
        "dragging": false,
        "positionAbsolute": {
          "x": 4071.7582301793736,
          "y": 361.3230474342012
        }
      }
    ],
    "edges": [
      {
        "source": "CMIP6DatasetProcessorComponent-hmgKP",
        "target": "TemporalResolutionFilterComponent-MLtJu",
        "sourceHandle": "{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-hmgKPœ,œnameœ:œprocessed_dfœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œdataset_infoœ,œidœ:œTemporalResolutionFilterComponent-MLtJuœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-CMIP6DatasetProcessorComponent-hmgKP{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-hmgKPœ,œnameœ:œprocessed_dfœ,œoutput_typesœ:[œDataœ]}-TemporalResolutionFilterComponent-MLtJu{œfieldNameœ:œdataset_infoœ,œidœ:œTemporalResolutionFilterComponent-MLtJuœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "dataset_info",
            "id": "TemporalResolutionFilterComponent-MLtJu",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CMIP6DatasetProcessorComponent",
            "id": "CMIP6DatasetProcessorComponent-hmgKP",
            "name": "processed_df",
            "output_types": [
              "Data"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "TemporalResolutionFilterComponent-MLtJu",
        "target": "YearRangeFilterComponent-bEvwF",
        "sourceHandle": "{œdataTypeœ:œTemporalResolutionFilterComponentœ,œidœ:œTemporalResolutionFilterComponent-MLtJuœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œdataset_infoœ,œidœ:œYearRangeFilterComponent-bEvwFœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-TemporalResolutionFilterComponent-MLtJu{œdataTypeœ:œTemporalResolutionFilterComponentœ,œidœ:œTemporalResolutionFilterComponent-MLtJuœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}-YearRangeFilterComponent-bEvwF{œfieldNameœ:œdataset_infoœ,œidœ:œYearRangeFilterComponent-bEvwFœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "dataset_info",
            "id": "YearRangeFilterComponent-bEvwF",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "TemporalResolutionFilterComponent",
            "id": "TemporalResolutionFilterComponent-MLtJu",
            "name": "filtered_datasets",
            "output_types": [
              "Data"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "YearRangeFilterComponent-bEvwF",
        "target": "URLExtractorComponent-fE6vL",
        "sourceHandle": "{œdataTypeœ:œYearRangeFilterComponentœ,œidœ:œYearRangeFilterComponent-bEvwFœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œdataset_infoœ,œidœ:œURLExtractorComponent-fE6vLœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-YearRangeFilterComponent-bEvwF{œdataTypeœ:œYearRangeFilterComponentœ,œidœ:œYearRangeFilterComponent-bEvwFœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}-URLExtractorComponent-fE6vL{œfieldNameœ:œdataset_infoœ,œidœ:œURLExtractorComponent-fE6vLœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "dataset_info",
            "id": "URLExtractorComponent-fE6vL",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "YearRangeFilterComponent",
            "id": "YearRangeFilterComponent-bEvwF",
            "name": "filtered_datasets",
            "output_types": [
              "Data"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "Prompt-z9f1V",
        "target": "OpenAIModel-mGQfP",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-z9f1Vœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-mGQfPœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-Prompt-z9f1V{œdataTypeœ:œPromptœ,œidœ:œPrompt-z9f1Vœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-mGQfP{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-mGQfPœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-mGQfP",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-z9f1V",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "OpenAIModel-mGQfP",
        "target": "YearRangeFilterComponent-bEvwF",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-mGQfPœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œyear_rangeœ,œidœ:œYearRangeFilterComponent-bEvwFœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-OpenAIModel-mGQfP{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-mGQfPœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-YearRangeFilterComponent-bEvwF{œfieldNameœ:œyear_rangeœ,œidœ:œYearRangeFilterComponent-bEvwFœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "year_range",
            "id": "YearRangeFilterComponent-bEvwF",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-mGQfP",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "Prompt-L0LEg",
        "target": "OpenAIModel-nbPZx",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-L0LEgœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-nbPZxœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-Prompt-L0LEg{œdataTypeœ:œPromptœ,œidœ:œPrompt-L0LEgœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-nbPZx{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-nbPZxœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-nbPZx",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-L0LEg",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "OpenAIModel-nbPZx",
        "target": "TemporalResolutionFilterComponent-MLtJu",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-nbPZxœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œresolutionœ,œidœ:œTemporalResolutionFilterComponent-MLtJuœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-OpenAIModel-nbPZx{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-nbPZxœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-TemporalResolutionFilterComponent-MLtJu{œfieldNameœ:œresolutionœ,œidœ:œTemporalResolutionFilterComponent-MLtJuœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "resolution",
            "id": "TemporalResolutionFilterComponent-MLtJu",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-nbPZx",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "CMIP6DatasetProcessorComponent-hmgKP",
        "target": "CMIP6VariableProcessorFromZip-rKSeA",
        "sourceHandle": "{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-hmgKPœ,œnameœ:œprocessed_dfœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œdataset_infoœ,œidœ:œCMIP6VariableProcessorFromZip-rKSeAœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-CMIP6DatasetProcessorComponent-hmgKP{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-hmgKPœ,œnameœ:œprocessed_dfœ,œoutput_typesœ:[œDataœ]}-CMIP6VariableProcessorFromZip-rKSeA{œfieldNameœ:œdataset_infoœ,œidœ:œCMIP6VariableProcessorFromZip-rKSeAœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "dataset_info",
            "id": "CMIP6VariableProcessorFromZip-rKSeA",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CMIP6DatasetProcessorComponent",
            "id": "CMIP6DatasetProcessorComponent-hmgKP",
            "name": "processed_df",
            "output_types": [
              "Data"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "OpenAIEmbeddings-sXTEV",
        "target": "CMIP6VariableProcessorFromZip-rKSeA",
        "sourceHandle": "{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-sXTEVœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "targetHandle": "{œfieldNameœ:œembeddingsœ,œidœ:œCMIP6VariableProcessorFromZip-rKSeAœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-OpenAIEmbeddings-sXTEV{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-sXTEVœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-CMIP6VariableProcessorFromZip-rKSeA{œfieldNameœ:œembeddingsœ,œidœ:œCMIP6VariableProcessorFromZip-rKSeAœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "embeddings",
            "id": "CMIP6VariableProcessorFromZip-rKSeA",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIEmbeddings",
            "id": "OpenAIEmbeddings-sXTEV",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "URLExtractorComponent-fE6vL",
        "target": "ParseData-kqy2r",
        "sourceHandle": "{œdataTypeœ:œURLExtractorComponentœ,œidœ:œURLExtractorComponent-fE6vLœ,œnameœ:œextracted_urlsœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-kqy2rœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-URLExtractorComponent-fE6vL{œdataTypeœ:œURLExtractorComponentœ,œidœ:œURLExtractorComponent-fE6vLœ,œnameœ:œextracted_urlsœ,œoutput_typesœ:[œDataœ]}-ParseData-kqy2r{œfieldNameœ:œdataœ,œidœ:œParseData-kqy2rœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-kqy2r",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "URLExtractorComponent",
            "id": "URLExtractorComponent-fE6vL",
            "name": "extracted_urls",
            "output_types": [
              "Data"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "ParseData-vEXGs",
        "target": "GroqModel-EFDIv",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-vEXGsœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œGroqModel-EFDIvœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-ParseData-vEXGs{œdataTypeœ:œParseDataœ,œidœ:œParseData-vEXGsœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-GroqModel-EFDIv{œfieldNameœ:œinput_valueœ,œidœ:œGroqModel-EFDIvœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "GroqModel-EFDIv",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-vEXGs",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "GroqModel-EFDIv",
        "target": "ChatOutput-V9dwj",
        "sourceHandle": "{œdataTypeœ:œGroqModelœ,œidœ:œGroqModel-EFDIvœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-V9dwjœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-GroqModel-EFDIv{œdataTypeœ:œGroqModelœ,œidœ:œGroqModel-EFDIvœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-V9dwj{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-V9dwjœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-V9dwj",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "GroqModel",
            "id": "GroqModel-EFDIv",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "CMIP6DatasetProcessorComponent-hmgKP",
        "sourceHandle": "{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-hmgKPœ,œnameœ:œunique_experimentsœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-8PcnD",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-8PcnDœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-8PcnD",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CMIP6DatasetProcessorComponent",
            "id": "CMIP6DatasetProcessorComponent-hmgKP",
            "name": "unique_experiments",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CMIP6DatasetProcessorComponent-hmgKP{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-hmgKPœ,œnameœ:œunique_experimentsœ,œoutput_typesœ:[œDataœ]}-ParseData-8PcnD{œfieldNameœ:œdataœ,œidœ:œParseData-8PcnDœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "CMIP6DatasetProcessorComponent-hmgKP",
        "sourceHandle": "{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-hmgKPœ,œnameœ:œunique_mipsœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-QDFBy",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-QDFByœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-QDFBy",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CMIP6DatasetProcessorComponent",
            "id": "CMIP6DatasetProcessorComponent-hmgKP",
            "name": "unique_mips",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CMIP6DatasetProcessorComponent-hmgKP{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-hmgKPœ,œnameœ:œunique_mipsœ,œoutput_typesœ:[œDataœ]}-ParseData-QDFBy{œfieldNameœ:œdataœ,œidœ:œParseData-QDFByœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "Prompt-5OXEm",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-5OXEmœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-zpTTy",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-zpTTyœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-zpTTy",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-5OXEm",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-5OXEm{œdataTypeœ:œPromptœ,œidœ:œPrompt-5OXEmœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-zpTTy{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-zpTTyœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "className": "",
        "animated": false
      },
      {
        "source": "Prompt-xAiEq",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-xAiEqœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-oZik5",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-oZik5œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-oZik5",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-xAiEq",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-xAiEq{œdataTypeœ:œPromptœ,œidœ:œPrompt-xAiEqœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-oZik5{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-oZik5œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": "",
        "selected": false,
        "animated": false
      },
      {
        "source": "ParseData-8PcnD",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-8PcnDœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-xAiEq",
        "targetHandle": "{œfieldNameœ:œEXPERIMENT_LISTœ,œidœ:œPrompt-xAiEqœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "EXPERIMENT_LIST",
            "id": "Prompt-xAiEq",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-8PcnD",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-8PcnD{œdataTypeœ:œParseDataœ,œidœ:œParseData-8PcnDœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-xAiEq{œfieldNameœ:œEXPERIMENT_LISTœ,œidœ:œPrompt-xAiEqœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": "",
        "selected": false,
        "animated": false
      },
      {
        "source": "ParseData-QDFBy",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-QDFByœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-5OXEm",
        "targetHandle": "{œfieldNameœ:œmip_listœ,œidœ:œPrompt-5OXEmœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "mip_list",
            "id": "Prompt-5OXEm",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-QDFBy",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-QDFBy{œdataTypeœ:œParseDataœ,œidœ:œParseData-QDFByœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-5OXEm{œfieldNameœ:œmip_listœ,œidœ:œPrompt-5OXEmœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": "",
        "selected": false,
        "animated": false
      },
      {
        "source": "CMIP6DatasetProcessorComponent-hmgKP",
        "sourceHandle": "{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-hmgKPœ,œnameœ:œprocessed_dfœ,œoutput_typesœ:[œDataœ]}",
        "target": "MIPFilterComponent-K59pp",
        "targetHandle": "{œfieldNameœ:œdataset_infoœ,œidœ:œMIPFilterComponent-K59ppœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "dataset_info",
            "id": "MIPFilterComponent-K59pp",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CMIP6DatasetProcessorComponent",
            "id": "CMIP6DatasetProcessorComponent-hmgKP",
            "name": "processed_df",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CMIP6DatasetProcessorComponent-hmgKP{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-hmgKPœ,œnameœ:œprocessed_dfœ,œoutput_typesœ:[œDataœ]}-MIPFilterComponent-K59pp{œfieldNameœ:œdataset_infoœ,œidœ:œMIPFilterComponent-K59ppœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "selected": false,
        "animated": false
      },
      {
        "source": "MIPFilterComponent-K59pp",
        "sourceHandle": "{œdataTypeœ:œMIPFilterComponentœ,œidœ:œMIPFilterComponent-K59ppœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}",
        "target": "ExperimentFilterComponent-IlfCZ",
        "targetHandle": "{œfieldNameœ:œdataset_infoœ,œidœ:œExperimentFilterComponent-IlfCZœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "dataset_info",
            "id": "ExperimentFilterComponent-IlfCZ",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "MIPFilterComponent",
            "id": "MIPFilterComponent-K59pp",
            "name": "filtered_datasets",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-MIPFilterComponent-K59pp{œdataTypeœ:œMIPFilterComponentœ,œidœ:œMIPFilterComponent-K59ppœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}-ExperimentFilterComponent-IlfCZ{œfieldNameœ:œdataset_infoœ,œidœ:œExperimentFilterComponent-IlfCZœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "OpenAIModel-zpTTy",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-zpTTyœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "MIPFilterComponent-K59pp",
        "targetHandle": "{œfieldNameœ:œmip_valueœ,œidœ:œMIPFilterComponent-K59ppœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "mip_value",
            "id": "MIPFilterComponent-K59pp",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-zpTTy",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-zpTTy{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-zpTTyœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-MIPFilterComponent-K59pp{œfieldNameœ:œmip_valueœ,œidœ:œMIPFilterComponent-K59ppœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "OpenAIModel-oZik5",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-oZik5œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ExperimentFilterComponent-IlfCZ",
        "targetHandle": "{œfieldNameœ:œexperiment_valueœ,œidœ:œExperimentFilterComponent-IlfCZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "experiment_value",
            "id": "ExperimentFilterComponent-IlfCZ",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-oZik5",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-oZik5{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-oZik5œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ExperimentFilterComponent-IlfCZ{œfieldNameœ:œexperiment_valueœ,œidœ:œExperimentFilterComponent-IlfCZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "CMIP6VariableProcessorFromZip-rKSeA",
        "sourceHandle": "{œdataTypeœ:œCMIP6VariableProcessorFromZipœ,œidœ:œCMIP6VariableProcessorFromZip-rKSeAœ,œnameœ:œvariable_infoœ,œoutput_typesœ:[œDataœ]}",
        "target": "FilteredVariableInfoComponent-ALgo2",
        "targetHandle": "{œfieldNameœ:œvariable_infoœ,œidœ:œFilteredVariableInfoComponent-ALgo2œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "variable_info",
            "id": "FilteredVariableInfoComponent-ALgo2",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CMIP6VariableProcessorFromZip",
            "id": "CMIP6VariableProcessorFromZip-rKSeA",
            "name": "variable_info",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CMIP6VariableProcessorFromZip-rKSeA{œdataTypeœ:œCMIP6VariableProcessorFromZipœ,œidœ:œCMIP6VariableProcessorFromZip-rKSeAœ,œnameœ:œvariable_infoœ,œoutput_typesœ:[œDataœ]}-FilteredVariableInfoComponent-ALgo2{œfieldNameœ:œvariable_infoœ,œidœ:œFilteredVariableInfoComponent-ALgo2œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "ExperimentFilterComponent-IlfCZ",
        "sourceHandle": "{œdataTypeœ:œExperimentFilterComponentœ,œidœ:œExperimentFilterComponent-IlfCZœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}",
        "target": "FilteredVariableInfoComponent-ALgo2",
        "targetHandle": "{œfieldNameœ:œfiltered_datasetsœ,œidœ:œFilteredVariableInfoComponent-ALgo2œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "filtered_datasets",
            "id": "FilteredVariableInfoComponent-ALgo2",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "ExperimentFilterComponent",
            "id": "ExperimentFilterComponent-IlfCZ",
            "name": "filtered_datasets",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-ExperimentFilterComponent-IlfCZ{œdataTypeœ:œExperimentFilterComponentœ,œidœ:œExperimentFilterComponent-IlfCZœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}-FilteredVariableInfoComponent-ALgo2{œfieldNameœ:œfiltered_datasetsœ,œidœ:œFilteredVariableInfoComponent-ALgo2œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "FilteredVariableInfoComponent-ALgo2",
        "sourceHandle": "{œdataTypeœ:œFilteredVariableInfoComponentœ,œidœ:œFilteredVariableInfoComponent-ALgo2œ,œnameœ:œfiltered_variable_infoœ,œoutput_typesœ:[œDataœ]}",
        "target": "variable_matcher-GzLTK",
        "targetHandle": "{œfieldNameœ:œvariable_infoœ,œidœ:œvariable_matcher-GzLTKœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "variable_info",
            "id": "variable_matcher-GzLTK",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "FilteredVariableInfoComponent",
            "id": "FilteredVariableInfoComponent-ALgo2",
            "name": "filtered_variable_info",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-FilteredVariableInfoComponent-ALgo2{œdataTypeœ:œFilteredVariableInfoComponentœ,œidœ:œFilteredVariableInfoComponent-ALgo2œ,œnameœ:œfiltered_variable_infoœ,œoutput_typesœ:[œDataœ]}-variable_matcher-GzLTK{œfieldNameœ:œvariable_infoœ,œidœ:œvariable_matcher-GzLTKœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "FilteredVariableInfoComponent-ALgo2",
        "sourceHandle": "{œdataTypeœ:œFilteredVariableInfoComponentœ,œidœ:œFilteredVariableInfoComponent-ALgo2œ,œnameœ:œfiltered_variable_infoœ,œoutput_typesœ:[œDataœ]}",
        "target": "variable_matcher-ngdqz",
        "targetHandle": "{œfieldNameœ:œvariable_infoœ,œidœ:œvariable_matcher-ngdqzœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "variable_info",
            "id": "variable_matcher-ngdqz",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "FilteredVariableInfoComponent",
            "id": "FilteredVariableInfoComponent-ALgo2",
            "name": "filtered_variable_info",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-FilteredVariableInfoComponent-ALgo2{œdataTypeœ:œFilteredVariableInfoComponentœ,œidœ:œFilteredVariableInfoComponent-ALgo2œ,œnameœ:œfiltered_variable_infoœ,œoutput_typesœ:[œDataœ]}-variable_matcher-ngdqz{œfieldNameœ:œvariable_infoœ,œidœ:œvariable_matcher-ngdqzœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "OpenAIEmbeddings-sXTEV",
        "sourceHandle": "{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-sXTEVœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "target": "variable_matcher-ngdqz",
        "targetHandle": "{œfieldNameœ:œembeddingsœ,œidœ:œvariable_matcher-ngdqzœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "embeddings",
            "id": "variable_matcher-ngdqz",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIEmbeddings",
            "id": "OpenAIEmbeddings-sXTEV",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIEmbeddings-sXTEV{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-sXTEVœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-variable_matcher-ngdqz{œfieldNameœ:œembeddingsœ,œidœ:œvariable_matcher-ngdqzœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "variable_matcher-GzLTK",
        "sourceHandle": "{œdataTypeœ:œvariable_matcherœ,œidœ:œvariable_matcher-GzLTKœ,œnameœ:œmatched_variablesœ,œoutput_typesœ:[œDataœ]}",
        "target": "TemporalResolutionFilterComponent-MLtJu",
        "targetHandle": "{œfieldNameœ:œmatched_variablesœ,œidœ:œTemporalResolutionFilterComponent-MLtJuœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "matched_variables",
            "id": "TemporalResolutionFilterComponent-MLtJu",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "variable_matcher",
            "id": "variable_matcher-GzLTK",
            "name": "matched_variables",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-variable_matcher-GzLTK{œdataTypeœ:œvariable_matcherœ,œidœ:œvariable_matcher-GzLTKœ,œnameœ:œmatched_variablesœ,œoutput_typesœ:[œDataœ]}-TemporalResolutionFilterComponent-MLtJu{œfieldNameœ:œmatched_variablesœ,œidœ:œTemporalResolutionFilterComponent-MLtJuœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "CurrentDateComponent-XMdiV",
        "sourceHandle": "{œdataTypeœ:œCurrentDateComponentœ,œidœ:œCurrentDateComponent-XMdiVœ,œnameœ:œcurrent_dateœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-z9f1V",
        "targetHandle": "{œfieldNameœ:œcurrent_dateœ,œidœ:œPrompt-z9f1Vœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "current_date",
            "id": "Prompt-z9f1V",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "CurrentDateComponent",
            "id": "CurrentDateComponent-XMdiV",
            "name": "current_date",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-CurrentDateComponent-XMdiV{œdataTypeœ:œCurrentDateComponentœ,œidœ:œCurrentDateComponent-XMdiVœ,œnameœ:œcurrent_dateœ,œoutput_typesœ:[œMessageœ]}-Prompt-z9f1V{œfieldNameœ:œcurrent_dateœ,œidœ:œPrompt-z9f1Vœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "Prompt-sXSLK",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-sXSLKœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Agent-P843R",
        "targetHandle": "{œfieldNameœ:œsystem_promptœ,œidœ:œAgent-P843Rœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "system_prompt",
            "id": "Agent-P843R",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-sXSLK",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "className": "",
        "id": "reactflow__edge-Prompt-sXSLK{œdataTypeœ:œPromptœ,œidœ:œPrompt-sXSLKœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-Agent-P843R{œfieldNameœ:œsystem_promptœ,œidœ:œAgent-P843Rœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "selected": false
      },
      {
        "source": "variable_matcher-ngdqz",
        "sourceHandle": "{œdataTypeœ:œvariable_matcherœ,œidœ:œvariable_matcher-ngdqzœ,œnameœ:œtoolœ,œoutput_typesœ:[œToolœ]}",
        "target": "Agent-P843R",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œAgent-P843Rœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-P843R",
            "inputTypes": [
              "Tool",
              "BaseTool",
              "StructuredTool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "variable_matcher",
            "id": "variable_matcher-ngdqz",
            "name": "tool",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-variable_matcher-ngdqz{œdataTypeœ:œvariable_matcherœ,œidœ:œvariable_matcher-ngdqzœ,œnameœ:œtoolœ,œoutput_typesœ:[œToolœ]}-Agent-P843R{œfieldNameœ:œtoolsœ,œidœ:œAgent-P843Rœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "Agent-P843R",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-P843Rœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "variable_matcher-GzLTK",
        "targetHandle": "{œfieldNameœ:œvariable_nameœ,œidœ:œvariable_matcher-GzLTKœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "variable_name",
            "id": "variable_matcher-GzLTK",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-P843R",
            "name": "response",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Agent-P843R{œdataTypeœ:œAgentœ,œidœ:œAgent-P843Rœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-variable_matcher-GzLTK{œfieldNameœ:œvariable_nameœ,œidœ:œvariable_matcher-GzLTKœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "OpenAIModel-oZik5",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-oZik5œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-aPZ0p",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-aPZ0pœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-aPZ0p",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-oZik5",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "animated": false,
        "className": "",
        "id": "reactflow__edge-OpenAIModel-oZik5{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-oZik5œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-aPZ0p{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-aPZ0pœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false
      },
      {
        "source": "OpenAIModel-zpTTy",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-zpTTyœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-B0h63",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-B0h63œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-B0h63",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-zpTTy",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-zpTTy{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-zpTTyœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-B0h63{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-B0h63œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "Agent-P843R",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-P843Rœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-pojIY",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-pojIYœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-pojIY",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-P843R",
            "name": "response",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Agent-P843R{œdataTypeœ:œAgentœ,œidœ:œAgent-P843Rœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-pojIY{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-pojIYœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "OpenAIModel-nbPZx",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-nbPZxœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-e9BH2",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-e9BH2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-e9BH2",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-nbPZx",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-nbPZx{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-nbPZxœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-e9BH2{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-e9BH2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "OpenAIModel-mGQfP",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-mGQfPœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-GzJ1x",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-GzJ1xœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-GzJ1x",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-mGQfP",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-mGQfP{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-mGQfPœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-GzJ1x{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-GzJ1xœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "ParseData-kqy2r",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-kqy2rœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-kZxYb",
        "targetHandle": "{œfieldNameœ:œurlœ,œidœ:œCustomComponent-kZxYbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "url",
            "id": "CustomComponent-kZxYb",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-kqy2r",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-kqy2r{œdataTypeœ:œParseDataœ,œidœ:œParseData-kqy2rœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-kZxYb{œfieldNameœ:œurlœ,œidœ:œCustomComponent-kZxYbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "ChatInput-5ouAc",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-5ouAcœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-2VOTD",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œCustomComponent-2VOTDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "message",
            "id": "CustomComponent-2VOTD",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-5ouAc",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-5ouAc{œdataTypeœ:œChatInputœ,œidœ:œChatInput-5ouAcœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-2VOTD{œfieldNameœ:œmessageœ,œidœ:œCustomComponent-2VOTDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "OpenAIModel-IDP4D",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-IDP4Dœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "StructuredOutputComponent-YApUs",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œStructuredOutputComponent-YApUsœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "llm",
            "id": "StructuredOutputComponent-YApUs",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-IDP4D",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-IDP4D{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-IDP4Dœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-StructuredOutputComponent-YApUs{œfieldNameœ:œllmœ,œidœ:œStructuredOutputComponent-YApUsœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "Agent-P843R",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-P843Rœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-kZxYb",
        "targetHandle": "{œfieldNameœ:œvariableœ,œidœ:œCustomComponent-kZxYbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "variable",
            "id": "CustomComponent-kZxYb",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-P843R",
            "name": "response",
            "output_types": [
              "Message"
            ]
          }
        },
        "animated": false,
        "className": "",
        "id": "reactflow__edge-Agent-P843R{œdataTypeœ:œAgentœ,œidœ:œAgent-P843Rœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-kZxYb{œfieldNameœ:œvariableœ,œidœ:œCustomComponent-kZxYbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false
      },
      {
        "source": "OpenAIModel-nbPZx",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-nbPZxœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-kZxYb",
        "targetHandle": "{œfieldNameœ:œtemporal_resolutionœ,œidœ:œCustomComponent-kZxYbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "temporal_resolution",
            "id": "CustomComponent-kZxYb",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-nbPZx",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "animated": false,
        "className": "",
        "id": "reactflow__edge-OpenAIModel-nbPZx{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-nbPZxœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-kZxYb{œfieldNameœ:œtemporal_resolutionœ,œidœ:œCustomComponent-kZxYbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false
      },
      {
        "source": "OpenAIModel-mGQfP",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-mGQfPœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-kZxYb",
        "targetHandle": "{œfieldNameœ:œdate_rangeœ,œidœ:œCustomComponent-kZxYbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "date_range",
            "id": "CustomComponent-kZxYb",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-mGQfP",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "animated": false,
        "className": "",
        "id": "reactflow__edge-OpenAIModel-mGQfP{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-mGQfPœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-kZxYb{œfieldNameœ:œdate_rangeœ,œidœ:œCustomComponent-kZxYbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false
      },
      {
        "source": "OpenAIModel-oZik5",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-oZik5œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-kZxYb",
        "targetHandle": "{œfieldNameœ:œexperimentœ,œidœ:œCustomComponent-kZxYbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "experiment",
            "id": "CustomComponent-kZxYb",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-oZik5",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "animated": false,
        "className": "",
        "id": "reactflow__edge-OpenAIModel-oZik5{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-oZik5œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-kZxYb{œfieldNameœ:œexperimentœ,œidœ:œCustomComponent-kZxYbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false
      },
      {
        "source": "OpenAIModel-zpTTy",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-zpTTyœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-kZxYb",
        "targetHandle": "{œfieldNameœ:œmipœ,œidœ:œCustomComponent-kZxYbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "mip",
            "id": "CustomComponent-kZxYb",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-zpTTy",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "animated": false,
        "className": "",
        "id": "reactflow__edge-OpenAIModel-zpTTy{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-zpTTyœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-kZxYb{œfieldNameœ:œmipœ,œidœ:œCustomComponent-kZxYbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false
      },
      {
        "source": "OpenAIModel-IDP4D",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-IDP4Dœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "StructuredOutputComponent-YApUs",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œStructuredOutputComponent-YApUsœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "StructuredOutputComponent-YApUs",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-IDP4D",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-IDP4D{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-IDP4Dœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-StructuredOutputComponent-YApUs{œfieldNameœ:œinput_valueœ,œidœ:œStructuredOutputComponent-YApUsœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "Prompt-sniLH",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-sniLHœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-IDP4D",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-IDP4Dœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "system_message",
            "id": "OpenAIModel-IDP4D",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-sniLH",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-sniLH{œdataTypeœ:œPromptœ,œidœ:œPrompt-sniLHœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-IDP4D{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-IDP4Dœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "StructuredOutputComponent-YApUs",
        "sourceHandle": "{œdataTypeœ:œStructuredOutputComponentœ,œidœ:œStructuredOutputComponent-YApUsœ,œnameœ:œstructured_outputœ,œoutput_typesœ:[œDataœ]}",
        "target": "CustomComponent-J5dzH",
        "targetHandle": "{œfieldNameœ:œtrigger_dataœ,œidœ:œCustomComponent-J5dzHœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "trigger_data",
            "id": "CustomComponent-J5dzH",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "StructuredOutputComponent",
            "id": "StructuredOutputComponent-YApUs",
            "name": "structured_output",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-StructuredOutputComponent-YApUs{œdataTypeœ:œStructuredOutputComponentœ,œidœ:œStructuredOutputComponent-YApUsœ,œnameœ:œstructured_outputœ,œoutput_typesœ:[œDataœ]}-CustomComponent-J5dzH{œfieldNameœ:œtrigger_dataœ,œidœ:œCustomComponent-J5dzHœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "CustomComponent-J5dzH",
        "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-J5dzHœ,œnameœ:œcleared_statusœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-himFj",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-himFjœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-himFj",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-J5dzH",
            "name": "cleared_status",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-J5dzH{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-J5dzHœ,œnameœ:œcleared_statusœ,œoutput_typesœ:[œDataœ]}-ParseData-himFj{œfieldNameœ:œdataœ,œidœ:œParseData-himFjœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "ParseData-himFj",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-himFjœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-b0JqM",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-b0JqMœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "system_message",
            "id": "OpenAIModel-b0JqM",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-himFj",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-himFj{œdataTypeœ:œParseDataœ,œidœ:œParseData-himFjœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-b0JqM{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-b0JqMœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "StructuredOutputComponent-YApUs",
        "sourceHandle": "{œdataTypeœ:œStructuredOutputComponentœ,œidœ:œStructuredOutputComponent-YApUsœ,œnameœ:œstructured_outputœ,œoutput_typesœ:[œDataœ]}",
        "target": "CustomComponent-AJAcN",
        "targetHandle": "{œfieldNameœ:œsentiment_dataœ,œidœ:œCustomComponent-AJAcNœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "sentiment_data",
            "id": "CustomComponent-AJAcN",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "StructuredOutputComponent",
            "id": "StructuredOutputComponent-YApUs",
            "name": "structured_output",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-StructuredOutputComponent-YApUs{œdataTypeœ:œStructuredOutputComponentœ,œidœ:œStructuredOutputComponent-YApUsœ,œnameœ:œstructured_outputœ,œoutput_typesœ:[œDataœ]}-CustomComponent-AJAcN{œfieldNameœ:œsentiment_dataœ,œidœ:œCustomComponent-AJAcNœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "ParseData-LlMXM",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-LlMXMœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-AJAcN",
        "targetHandle": "{œfieldNameœ:œsearch_run_idœ,œidœ:œCustomComponent-AJAcNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "search_run_id",
            "id": "CustomComponent-AJAcN",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-LlMXM",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-LlMXM{œdataTypeœ:œParseDataœ,œidœ:œParseData-LlMXMœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-AJAcN{œfieldNameœ:œsearch_run_idœ,œidœ:œCustomComponent-AJAcNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "ParseData-6qzNm",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-6qzNmœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-IDP4D",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-IDP4Dœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-IDP4D",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-6qzNm",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-6qzNm{œdataTypeœ:œParseDataœ,œidœ:œParseData-6qzNmœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-IDP4D{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-IDP4Dœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "ParseData-6qzNm",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-6qzNmœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-b0JqM",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-b0JqMœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-b0JqM",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-6qzNm",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-6qzNm{œdataTypeœ:œParseDataœ,œidœ:œParseData-6qzNmœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-b0JqM{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-b0JqMœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "CustomComponent-kZxYb",
        "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-kZxYbœ,œnameœ:œsaved_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "CustomComponent-22zyT",
        "targetHandle": "{œfieldNameœ:œconfig_dataœ,œidœ:œCustomComponent-22zyTœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "config_data",
            "id": "CustomComponent-22zyT",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-kZxYb",
            "name": "saved_data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-kZxYb{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-kZxYbœ,œnameœ:œsaved_dataœ,œoutput_typesœ:[œDataœ]}-CustomComponent-22zyT{œfieldNameœ:œconfig_dataœ,œidœ:œCustomComponent-22zyTœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "CustomComponent-CYsb7",
        "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-CYsb7œ,œnameœ:œconfig_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "CustomComponent-2VOTD",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œCustomComponent-2VOTDœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_data",
            "id": "CustomComponent-2VOTD",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-CYsb7",
            "name": "config_data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-CYsb7{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-CYsb7œ,œnameœ:œconfig_dataœ,œoutput_typesœ:[œDataœ]}-CustomComponent-2VOTD{œfieldNameœ:œinput_dataœ,œidœ:œCustomComponent-2VOTDœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "CustomComponent-kZxYb",
        "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-kZxYbœ,œnameœ:œsaved_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-vEXGs",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-vEXGsœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-vEXGs",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-kZxYb",
            "name": "saved_data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-kZxYb{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-kZxYbœ,œnameœ:œsaved_dataœ,œoutput_typesœ:[œDataœ]}-ParseData-vEXGs{œfieldNameœ:œdataœ,œidœ:œParseData-vEXGsœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "Prompt-dLMFP",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-dLMFPœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "GroqModel-EFDIv",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œGroqModel-EFDIvœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "system_message",
            "id": "GroqModel-EFDIv",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-dLMFP",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-dLMFP{œdataTypeœ:œPromptœ,œidœ:œPrompt-dLMFPœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-GroqModel-EFDIv{œfieldNameœ:œsystem_messageœ,œidœ:œGroqModel-EFDIvœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "ParseData-Ia8kl",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-Ia8klœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-sniLH",
        "targetHandle": "{œfieldNameœ:œsearch_configœ,œidœ:œPrompt-sniLHœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "search_config",
            "id": "Prompt-sniLH",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-Ia8kl",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-Ia8kl{œdataTypeœ:œParseDataœ,œidœ:œParseData-Ia8klœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-sniLH{œfieldNameœ:œsearch_configœ,œidœ:œPrompt-sniLHœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "selected": false,
        "className": "",
        "animated": false
      },
      {
        "source": "OpenAIModel-b0JqM",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-b0JqMœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-so6Rv",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-so6Rvœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-so6Rv",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-b0JqM",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-b0JqM{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-b0JqMœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-so6Rv{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-so6Rvœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": "",
        "selected": false,
        "animated": false
      },
      {
        "source": "CustomComponent-2VOTD",
        "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-2VOTDœ,œnameœ:œurl_presentœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-6qzNm",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-6qzNmœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-6qzNm",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-2VOTD",
            "name": "url_present",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-2VOTD{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-2VOTDœ,œnameœ:œurl_presentœ,œoutput_typesœ:[œDataœ]}-ParseData-6qzNm{œfieldNameœ:œdataœ,œidœ:œParseData-6qzNmœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "selected": false,
        "animated": false
      },
      {
        "source": "CustomComponent-2VOTD",
        "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-2VOTDœ,œnameœ:œurl_absentœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-3O8KR",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-3O8KRœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-3O8KR",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-2VOTD",
            "name": "url_absent",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-2VOTD{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-2VOTDœ,œnameœ:œurl_absentœ,œoutput_typesœ:[œDataœ]}-ParseData-3O8KR{œfieldNameœ:œdataœ,œidœ:œParseData-3O8KRœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "selected": false,
        "animated": false
      },
      {
        "source": "CustomComponent-2VOTD",
        "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-2VOTDœ,œnameœ:œurl_presentœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-Ia8kl",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-Ia8klœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-Ia8kl",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-2VOTD",
            "name": "url_present",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-2VOTD{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-2VOTDœ,œnameœ:œurl_presentœ,œoutput_typesœ:[œDataœ]}-ParseData-Ia8kl{œfieldNameœ:œdataœ,œidœ:œParseData-Ia8klœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "selected": false,
        "animated": false
      },
      {
        "source": "CustomComponent-2VOTD",
        "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-2VOTDœ,œnameœ:œurl_presentœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-LlMXM",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-LlMXMœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-LlMXM",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-2VOTD",
            "name": "url_present",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CustomComponent-2VOTD{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-2VOTDœ,œnameœ:œurl_presentœ,œoutput_typesœ:[œDataœ]}-ParseData-LlMXM{œfieldNameœ:œdataœ,œidœ:œParseData-LlMXMœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "selected": false,
        "animated": false
      },
      {
        "source": "ParseData-3O8KR",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-3O8KRœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-5OXEm",
        "targetHandle": "{œfieldNameœ:œqueryœ,œidœ:œPrompt-5OXEmœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "query",
            "id": "Prompt-5OXEm",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-3O8KR",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-3O8KR{œdataTypeœ:œParseDataœ,œidœ:œParseData-3O8KRœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-5OXEm{œfieldNameœ:œqueryœ,œidœ:œPrompt-5OXEmœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "ParseData-3O8KR",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-3O8KRœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-xAiEq",
        "targetHandle": "{œfieldNameœ:œqueryœ,œidœ:œPrompt-xAiEqœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "query",
            "id": "Prompt-xAiEq",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-3O8KR",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-3O8KR{œdataTypeœ:œParseDataœ,œidœ:œParseData-3O8KRœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-xAiEq{œfieldNameœ:œqueryœ,œidœ:œPrompt-xAiEqœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "ParseData-3O8KR",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-3O8KRœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-sXSLK",
        "targetHandle": "{œfieldNameœ:œqueryœ,œidœ:œPrompt-sXSLKœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "query",
            "id": "Prompt-sXSLK",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-3O8KR",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-3O8KR{œdataTypeœ:œParseDataœ,œidœ:œParseData-3O8KRœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-sXSLK{œfieldNameœ:œqueryœ,œidœ:œPrompt-sXSLKœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "ParseData-3O8KR",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-3O8KRœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-L0LEg",
        "targetHandle": "{œfieldNameœ:œqueryœ,œidœ:œPrompt-L0LEgœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "query",
            "id": "Prompt-L0LEg",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-3O8KR",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-3O8KR{œdataTypeœ:œParseDataœ,œidœ:œParseData-3O8KRœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-L0LEg{œfieldNameœ:œqueryœ,œidœ:œPrompt-L0LEgœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "ParseData-3O8KR",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-3O8KRœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-z9f1V",
        "targetHandle": "{œfieldNameœ:œqueryœ,œidœ:œPrompt-z9f1Vœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "query",
            "id": "Prompt-z9f1V",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-3O8KR",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-3O8KR{œdataTypeœ:œParseDataœ,œidœ:œParseData-3O8KRœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-z9f1V{œfieldNameœ:œqueryœ,œidœ:œPrompt-z9f1Vœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "ParseData-3O8KR",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-3O8KRœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-kZxYb",
        "targetHandle": "{œfieldNameœ:œuser_queryœ,œidœ:œCustomComponent-kZxYbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "user_query",
            "id": "CustomComponent-kZxYb",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-3O8KR",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-3O8KR{œdataTypeœ:œParseDataœ,œidœ:œParseData-3O8KRœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-kZxYb{œfieldNameœ:œuser_queryœ,œidœ:œCustomComponent-kZxYbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "className": "",
        "animated": false
      }
    ],
    "viewport": {
      "x": -2712.76829085238,
      "y": -85.67416269242295,
      "zoom": 0.7422988788915975
    }
  },
  "icon_bg_color": null,
  "user_id": "9a72363d-c583-47c5-97e7-e65d3daa87c0",
  "gradient": null,
  "icon": null,
  "is_component": false,
  "tags": null,
  "updated_at": "2024-12-09T18:54:23+00:00",
  "folder_id": "54aad242-ee9a-4a53-960f-3fe4f6177497",
  "webhook": false
}