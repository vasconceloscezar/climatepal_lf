{
  "endpoint_name": "nasa-dataset-selector-02-1-1",
  "description": "Your Toolkit for Text Generation.",
  "id": "1cecff9d-0db7-4c8f-a807-ae301f84ab25",
  "name": "Dataset Retrieval - v1.0.4 (QUERY ONLY)",
  "data": {
    "nodes": [
      {
        "id": "ChatInput-yzRsT",
        "type": "genericNode",
        "position": {
          "x": 1136.0836818107007,
          "y": -1476.8237613939023
        },
        "data": {
          "id": "ChatInput-yzRsT",
          "node": {
            "template": {
              "_type": "Component",
              "files": {
                "trace_as_metadata": true,
                "file_path": "",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "files",
                "value": "",
                "display_name": "Files",
                "advanced": true,
                "dynamic": false,
                "info": "Files to be sent with the message.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput"
              },
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_USER, MESSAGE_SENDER_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        _background_color = self.background_color\n        _text_color = self.text_color\n        _icon = self.chat_icon\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\"background_color\": _background_color, \"text_color\": _text_color, \"icon\": _icon},\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "Provide all the times Ames, Iowa had over 50 frost days from 1980 to 2014 in a historical simulation.",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "User",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Get chat inputs from the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Dataset Description",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "ChatInput",
          "description": "Get chat inputs from the Playground.",
          "display_name": "Dataset Description"
        },
        "selected": false,
        "width": 320,
        "height": 231,
        "positionAbsolute": {
          "x": 1136.0836818107007,
          "y": -1476.8237613939023
        },
        "dragging": false
      },
      {
        "id": "CMIP6DatasetProcessorComponent-Ce7RN",
        "type": "genericNode",
        "position": {
          "x": 2135.035516520518,
          "y": -2749.5015248796835
        },
        "data": {
          "type": "CMIP6DatasetProcessorComponent",
          "node": {
            "template": {
              "_type": "Component",
              "csv_file": {
                "trace_as_metadata": true,
                "file_path": "1cecff9d-0db7-4c8f-a807-ae301f84ab25/2025-03-04_18-26-01_model_experiment_fields_ScenarioMIP_CMIP_filename_dates (1).csv",
                "fileTypes": [
                  "csv"
                ],
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "csv_file",
                "value": "",
                "display_name": "CSV File",
                "advanced": false,
                "dynamic": false,
                "info": "Upload the CSV file containing CMIP6 dataset information.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput",
                "load_from_db": false
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import pandas as pd\r\nimport numpy as np\r\nfrom pathlib import Path\r\nfrom langflow.custom import Component\r\nfrom langflow.io import FileInput, MessageTextInput, Output\r\nfrom langflow.schema.data import Data\r\n\r\nclass CMIP6DatasetProcessorComponent(Component):\r\n    display_name = \"CMIP6 Dataset Processor\"\r\n    description = \"Process a CSV file containing CMIP6 dataset information into a usable DataFrame.\"\r\n    icon = \"table\"\r\n    \r\n    inputs = [\r\n        FileInput(\r\n            name=\"csv_file\",\r\n            display_name=\"CSV File\",\r\n            file_types=[\"csv\"],\r\n            info=\"Upload the CSV file containing CMIP6 dataset information.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"csv_path\",\r\n            display_name=\"CSV File Path\",\r\n            info=\"Provide the path to the CSV file as pure text\",\r\n        ),\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(display_name=\"Processed DataFrame\", name=\"processed_df\", method=\"process_csv\"),\r\n        Output(display_name=\"Unique MIPs\", name=\"unique_mips\", method=\"get_unique_mips\"),\r\n        Output(display_name=\"Unique Experiments\", name=\"unique_experiments\", method=\"get_unique_experiments\"),\r\n    ]\r\n\r\n    def _process_dataframe(self):\r\n        \"\"\"Helper method to process the dataframe and cache it for multiple outputs\"\"\"\r\n        if not hasattr(self, '_cached_df'):\r\n            if sum(bool(field) for field in [self.csv_file, self.csv_path]) != 1:\r\n                raise ValueError(\"Please provide exactly one of: CSV file or file path.\")\r\n            \r\n            try:\r\n                # Read the CSV file based on input type\r\n                if self.csv_file:\r\n                    df = pd.read_csv(self.csv_file)\r\n                else:\r\n                    if not Path(self.csv_path).exists():\r\n                        raise FileNotFoundError(f\"File not found: {self.csv_path}\")\r\n                    df = pd.read_csv(self.csv_path)\r\n                \r\n                # Process the DataFrame as before\r\n                df['collection'] = 'giss_cmip6'\r\n                df['org'] = 'NASA-GISS'\r\n                \r\n                # Select and rename columns\r\n                df = df[['collection', 'MIP', 'org', 'model', 'experiment', 'variant', \r\n                         'tableID', 'variable', 'grid', 'version', 'start_YM', 'end_YM', 'filename']]\r\n                df.columns = ['collection', 'MIP', 'org', 'model', 'experiment', 'variant', \r\n                             'temporal resolution', 'variable', 'grid', 'version', 'start year', 'end year', 'filename']\r\n                \r\n                # Rest of the processing...\r\n                df = df.astype(str)\r\n                \r\n                def generate_url(x):\r\n                    cols = '/'.join([val for val in x])\r\n                    return 'https://portal.nccs.nasa.gov/datashare/' + cols\r\n                \r\n                url_col_names = df.columns[:-3].to_list() + ['filename']\r\n                urldf = df[url_col_names]\r\n                df['URL'] = urldf.apply(lambda x: generate_url(x), axis=1)\r\n                \r\n                def safe_year_convert(x):\r\n                    try:\r\n                        return int(x[:4])\r\n                    except ValueError:\r\n                        return np.nan\r\n                \r\n                df['start year'] = df['start year'].apply(safe_year_convert)\r\n                df['end year'] = df['end year'].apply(safe_year_convert)\r\n                \r\n                df = df.sort_values(df.columns.to_list(), ascending=True).drop_duplicates(\r\n                    subset=set(df.columns.to_list()) - set(['version', 'filename', 'URL']),\r\n                    ignore_index=True, keep='last')\r\n                \r\n                def clean_resolution(reso):\r\n                    resos = ['hr', 'day', 'mon']\r\n                    for q in resos:\r\n                        if q in reso:\r\n                            return q\r\n                    return 'NA'\r\n                \r\n                df['temporal resolution'] = df.apply(lambda x: clean_resolution(x['temporal resolution']), axis=1)\r\n                \r\n                self._cached_df = df\r\n                \r\n            except Exception as e:\r\n                raise ValueError(f\"Error processing CSV: {str(e)}\")\r\n        \r\n        return self._cached_df\r\n\r\n    def process_csv(self) -> Data:\r\n        try:\r\n            df = self._process_dataframe()\r\n            self.status = f\"DataFrame processed successfully. Shape: {df.shape}\"\r\n            return Data(data={\"df\": df})\r\n        except Exception as e:\r\n            error_message = f\"Error processing CSV: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})\r\n\r\n    def get_unique_mips(self) -> list[Data]:\r\n        \"\"\"Return a list of Data objects containing unique MIP values\"\"\"\r\n        try:\r\n            df = self._process_dataframe()\r\n            unique_mips = df['MIP'].unique().tolist()\r\n            return [Data(data={\"MIP\": mip}) for mip in sorted(unique_mips)]\r\n        except Exception as e:\r\n            error_message = f\"Error getting unique MIPs: {str(e)}\"\r\n            self.status = error_message\r\n            return [Data(data={\"error\": error_message})]\r\n\r\n    def get_unique_experiments(self) -> list[Data]:\r\n        \"\"\"Return a list of Data objects containing unique experiment values\"\"\"\r\n        try:\r\n            df = self._process_dataframe()\r\n            unique_experiments = df['experiment'].unique().tolist()\r\n            return [Data(data={\"experiment\": exp}) for exp in sorted(unique_experiments)]\r\n        except Exception as e:\r\n            error_message = f\"Error getting unique experiments: {str(e)}\"\r\n            self.status = error_message\r\n            return [Data(data={\"error\": error_message})]",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "csv_path": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "csv_path",
                "value": "",
                "display_name": "CSV File Path",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Provide the path to the CSV file as pure text",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Process a CSV file containing CMIP6 dataset information into a usable DataFrame.",
            "icon": "table",
            "base_classes": [
              "Data"
            ],
            "display_name": "CMIP6 Dataset Processor",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": true,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "processed_df",
                "display_name": "Processed DataFrame",
                "method": "process_csv",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "unique_mips",
                "display_name": "Unique MIPs",
                "method": "get_unique_mips",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "unique_experiments",
                "display_name": "Unique Experiments",
                "method": "get_unique_experiments",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "csv_file",
              "csv_path"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.1.1"
          },
          "id": "CMIP6DatasetProcessorComponent-Ce7RN"
        },
        "selected": false,
        "width": 320,
        "height": 432,
        "dragging": false,
        "positionAbsolute": {
          "x": 2135.035516520518,
          "y": -2749.5015248796835
        }
      },
      {
        "id": "CMIP6VariableProcessorFromZip-owuWY",
        "type": "genericNode",
        "position": {
          "x": 3249.743385806226,
          "y": -2877.5011036218298
        },
        "data": {
          "type": "CMIP6VariableProcessorFromZip",
          "node": {
            "template": {
              "_type": "Component",
              "dataset_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dataset_info",
                "value": "",
                "display_name": "Dataset Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Processed CMIP6 dataset information for filtering variables.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "embeddings": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embeddings",
                "value": "",
                "display_name": "Embeddings",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "Embeddings component for generating embeddings.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "zip_file": {
                "trace_as_metadata": true,
                "file_path": "1cecff9d-0db7-4c8f-a807-ae301f84ab25/2025-03-04_18-25-44_cmip6-cmor-tables-main.zip",
                "fileTypes": [
                  "zip"
                ],
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "zip_file",
                "value": "",
                "display_name": "Zip File",
                "advanced": false,
                "dynamic": false,
                "info": "Upload a zip file containing CMIP6 JSON files.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput",
                "load_from_db": false
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import zipfile\r\nimport json\r\nimport pandas as pd\r\nimport numpy as np\r\nfrom pathlib import Path\r\nfrom langflow.custom import Component\r\nfrom langflow.io import FileInput, HandleInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass CMIP6VariableProcessorFromZip(Component):\r\n    display_name = \"CMIP6 Variable Processor (Zip)\"\r\n    description = \"Processes CMIP6 variable information JSON files from a zip file and generates embeddings.\"\r\n    icon = \"file-zip\"\r\n    \r\n    inputs = [\r\n        FileInput(\r\n            name=\"zip_file\",\r\n            display_name=\"Zip File\",\r\n            file_types=[\"zip\"],\r\n            info=\"Upload a zip file containing CMIP6 JSON files.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"zip_path\",\r\n            display_name=\"Zip File Path\",\r\n            info=\"Provide the path to the zip file as pure text\",\r\n        ),\r\n        HandleInput(\r\n            name=\"dataset_info\",\r\n            display_name=\"Dataset Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Processed CMIP6 dataset information for filtering variables.\",\r\n        ),\r\n        HandleInput(\r\n            name=\"embeddings\",\r\n            display_name=\"Embeddings\",\r\n            input_types=[\"Embeddings\"],\r\n            info=\"Embeddings component for generating embeddings.\",\r\n        ),\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(display_name=\"CMIP6 Variable Info\", name=\"variable_info\", method=\"process_zip_file\"),\r\n    ]\r\n\r\n    def process_zip_file(self) -> Data:\r\n        # Validate inputs\r\n        if sum(bool(field) for field in [self.zip_file, self.zip_path]) != 1:\r\n            raise ValueError(\"Please provide exactly one of: zip file or file path.\")\r\n\r\n        try:\r\n            # Get the correct file path\r\n            if self.zip_file:\r\n                file_path = self.resolve_path(self.zip_file)\r\n            else:\r\n                file_path = self.zip_path\r\n                if not Path(file_path).exists():\r\n                    raise FileNotFoundError(f\"File not found: {file_path}\")\r\n\r\n            # Process the zip file\r\n            jdfs = []\r\n            with zipfile.ZipFile(file_path, 'r') as zip_ref:\r\n                for file_name in zip_ref.namelist():\r\n                    if file_name.endswith('.json') and 'Tables' in file_name:\r\n                        self.log(f\"Processing file: {file_name}\")\r\n                        with zip_ref.open(file_name) as file:\r\n                            content = file.read()\r\n                            d = json.loads(content.decode('utf-8'))\r\n                            try:\r\n                                jdf = pd.DataFrame.from_dict(d['variable_entry'], orient='index')\r\n                                jdf['temporal resolution'] = file_name.split('_')[-1].split('.')[0]\r\n                                jdfs.append(jdf)\r\n                            except KeyError:\r\n                                self.log(f\"Skipping {file_name} due to formatting issue\")\r\n\r\n            if not jdfs:\r\n                raise ValueError(\"No valid JSON files were found in the zip file\")\r\n\r\n            # Create the combined DataFrame\r\n            varsdf = pd.concat(jdfs)\r\n            varsdf.rename(columns={'out_name': 'variable'}, inplace=True)\r\n            varsdf = varsdf.loc[:, ['long_name', 'comment', 'variable']]\r\n            varsdf.drop_duplicates(inplace=True)\r\n            \r\n            # Create extended comment\r\n            varsdf['extended_comment'] = varsdf.apply(\r\n                lambda x: f\"{x['long_name']} ({x['variable']}): {x['comment']}\", \r\n                axis=1\r\n            )\r\n            \r\n            # Filter variables based on the dataset_info\r\n            if isinstance(self.dataset_info, Data) and 'df' in self.dataset_info.data:\r\n                df = pd.DataFrame(self.dataset_info.data['df'])\r\n                varsdf = varsdf[varsdf['variable'].isin(df['variable'].unique())]\r\n            else:\r\n                self.log(\"Warning: No dataset info provided for filtering variables.\")\r\n\r\n            # Generate embeddings\r\n            varsdf.loc[varsdf['extended_comment'].isna(), 'extended_comment'] = ''\r\n            varsdf['embeds'] = list(np.asarray(\r\n                self.embeddings.embed_documents(varsdf['extended_comment'].tolist())\r\n            ))\r\n\r\n            self.status = f\"Variable info processed and embeddings generated successfully. Shape: {varsdf.shape}\"\r\n            return Data(data={\"variable_info\": varsdf})\r\n\r\n        except Exception as e:\r\n            error_message = f\"Error processing zip file or generating embeddings: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "zip_path": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "zip_path",
                "value": "",
                "display_name": "Zip File Path",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Provide the path to the zip file as pure text",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Processes CMIP6 variable information JSON files from a zip file and generates embeddings.",
            "icon": "file-zip",
            "base_classes": [
              "Data"
            ],
            "display_name": "CMIP6 Variable Processor (Zip)",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": true,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "variable_info",
                "display_name": "CMIP6 Variable Info",
                "method": "process_zip_file",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "zip_file",
              "zip_path",
              "dataset_info",
              "embeddings"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.1.1"
          },
          "id": "CMIP6VariableProcessorFromZip-owuWY"
        },
        "selected": false,
        "width": 320,
        "height": 366,
        "positionAbsolute": {
          "x": 3249.743385806226,
          "y": -2877.5011036218298
        },
        "dragging": false
      },
      {
        "id": "variable_matcher-Fdn7i",
        "type": "genericNode",
        "position": {
          "x": 5643.319471179704,
          "y": -1459.7994934350872
        },
        "data": {
          "type": "variable_matcher",
          "node": {
            "template": {
              "_type": "Component",
              "variable_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "variable_info",
                "value": "",
                "display_name": "Variable Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Processed CMIP6 variable information from the previous component.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import List, Dict, Any\r\nfrom pydantic import BaseModel, Field\r\nimport pandas as pd\r\n\r\nfrom langflow.base.langchain_utilities.model import LCToolComponent\r\nfrom langflow.io import HandleInput, MessageTextInput, IntInput, Output\r\nfrom langflow.schema import Data\r\nfrom langflow.field_typing import Tool\r\nfrom langchain.tools import StructuredTool\r\n\r\nclass VariableMatcherToolComponent(LCToolComponent):\r\n    display_name = \"CMIP6 Variable Matcher\"\r\n    description = \"Filters CMIP6 variables based on exact variable name matches.\"\r\n    icon = \"match\"\r\n    name = \"variable_matcher\"\r\n    \r\n    inputs = [\r\n        HandleInput(\r\n            name=\"variable_info\",\r\n            display_name=\"Variable Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Processed CMIP6 variable information from the previous component.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"variable_name\",\r\n            display_name=\"Variable Name\",\r\n            info=\"The exact variable name to filter for (e.g., 'tas').\",\r\n        ),\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(display_name=\"Matched Variables\", name=\"matched_variables\", method=\"match_variables\"),\r\n        Output(display_name=\"Tool\", name=\"tool\", method=\"build_tool\"),\r\n    ]\r\n\r\n    class VariableMatcherSchema(BaseModel):\r\n        variable_name: str = Field(\r\n            ..., \r\n            description=\"The exact variable name to filter for (e.g., 'tas')\"\r\n        )\r\n\r\n    def _process_matches(self, variable_name: str) -> List[Dict[str, Any]]:\r\n        \"\"\"Internal method to filter variables by exact name match\"\"\"\r\n        if not isinstance(self.variable_info, Data) or 'variable_info' not in self.variable_info.data:\r\n            raise ValueError(\"Invalid variable info input. Expected Data object with 'variable_info' key.\")\r\n        \r\n        varsdf = self.variable_info.data['variable_info']\r\n        \r\n        try:\r\n            # Filter for exact matches\r\n            filtered_df = varsdf[varsdf['variable'].str.lower() == variable_name.lower()]\r\n            \r\n            if filtered_df.empty:\r\n                return [{\"message\": f\"No matches found for variable '{variable_name}'\"}]\r\n            \r\n            # Convert results to list of dictionaries\r\n            results = [\r\n                {\r\n                    'variable': row['variable'],\r\n                    'long_name': row['long_name'],\r\n                    'comment': row['comment'],\r\n                }\r\n                for _, row in filtered_df.iterrows()\r\n            ]\r\n            \r\n            return results\r\n\r\n        except Exception as e:\r\n            return [{\"error\": f\"Error filtering variables: {str(e)}\"}]\r\n\r\n    def match_variables(self) -> List[Data]:\r\n        \"\"\"Method for component output\"\"\"\r\n        try:\r\n            results = self._process_matches(self.variable_name)\r\n            data_list = [Data(data=result) for result in results]\r\n            self.status = data_list\r\n            return data_list\r\n            \r\n        except Exception as e:\r\n            error_message = f\"Error matching variables: {str(e)}\"\r\n            self.status = error_message\r\n            return [Data(data={\"error\": error_message})]\r\n\r\n    def build_tool(self) -> Tool:\r\n        \"\"\"Build and return the tool\"\"\"\r\n        return StructuredTool.from_function(\r\n            name=\"variable_matcher\",\r\n            description=\"Filter CMIP6 variables by exact variable name match. \"\r\n                      \"Input should be the exact variable name (e.g., 'tas').\",\r\n            func=self._tool_function,\r\n            args_schema=self.VariableMatcherSchema,\r\n        )\r\n\r\n    def _tool_function(self, variable_name: str) -> List[Dict[str, Any]]:\r\n        \"\"\"Function to be called by the tool\"\"\"\r\n        try:\r\n            return self._process_matches(variable_name)\r\n        except Exception as e:\r\n            return [{\"error\": f\"Error matching variables: {str(e)}\"}]",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "variable_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "variable_name",
                "value": "",
                "display_name": "Variable Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The exact variable name to filter for (e.g., 'tas').",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Filters CMIP6 variables based on exact variable name matches.",
            "icon": "match",
            "base_classes": [
              "Data",
              "Tool"
            ],
            "display_name": "CMIP6 Variable Matcher",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "matched_variables",
                "display_name": "Matched Variables",
                "method": "match_variables",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              }
            ],
            "field_order": [
              "variable_info",
              "variable_name"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.1.1"
          },
          "id": "variable_matcher-Fdn7i"
        },
        "selected": false,
        "width": 320,
        "height": 300,
        "dragging": false,
        "positionAbsolute": {
          "x": 5643.319471179704,
          "y": -1459.7994934350872
        }
      },
      {
        "id": "OpenAIEmbeddings-RdeOk",
        "type": "genericNode",
        "position": {
          "x": 2888.1600442024533,
          "y": -2819.285701514933
        },
        "data": {
          "type": "OpenAIEmbeddings",
          "node": {
            "template": {
              "_type": "Component",
              "chunk_size": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_size",
                "value": 1000,
                "display_name": "Chunk Size",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "client": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "client",
                "value": "",
                "display_name": "Client",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_openai import OpenAIEmbeddings\n\nfrom langflow.base.embeddings.model import LCEmbeddingsModel\nfrom langflow.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass OpenAIEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIEmbeddings\"\n\n    inputs = [\n        DictInput(\n            name=\"default_headers\",\n            display_name=\"Default Headers\",\n            advanced=True,\n            info=\"Default headers to use for the API request.\",\n        ),\n        DictInput(\n            name=\"default_query\",\n            display_name=\"Default Query\",\n            advanced=True,\n            info=\"Default query parameters to use for the API request.\",\n        ),\n        IntInput(name=\"chunk_size\", display_name=\"Chunk Size\", advanced=True, value=1000),\n        MessageTextInput(name=\"client\", display_name=\"Client\", advanced=True),\n        MessageTextInput(name=\"deployment\", display_name=\"Deployment\", advanced=True),\n        IntInput(name=\"embedding_ctx_length\", display_name=\"Embedding Context Length\", advanced=True, value=1536),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=\"text-embedding-3-small\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\"),\n        MessageTextInput(name=\"openai_api_base\", display_name=\"OpenAI API Base\", advanced=True),\n        MessageTextInput(name=\"openai_api_type\", display_name=\"OpenAI API Type\", advanced=True),\n        MessageTextInput(name=\"openai_api_version\", display_name=\"OpenAI API Version\", advanced=True),\n        MessageTextInput(\n            name=\"openai_organization\",\n            display_name=\"OpenAI Organization\",\n            advanced=True,\n        ),\n        MessageTextInput(name=\"openai_proxy\", display_name=\"OpenAI Proxy\", advanced=True),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n        BoolInput(name=\"show_progress_bar\", display_name=\"Show Progress Bar\", advanced=True),\n        BoolInput(name=\"skip_empty\", display_name=\"Skip Empty\", advanced=True),\n        MessageTextInput(\n            name=\"tiktoken_model_name\",\n            display_name=\"TikToken Model Name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tiktoken_enable\",\n            display_name=\"TikToken Enable\",\n            advanced=True,\n            value=True,\n            info=\"If False, you must have transformers installed.\",\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. \"\n            \"Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return OpenAIEmbeddings(\n            client=self.client or None,\n            model=self.model,\n            dimensions=self.dimensions or None,\n            deployment=self.deployment or None,\n            api_version=self.openai_api_version or None,\n            base_url=self.openai_api_base or None,\n            openai_api_type=self.openai_api_type or None,\n            openai_proxy=self.openai_proxy or None,\n            embedding_ctx_length=self.embedding_ctx_length,\n            api_key=self.openai_api_key or None,\n            organization=self.openai_organization or None,\n            allowed_special=\"all\",\n            disallowed_special=\"all\",\n            chunk_size=self.chunk_size,\n            max_retries=self.max_retries,\n            timeout=self.request_timeout or None,\n            tiktoken_enabled=self.tiktoken_enable,\n            tiktoken_model_name=self.tiktoken_model_name or None,\n            show_progress_bar=self.show_progress_bar,\n            model_kwargs=self.model_kwargs,\n            skip_empty=self.skip_empty,\n            default_headers=self.default_headers or None,\n            default_query=self.default_query or None,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "default_headers": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "default_headers",
                "value": {},
                "display_name": "Default Headers",
                "advanced": true,
                "dynamic": false,
                "info": "Default headers to use for the API request.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "default_query": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "default_query",
                "value": {},
                "display_name": "Default Query",
                "advanced": true,
                "dynamic": false,
                "info": "Default query parameters to use for the API request.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "deployment": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "deployment",
                "value": "",
                "display_name": "Deployment",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "dimensions": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dimensions",
                "value": "",
                "display_name": "Dimensions",
                "advanced": true,
                "dynamic": false,
                "info": "The number of dimensions the resulting output embeddings should have. Only supported by certain models.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "embedding_ctx_length": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embedding_ctx_length",
                "value": 1536,
                "display_name": "Embedding Context Length",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "max_retries": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_retries",
                "value": 3,
                "display_name": "Max Retries",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "text-embedding-3-small",
                  "text-embedding-3-large",
                  "text-embedding-ada-002"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "text-embedding-3-large",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "openai_api_base": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_key",
                "value": "OPENAI_API_KEY",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "openai_api_type": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_type",
                "value": "",
                "display_name": "OpenAI API Type",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_api_version": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_version",
                "value": "",
                "display_name": "OpenAI API Version",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_organization": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_organization",
                "value": "",
                "display_name": "OpenAI Organization",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_proxy": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_proxy",
                "value": "",
                "display_name": "OpenAI Proxy",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "request_timeout": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "request_timeout",
                "value": "",
                "display_name": "Request Timeout",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "show_progress_bar": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "show_progress_bar",
                "value": false,
                "display_name": "Show Progress Bar",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "skip_empty": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "skip_empty",
                "value": false,
                "display_name": "Skip Empty",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "tiktoken_enable": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tiktoken_enable",
                "value": true,
                "display_name": "TikToken Enable",
                "advanced": true,
                "dynamic": false,
                "info": "If False, you must have transformers installed.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "tiktoken_model_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tiktoken_model_name",
                "value": "",
                "display_name": "TikToken Model Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Generate embeddings using OpenAI models.",
            "icon": "OpenAI",
            "base_classes": [
              "Embeddings"
            ],
            "display_name": "OpenAI Embeddings",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": true,
            "outputs": [
              {
                "types": [
                  "Embeddings"
                ],
                "selected": "Embeddings",
                "name": "embeddings",
                "display_name": "Embeddings",
                "method": "build_embeddings",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              }
            ],
            "field_order": [
              "default_headers",
              "default_query",
              "chunk_size",
              "client",
              "deployment",
              "embedding_ctx_length",
              "max_retries",
              "model",
              "model_kwargs",
              "openai_api_key",
              "openai_api_base",
              "openai_api_type",
              "openai_api_version",
              "openai_organization",
              "openai_proxy",
              "request_timeout",
              "show_progress_bar",
              "skip_empty",
              "tiktoken_model_name",
              "tiktoken_enable",
              "dimensions"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "id": "OpenAIEmbeddings-RdeOk",
          "description": "Generate embeddings using OpenAI models.",
          "display_name": "OpenAI Embeddings"
        },
        "selected": false,
        "width": 320,
        "height": 318,
        "dragging": false,
        "positionAbsolute": {
          "x": 2888.1600442024533,
          "y": -2819.285701514933
        }
      },
      {
        "id": "TemporalResolutionFilterComponent-tc5z8",
        "type": "genericNode",
        "position": {
          "x": 6114.570741928117,
          "y": -1225.2071671185627
        },
        "data": {
          "type": "TemporalResolutionFilterComponent",
          "node": {
            "template": {
              "_type": "Component",
              "dataset_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dataset_info",
                "value": "",
                "display_name": "Dataset Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Processed CMIP6 dataset information from the CMIP6 Dataset Processor.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "matched_variables": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "matched_variables",
                "value": "",
                "display_name": "Matched Variables",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Matched variables from the CMIP6 Variable Matcher.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\r\nfrom langflow.io import HandleInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass TemporalResolutionFilterComponent(Component):\r\n    display_name = \"Temporal Resolution Filter\"\r\n    description = \"Filters CMIP6 datasets based on temporal resolution and matched variables.\"\r\n    icon = \"filter\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"dataset_info\",\r\n            display_name=\"Dataset Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Processed CMIP6 dataset information from the CMIP6 Dataset Processor.\",\r\n        ),\r\n        HandleInput(\r\n            name=\"matched_variables\",\r\n            display_name=\"Matched Variables\",\r\n            input_types=[\"Data\"],\r\n            info=\"Matched variables from the CMIP6 Variable Matcher.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"resolution\",\r\n            display_name=\"Temporal Resolution\",\r\n            info=\"Enter the desired temporal resolution (e.g., hr, day, mon, fx).\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Filtered Datasets\", name=\"filtered_datasets\", method=\"filter_datasets\"),\r\n    ]\r\n\r\n    def filter_datasets(self) -> Data:\r\n        if not isinstance(self.dataset_info, Data) or 'df' not in self.dataset_info.data:\r\n            raise ValueError(\"Invalid dataset info input. Expected Data object with 'df' key.\")\r\n\r\n        if not isinstance(self.matched_variables, list) or not all(isinstance(x, Data) for x in self.matched_variables):\r\n            raise ValueError(\"Invalid matched variables input. Expected list of Data objects.\")\r\n\r\n        df = self.dataset_info.data['df']\r\n\r\n        if 'temporal resolution' not in df.columns or 'variable' not in df.columns:\r\n            raise ValueError(\"Expected 'temporal resolution' and 'variable' columns in dataset info DataFrame.\")\r\n\r\n        try:\r\n            resolution = self.resolution.strip().lower()\r\n            \r\n            # Get the list of matched variable names\r\n            matched_var_names = [v.data['variable'] for v in self.matched_variables if 'variable' in v.data]\r\n            \r\n            # Filter the dataset\r\n            filtered_df = df[\r\n                (df['temporal resolution'] == resolution) &\r\n                (df['variable'].isin(matched_var_names))\r\n            ]\r\n            \r\n            self.status = f\"Filtered {len(filtered_df)} datasets with {resolution} temporal resolution and matching variables.\"\r\n            return Data(data={\"filtered_df\": filtered_df})\r\n\r\n        except Exception as e:\r\n            error_message = f\"Error filtering datasets: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "resolution": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "resolution",
                "value": "",
                "display_name": "Temporal Resolution",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the desired temporal resolution (e.g., hr, day, mon, fx).",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Filters CMIP6 datasets based on temporal resolution and matched variables.",
            "icon": "filter",
            "base_classes": [
              "Data"
            ],
            "display_name": "Temporal Resolution Filter",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "filtered_datasets",
                "display_name": "Filtered Datasets",
                "method": "filter_datasets",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "dataset_info",
              "matched_variables",
              "resolution"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.1.1"
          },
          "id": "TemporalResolutionFilterComponent-tc5z8"
        },
        "selected": false,
        "width": 320,
        "height": 348,
        "dragging": false,
        "positionAbsolute": {
          "x": 6114.570741928117,
          "y": -1225.2071671185627
        }
      },
      {
        "id": "YearRangeFilterComponent-veOZo",
        "type": "genericNode",
        "position": {
          "x": 6572.064522169262,
          "y": -1009.1006848302384
        },
        "data": {
          "type": "YearRangeFilterComponent",
          "node": {
            "template": {
              "_type": "Component",
              "dataset_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dataset_info",
                "value": "",
                "display_name": "Dataset Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Processed CMIP6 dataset information from the previous filter.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\r\nfrom langflow.io import HandleInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass YearRangeFilterComponent(Component):\r\n    display_name = \"Year Range Filter\"\r\n    description = \"Filters CMIP6 datasets based on a specified year range.\"\r\n    icon = \"calendar\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"dataset_info\",\r\n            display_name=\"Dataset Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Processed CMIP6 dataset information from the previous filter.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"year_range\",\r\n            display_name=\"Year Range\",\r\n            info=\"The year range for filtering (format: START-END, e.g., '1980-2014' or '1000-NA' or 'NA-2100').\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Filtered Datasets\", name=\"filtered_datasets\", method=\"filter_datasets\"),\r\n    ]\r\n\r\n    def parse_year_range(self, year_range: str):\r\n        start, end = year_range.split('-')\r\n        start = int(start) if start.lower() != 'na' else None\r\n        end = int(end) if end.lower() != 'na' else None\r\n        return start, end\r\n\r\n    def filter_datasets(self) -> Data:\r\n        if not isinstance(self.dataset_info, Data) or 'filtered_df' not in self.dataset_info.data:\r\n            raise ValueError(\"Invalid dataset info input. Expected Data object with 'filtered_df' key.\")\r\n\r\n        df = self.dataset_info.data['filtered_df']\r\n\r\n        if 'start year' not in df.columns or 'end year' not in df.columns:\r\n            raise ValueError(\"Expected 'start year' and 'end year' columns in dataset info DataFrame.\")\r\n\r\n        try:\r\n            start_year, end_year = self.parse_year_range(self.year_range.strip())\r\n            \r\n            if start_year is not None:\r\n                df = df[df['end year'] >= start_year]\r\n            if end_year is not None:\r\n                df = df[df['start year'] <= end_year]\r\n            \r\n            year_range_str = f\"{start_year if start_year else 'NA'}-{end_year if end_year else 'NA'}\"\r\n            self.status = f\"Filtered datasets within the year range {year_range_str}. {len(df)} datasets remain.\"\r\n            return Data(data={\"filtered_df\": df})\r\n\r\n        except ValueError:\r\n            error_message = \"Invalid year range input. Please enter a valid range (e.g., '1980-2014' or '1000-NA' or 'NA-2100').\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})\r\n        except Exception as e:\r\n            error_message = f\"Error filtering datasets: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "year_range": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "year_range",
                "value": "",
                "display_name": "Year Range",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The year range for filtering (format: START-END, e.g., '1980-2014' or '1000-NA' or 'NA-2100').",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Filters CMIP6 datasets based on a specified year range.",
            "icon": "calendar",
            "base_classes": [
              "Data"
            ],
            "display_name": "Year Range Filter",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "filtered_datasets",
                "display_name": "Filtered Datasets",
                "method": "filter_datasets",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "dataset_info",
              "year_range"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.1.1"
          },
          "id": "YearRangeFilterComponent-veOZo"
        },
        "selected": false,
        "width": 320,
        "height": 300,
        "dragging": false,
        "positionAbsolute": {
          "x": 6572.064522169262,
          "y": -1009.1006848302384
        }
      },
      {
        "id": "URLExtractorComponent-8YWrk",
        "type": "genericNode",
        "position": {
          "x": 6990.787869759375,
          "y": -749.5272132244486
        },
        "data": {
          "type": "URLExtractorComponent",
          "node": {
            "template": {
              "_type": "Component",
              "dataset_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dataset_info",
                "value": "",
                "display_name": "Filtered Dataset Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Filtered CMIP6 dataset information from the previous filters.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\r\nfrom langflow.io import HandleInput, IntInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass URLExtractorComponent(Component):\r\n    display_name = \"URL Extractor\"\r\n    description = \"Extracts URLs from filtered CMIP6 datasets.\"\r\n    icon = \"link\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"dataset_info\",\r\n            display_name=\"Filtered Dataset Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Filtered CMIP6 dataset information from the previous filters.\",\r\n        ),\r\n        IntInput(\r\n            name=\"max_urls\",\r\n            display_name=\"Maximum URLs\",\r\n            info=\"Maximum number of URLs to extract (0 for all).\",\r\n            value=5,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Extracted URLs\", name=\"extracted_urls\", method=\"extract_urls\"),\r\n    ]\r\n\r\n    def extract_urls(self) -> Data:\r\n        if not isinstance(self.dataset_info, Data) or 'filtered_df' not in self.dataset_info.data:\r\n            raise ValueError(\"Invalid dataset info input. Expected Data object with 'filtered_df' key.\")\r\n\r\n        df = self.dataset_info.data['filtered_df']\r\n\r\n        if 'URL' not in df.columns:\r\n            raise ValueError(\"Expected 'URL' column in dataset info DataFrame.\")\r\n\r\n        try:\r\n            if self.max_urls > 0:\r\n                urls = df['URL'].head(self.max_urls).tolist()\r\n            else:\r\n                urls = df['URL'].tolist()\r\n\r\n            result = []\r\n            for i, url in enumerate(urls, 1):\r\n                result.append(Data(data={\r\n                    \"url\": url,\r\n                    \"index\": i,\r\n                    \"filename\": url.split('/')[-1]\r\n                }))\r\n\r\n            self.status = result\r\n            return result\r\n\r\n        except Exception as e:\r\n            error_message = f\"Error extracting URLs: {str(e)}\"\r\n            self.status = error_message\r\n            return [Data(data={\"error\": error_message})]",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "max_urls": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_urls",
                "value": 1,
                "display_name": "Maximum URLs",
                "advanced": false,
                "dynamic": false,
                "info": "Maximum number of URLs to extract (0 for all).",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput",
                "load_from_db": false
              }
            },
            "description": "Extracts URLs from filtered CMIP6 datasets.",
            "icon": "link",
            "base_classes": [
              "Data"
            ],
            "display_name": "URL Extractor",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "extracted_urls",
                "display_name": "Extracted URLs",
                "method": "extract_urls",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "dataset_info",
              "max_urls"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.1.1"
          },
          "id": "URLExtractorComponent-8YWrk"
        },
        "selected": false,
        "width": 320,
        "height": 279,
        "positionAbsolute": {
          "x": 6990.787869759375,
          "y": -749.5272132244486
        },
        "dragging": false
      },
      {
        "id": "Prompt-s0t9t",
        "type": "genericNode",
        "position": {
          "x": 3264.4647752945025,
          "y": -123.01349579960996
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "You are an expert climate scientist. \n\nDoes the following CMIP6 query require or specify a year range for the data required to answer.\n\nQuery: {query}\n\nIf yes, provide the year range in format START-END, for instance 1960-1970 or 2100-3100. If no, respond NA-NA. \n\nIf only the start or end is specified, provide just that year in format START-NA (eg 2100-NA) or NA-END (eg NA-1900).\n\nProvide only the year range in this format and nothing else.\n\nToday is: {current_date}",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput",
                "load_from_db": false
              },
              "query": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "query",
                "display_name": "query",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "current_date": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "current_date",
                "display_name": "current_date",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "base_classes": [
              "Message"
            ],
            "display_name": "Date Range Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "query",
                "current_date"
              ]
            },
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "id": "Prompt-s0t9t",
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Date Range Prompt"
        },
        "selected": false,
        "width": 320,
        "height": 429,
        "dragging": false,
        "positionAbsolute": {
          "x": 3264.4647752945025,
          "y": -123.01349579960996
        }
      },
      {
        "id": "OpenAIModel-Ra6hC",
        "type": "genericNode",
        "position": {
          "x": 3619.843933794377,
          "y": -29.190755612016034
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "OPENAI_API_KEY",
                "display_name": "OpenAI API Key",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\nfrom langflow.inputs.inputs import HandleInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. \"\n            \"You must pass the word JSON in the prompt. \"\n            \"If left blank, JSON mode will be disabled. [DEPRECATED]\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o",
                "display_name": "Model Name",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled. [DEPRECATED]",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "RangeSelector",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [],
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "output_parser"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "id": "OpenAIModel-Ra6hC",
          "description": "Generates text using OpenAI LLMs.",
          "display_name": "RangeSelector"
        },
        "selected": false,
        "width": 320,
        "height": 232,
        "dragging": false,
        "positionAbsolute": {
          "x": 3619.843933794377,
          "y": -29.190755612016034
        }
      },
      {
        "id": "Prompt-dr6NU",
        "type": "genericNode",
        "position": {
          "x": 3266.07640414577,
          "y": -598.5560148810174
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "You are an expert climate scientist. Is the following CMIP6-related query best answered using data gathered at which of the following resolutions: \n\n- 'hr': hour\n- 'day': day\n- 'mon': month\n- 'NA': not applicable, none of the above, or unclear\n\n\nRespond with only the short term of one following corresponding to your choice and nothing else. \n\nIf a query does not specify any given temporal resolution, like the query \"plot average temperature\", then choose \noption NA\n\n\nQuery: {query}\n",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput",
                "load_from_db": false
              },
              "query": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "query",
                "display_name": "query",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "base_classes": [
              "Message"
            ],
            "display_name": "Temporal Resolution Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "query"
              ]
            },
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "id": "Prompt-dr6NU",
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Temporal Resolution Prompt"
        },
        "selected": false,
        "width": 320,
        "height": 343,
        "positionAbsolute": {
          "x": 3266.07640414577,
          "y": -598.5560148810174
        },
        "dragging": false
      },
      {
        "id": "OpenAIModel-1xWtn",
        "type": "genericNode",
        "position": {
          "x": 3613.7156540479637,
          "y": -566.2205990195372
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "OPENAI_API_KEY",
                "display_name": "OpenAI API Key",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\nfrom langflow.inputs.inputs import HandleInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. \"\n            \"You must pass the word JSON in the prompt. \"\n            \"If left blank, JSON mode will be disabled. [DEPRECATED]\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o-mini",
                "display_name": "Model Name",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled. [DEPRECATED]",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "TemporalSelector",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [],
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "output_parser"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "id": "OpenAIModel-1xWtn",
          "description": "Generates text using OpenAI LLMs.",
          "display_name": "TemporalSelector"
        },
        "selected": false,
        "width": 320,
        "height": 232,
        "dragging": false,
        "positionAbsolute": {
          "x": 3613.7156540479637,
          "y": -566.2205990195372
        }
      },
      {
        "id": "Prompt-s5f6Z",
        "type": "genericNode",
        "position": {
          "x": 3262.920008885303,
          "y": -1045.856817683067
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "You are a climate scientist and expert on the CMIP6 dataset. Given a colleague's query, find CMIP6 **variables** most likely to help answer the query. \n\nTo find these variables: \n\n1. summarize the variable-related keywords in the query (e.g. \"rain\", not analysis words like \"plot\") using words that are useful for describing the CMIP 6 datasets. For instance, instead of \"weather month\", say temperature precipitation wind\", because \"month\" is not relevant to the variable choice and temperature precipitation wind\" is more specific than \"weather\". \nIf the query relates to whether a variable surpasses some threshold, you may wish to search for the \"min\" or \"max\" versions of variables.\n\n2. connect your list of summary words into one comma separated string.\n\nAdd as much as relevant, don't be shy\n\nUse the tool to check the variables, and at the end output the actual needed query. \n\nYour output should be only the variable name that you found most accurate for the query. No explanations\n\nQuery: {query}",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput",
                "load_from_db": false
              },
              "query": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "query",
                "display_name": "query",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "base_classes": [
              "Message"
            ],
            "display_name": "DPrompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "query"
              ]
            },
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "id": "Prompt-s5f6Z",
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Variables Prompt"
        },
        "selected": false,
        "width": 320,
        "height": 343,
        "positionAbsolute": {
          "x": 3262.920008885303,
          "y": -1045.856817683067
        },
        "dragging": false
      },
      {
        "id": "ParseData-IO8gV",
        "type": "genericNode",
        "position": {
          "x": 7405.218374802683,
          "y": -653.5235787135279
        },
        "data": {
          "type": "ParseData",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{url}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "Parse Data",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "edited": false,
            "metadata": {},
            "lf_version": "1.1.1"
          },
          "id": "ParseData-IO8gV",
          "description": "Convert Data into plain text following a specified template.",
          "display_name": "Parse Data"
        },
        "selected": false,
        "width": 320,
        "height": 299,
        "positionAbsolute": {
          "x": 7405.218374802683,
          "y": -653.5235787135279
        },
        "dragging": false
      },
      {
        "id": "ParseData-fNUvy",
        "type": "genericNode",
        "position": {
          "x": 2511.0347784734704,
          "y": -2439.1016070685455
        },
        "data": {
          "type": "ParseData",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{experiment}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "Experiment",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "edited": false,
            "metadata": {},
            "lf_version": "1.1.1"
          },
          "id": "ParseData-fNUvy",
          "description": "Convert Data into plain text following a specified template.",
          "display_name": "Experiment"
        },
        "selected": false,
        "width": 320,
        "height": 299,
        "positionAbsolute": {
          "x": 2511.0347784734704,
          "y": -2439.1016070685455
        },
        "dragging": false
      },
      {
        "id": "ParseData-mEftS",
        "type": "genericNode",
        "position": {
          "x": 2503.418552215972,
          "y": -2796.495319491069
        },
        "data": {
          "type": "ParseData",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{MIP}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "MIP",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "edited": false,
            "metadata": {},
            "lf_version": "1.1.1"
          },
          "id": "ParseData-mEftS",
          "description": "Convert Data into plain text following a specified template.",
          "display_name": "MIP"
        },
        "selected": false,
        "width": 320,
        "height": 299,
        "dragging": false,
        "positionAbsolute": {
          "x": 2503.418552215972,
          "y": -2796.495319491069
        }
      },
      {
        "id": "Prompt-QYews",
        "type": "genericNode",
        "position": {
          "x": 3267.897612365564,
          "y": -2095.6402967966023
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "You are an expert climate scientist working with CMIP6.\n\nHere is a list of the MIPs you work with:\n<MIP_LIST>\n{mip_list}\n</MIP_LIST>\n\nBased on the following query, which of the above MIPs would you use? Return ONLY the name of the MIP and nothing else. If the choice of MIP does not matter, return 'None'.\n\nQuery: {query}\n",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput",
                "load_from_db": false
              },
              "mip_list": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "mip_list",
                "display_name": "mip_list",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "query": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "query",
                "display_name": "query",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "base_classes": [
              "Message"
            ],
            "display_name": "MIP Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "mip_list",
                "query"
              ]
            },
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "id": "Prompt-QYews",
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Date Range Prompt"
        },
        "selected": false,
        "width": 320,
        "height": 429,
        "dragging": false,
        "positionAbsolute": {
          "x": 3267.897612365564,
          "y": -2095.6402967966023
        }
      },
      {
        "id": "OpenAIModel-6kjJN",
        "type": "genericNode",
        "position": {
          "x": 3630.1633108226492,
          "y": -2019.7750795794166
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "OPENAI_API_KEY",
                "display_name": "OpenAI API Key",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\nfrom langflow.inputs.inputs import HandleInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. \"\n            \"You must pass the word JSON in the prompt. \"\n            \"If left blank, JSON mode will be disabled. [DEPRECATED]\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o",
                "display_name": "Model Name",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled. [DEPRECATED]",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "MIPSelector",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [],
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "output_parser"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "id": "OpenAIModel-6kjJN",
          "description": "Generates text using OpenAI LLMs.",
          "display_name": "MIPSelector"
        },
        "selected": false,
        "width": 320,
        "height": 232,
        "dragging": false,
        "positionAbsolute": {
          "x": 3630.1633108226492,
          "y": -2019.7750795794166
        }
      },
      {
        "id": "Prompt-8BkYc",
        "type": "genericNode",
        "position": {
          "x": 3267.2895934065823,
          "y": -1570.378785358372
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "You are an expert climate scientist working with CMIP6.\n\nHere is a list of the experiments you work with:\n<EXPERIMENT_LIST>\n{EXPERIMENT_LIST}\n</EXPERIMENT_LIST>\nBased on the following query, which of the above experiments would you use? Return ONLY the name of the experiment and nothing else. If the choice of experiment does not matter, return 'None'.\n\nQuery: {query}",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput",
                "load_from_db": false
              },
              "EXPERIMENT_LIST": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "EXPERIMENT_LIST",
                "display_name": "EXPERIMENT_LIST",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              },
              "query": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "query",
                "display_name": "query",
                "advanced": false,
                "input_types": [
                  "Message",
                  "Text"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "base_classes": [
              "Message"
            ],
            "display_name": "Experiment Prompt",
            "documentation": "",
            "custom_fields": {
              "template": [
                "EXPERIMENT_LIST",
                "query"
              ]
            },
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "template"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "id": "Prompt-8BkYc",
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Date Range Prompt"
        },
        "selected": false,
        "width": 320,
        "height": 429,
        "dragging": false,
        "positionAbsolute": {
          "x": 3267.2895934065823,
          "y": -1570.378785358372
        }
      },
      {
        "id": "OpenAIModel-w4BlI",
        "type": "genericNode",
        "position": {
          "x": 3627.126468560398,
          "y": -1485.4427972933431
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "OPENAI_API_KEY",
                "display_name": "OpenAI API Key",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\nfrom langflow.inputs.inputs import HandleInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. \"\n            \"You must pass the word JSON in the prompt. \"\n            \"If left blank, JSON mode will be disabled. [DEPRECATED]\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o",
                "display_name": "Model Name",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled. [DEPRECATED]",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": true,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "ExperimentSelector",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [],
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "output_parser"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "id": "OpenAIModel-w4BlI",
          "description": "Generates text using OpenAI LLMs.",
          "display_name": "MIPSelector"
        },
        "selected": false,
        "width": 320,
        "height": 232,
        "dragging": false,
        "positionAbsolute": {
          "x": 3627.126468560398,
          "y": -1485.4427972933431
        }
      },
      {
        "id": "note-uzk47",
        "type": "noteNode",
        "position": {
          "x": 3244.3440273878914,
          "y": -1620.348533861517
        },
        "data": {
          "node": {
            "description": "# Experiment Selector",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note",
          "id": "note-uzk47"
        },
        "selected": false,
        "width": 600,
        "height": 369,
        "positionAbsolute": {
          "x": 3244.3440273878914,
          "y": -1620.348533861517
        },
        "dragging": false,
        "style": {
          "width": 600,
          "height": 369
        },
        "resizing": false
      },
      {
        "id": "note-ELwce",
        "type": "noteNode",
        "position": {
          "x": 3251.2064453977755,
          "y": -2156.8080171949077
        },
        "data": {
          "node": {
            "description": "# MIP Selector",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note",
          "id": "note-ELwce"
        },
        "selected": false,
        "width": 600,
        "height": 324,
        "positionAbsolute": {
          "x": 3251.2064453977755,
          "y": -2156.8080171949077
        },
        "dragging": false,
        "style": {
          "width": 600,
          "height": 324
        },
        "resizing": false
      },
      {
        "id": "note-qUXKm",
        "type": "noteNode",
        "position": {
          "x": 3251.2235651114934,
          "y": -1111.928915575845
        },
        "data": {
          "node": {
            "description": "# Variables Selector",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note",
          "id": "note-qUXKm"
        },
        "selected": false,
        "width": 600,
        "height": 349,
        "positionAbsolute": {
          "x": 3251.2235651114934,
          "y": -1111.928915575845
        },
        "dragging": false,
        "style": {
          "width": 600,
          "height": 349
        },
        "resizing": false
      },
      {
        "id": "note-gUX7U",
        "type": "noteNode",
        "position": {
          "x": 3241.700118210881,
          "y": -672.7835776147137
        },
        "data": {
          "node": {
            "description": "# Temporal Selector",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note",
          "id": "note-gUX7U"
        },
        "selected": false,
        "width": 600,
        "height": 324,
        "positionAbsolute": {
          "x": 3241.700118210881,
          "y": -672.7835776147137
        },
        "dragging": false,
        "resizing": false,
        "style": {
          "width": 600,
          "height": 324
        }
      },
      {
        "id": "note-pz12u",
        "type": "noteNode",
        "position": {
          "x": 3242.4078436029895,
          "y": -193.87950720208156
        },
        "data": {
          "node": {
            "description": "# Range Selector",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note",
          "id": "note-pz12u"
        },
        "selected": false,
        "width": 600,
        "height": 324,
        "positionAbsolute": {
          "x": 3242.4078436029895,
          "y": -193.87950720208156
        },
        "dragging": false,
        "style": {
          "width": 600,
          "height": 324
        },
        "resizing": false
      },
      {
        "id": "note-nAEmE",
        "type": "noteNode",
        "position": {
          "x": 2104.4217981304396,
          "y": -2840.3587680822898
        },
        "data": {
          "node": {
            "description": "# Load CMIP6 Datasets",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "blue"
            }
          },
          "type": "note",
          "id": "note-nAEmE"
        },
        "selected": false,
        "width": 600,
        "height": 344,
        "positionAbsolute": {
          "x": 2104.4217981304396,
          "y": -2840.3587680822898
        },
        "dragging": false,
        "style": {
          "width": 600,
          "height": 344
        },
        "resizing": false
      },
      {
        "id": "note-wFYVb",
        "type": "noteNode",
        "position": {
          "x": 2876.2126877207456,
          "y": -2921.831798449466
        },
        "data": {
          "node": {
            "description": "# Load CMIP6 JSON Tables",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "blue"
            }
          },
          "type": "note",
          "id": "note-wFYVb"
        },
        "selected": false,
        "width": 600,
        "height": 324,
        "dragging": false,
        "positionAbsolute": {
          "x": 2876.2126877207456,
          "y": -2921.831798449466
        },
        "resizing": false,
        "style": {
          "width": 600,
          "height": 324
        }
      },
      {
        "id": "note-pp9U1",
        "type": "noteNode",
        "position": {
          "x": 1025.1235050841265,
          "y": -1588.674099475012
        },
        "data": {
          "node": {
            "description": "# Chat Start",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "lime"
            }
          },
          "type": "note",
          "id": "note-pp9U1"
        },
        "selected": false,
        "width": 324,
        "height": 324,
        "positionAbsolute": {
          "x": 1025.1235050841265,
          "y": -1588.674099475012
        },
        "dragging": false
      },
      {
        "id": "MIPFilterComponent-NmATT",
        "type": "genericNode",
        "position": {
          "x": 4308.5991434316675,
          "y": -2286.042075504498
        },
        "data": {
          "type": "MIPFilterComponent",
          "node": {
            "template": {
              "_type": "Component",
              "dataset_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dataset_info",
                "value": "",
                "display_name": "Dataset Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Processed CMIP6 dataset information from the previous component.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# MIPFilterComponent.py\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import HandleInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass MIPFilterComponent(Component):\r\n    display_name = \"MIP Filter\"\r\n    description = \"Filters CMIP6 datasets based on the predicted MIP.\"\r\n    icon = \"filter\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"dataset_info\",\r\n            display_name=\"Dataset Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Processed CMIP6 dataset information from the previous component.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"mip_value\",\r\n            display_name=\"MIP Value\",\r\n            info=\"The MIP value predicted by the LLM.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Filtered Datasets\", name=\"filtered_datasets\", method=\"filter_datasets_by_mip\"),\r\n    ]\r\n\r\n    def filter_datasets_by_mip(self) -> Data:\r\n        if not isinstance(self.dataset_info, Data) or 'df' not in self.dataset_info.data:\r\n            raise ValueError(\"Invalid dataset info input. Expected Data object with 'df' key.\")\r\n\r\n        df = self.dataset_info.data['df']\r\n\r\n        if 'MIP' not in df.columns:\r\n            raise ValueError(\"Expected 'MIP' column in dataset info DataFrame.\")\r\n\r\n        try:\r\n            mip_value = self.mip_value.strip()\r\n            if mip_value.lower() == 'none':\r\n                # No filtering; pass all datasets\r\n                filtered_df = df\r\n                self.status = \"No MIP filtering applied.\"\r\n            else:\r\n                # Filter the dataframe\r\n                filtered_df = df[df['MIP'] == mip_value]\r\n\r\n                if filtered_df.empty:\r\n                    self.status = f\"No datasets found for MIP '{mip_value}'.\"\r\n                else:\r\n                    self.status = f\"Filtered datasets by MIP '{mip_value}'. Remaining datasets: {len(filtered_df)}\"\r\n\r\n            return Data(data={\"filtered_df\": filtered_df})\r\n\r\n        except Exception as e:\r\n            error_message = f\"Error filtering datasets by MIP: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "mip_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "mip_value",
                "value": "",
                "display_name": "MIP Value",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The MIP value predicted by the LLM.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Filters CMIP6 datasets based on the predicted MIP.",
            "icon": "filter",
            "base_classes": [
              "Data"
            ],
            "display_name": "MIP Filter",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "filtered_datasets",
                "display_name": "Filtered Datasets",
                "method": "filter_datasets_by_mip",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "dataset_info",
              "mip_value"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.1.1"
          },
          "id": "MIPFilterComponent-NmATT"
        },
        "selected": false,
        "width": 320,
        "height": 300,
        "positionAbsolute": {
          "x": 4308.5991434316675,
          "y": -2286.042075504498
        },
        "dragging": false
      },
      {
        "id": "ExperimentFilterComponent-2Twis",
        "type": "genericNode",
        "position": {
          "x": 4720.720971626717,
          "y": -1965.9139769291764
        },
        "data": {
          "type": "ExperimentFilterComponent",
          "node": {
            "template": {
              "_type": "Component",
              "dataset_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dataset_info",
                "value": "",
                "display_name": "Dataset Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Dataset information from the previous component (after MIP filtering).",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# ExperimentFilterComponent.py\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import HandleInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass ExperimentFilterComponent(Component):\r\n    display_name = \"Experiment Filter\"\r\n    description = \"Filters CMIP6 datasets based on the predicted Experiment.\"\r\n    icon = \"filter\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"dataset_info\",\r\n            display_name=\"Dataset Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Dataset information from the previous component (after MIP filtering).\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"experiment_value\",\r\n            display_name=\"Experiment Value\",\r\n            info=\"The Experiment value predicted by the LLM.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Filtered Datasets\", name=\"filtered_datasets\", method=\"filter_datasets_by_experiment\"),\r\n    ]\r\n\r\n    def filter_datasets_by_experiment(self) -> Data:\r\n        if not isinstance(self.dataset_info, Data) or 'filtered_df' not in self.dataset_info.data:\r\n            raise ValueError(\"Invalid dataset info input. Expected Data object with 'filtered_df' key.\")\r\n\r\n        df = self.dataset_info.data['filtered_df']\r\n\r\n        if 'experiment' not in df.columns:\r\n            raise ValueError(\"Expected 'experiment' column in dataset info DataFrame.\")\r\n\r\n        try:\r\n            experiment_value = self.experiment_value.strip()\r\n            if experiment_value.lower() == 'none':\r\n                # No filtering; pass all datasets\r\n                filtered_df = df\r\n                self.status = \"No Experiment filtering applied.\"\r\n            else:\r\n                # Filter the dataframe\r\n                filtered_df = df[df['experiment'] == experiment_value]\r\n\r\n                if filtered_df.empty:\r\n                    self.status = f\"No datasets found for Experiment '{experiment_value}'.\"\r\n                else:\r\n                    self.status = f\"Filtered datasets by Experiment '{experiment_value}'. Remaining datasets: {len(filtered_df)}\"\r\n\r\n            return Data(data={\"filtered_df\": filtered_df})\r\n\r\n        except Exception as e:\r\n            error_message = f\"Error filtering datasets by Experiment: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "experiment_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "experiment_value",
                "value": "",
                "display_name": "Experiment Value",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The Experiment value predicted by the LLM.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Filters CMIP6 datasets based on the predicted Experiment.",
            "icon": "filter",
            "base_classes": [
              "Data"
            ],
            "display_name": "Experiment Filter",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "filtered_datasets",
                "display_name": "Filtered Datasets",
                "method": "filter_datasets_by_experiment",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "dataset_info",
              "experiment_value"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.1.1"
          },
          "id": "ExperimentFilterComponent-2Twis"
        },
        "selected": false,
        "width": 320,
        "height": 300,
        "positionAbsolute": {
          "x": 4720.720971626717,
          "y": -1965.9139769291764
        },
        "dragging": false
      },
      {
        "id": "FilteredVariableInfoComponent-cuXJv",
        "type": "genericNode",
        "position": {
          "x": 5150.778223745258,
          "y": -1649.2561807049508
        },
        "data": {
          "type": "FilteredVariableInfoComponent",
          "node": {
            "template": {
              "_type": "Component",
              "filtered_datasets": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "filtered_datasets",
                "value": "",
                "display_name": "Filtered Datasets",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Filtered datasets after MIP and Experiment filters.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "variable_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "variable_info",
                "value": "",
                "display_name": "Variable Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Original CMIP6 variable information.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# FilteredVariableInfoComponent.py\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import HandleInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass FilteredVariableInfoComponent(Component):\r\n    display_name = \"Filtered Variable Info\"\r\n    description = \"Filters variable info based on variables present in filtered datasets.\"\r\n    icon = \"filter\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"variable_info\",\r\n            display_name=\"Variable Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Original CMIP6 variable information.\",\r\n        ),\r\n        HandleInput(\r\n            name=\"filtered_datasets\",\r\n            display_name=\"Filtered Datasets\",\r\n            input_types=[\"Data\"],\r\n            info=\"Filtered datasets after MIP and Experiment filters.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(\r\n            display_name=\"Filtered Variable Info\",\r\n            name=\"filtered_variable_info\",\r\n            method=\"filter_variable_info\",\r\n        ),\r\n    ]\r\n\r\n    def filter_variable_info(self) -> Data:\r\n        if not isinstance(self.variable_info, Data) or 'variable_info' not in self.variable_info.data:\r\n            raise ValueError(\"Invalid variable info input. Expected Data object with 'variable_info' key.\")\r\n\r\n        if not isinstance(self.filtered_datasets, Data) or 'filtered_df' not in self.filtered_datasets.data:\r\n            raise ValueError(\"Invalid filtered datasets input. Expected Data object with 'filtered_df' key.\")\r\n\r\n        variable_info_df = self.variable_info.data['variable_info']\r\n        filtered_df = self.filtered_datasets.data['filtered_df']\r\n\r\n        try:\r\n            # Get the list of variables present in the filtered datasets\r\n            variables_in_filtered_datasets = filtered_df['variable'].unique().tolist()\r\n\r\n            # Filter variable info to only include these variables\r\n            filtered_variable_info_df = variable_info_df[variable_info_df['variable'].isin(variables_in_filtered_datasets)]\r\n\r\n            self.status = f\"Filtered variable info. Remaining variables: {len(filtered_variable_info_df)}\"\r\n            return Data(data={\"variable_info\": filtered_variable_info_df})\r\n\r\n        except Exception as e:\r\n            error_message = f\"Error filtering variable info: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Filters variable info based on variables present in filtered datasets.",
            "icon": "filter",
            "base_classes": [
              "Data"
            ],
            "display_name": "Filtered Variable Info",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "filtered_variable_info",
                "display_name": "Filtered Variable Info",
                "method": "filter_variable_info",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "variable_info",
              "filtered_datasets"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.1.1"
          },
          "id": "FilteredVariableInfoComponent-cuXJv"
        },
        "selected": false,
        "width": 320,
        "height": 262,
        "dragging": false,
        "positionAbsolute": {
          "x": 5150.778223745258,
          "y": -1649.2561807049508
        }
      },
      {
        "id": "variable_matcher-pUtyv",
        "type": "genericNode",
        "position": {
          "x": 3666.3057680460593,
          "y": -1060.990373856476
        },
        "data": {
          "type": "variable_matcher",
          "node": {
            "template": {
              "_type": "Component",
              "embeddings": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embeddings",
                "value": "",
                "display_name": "Embeddings",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "Embeddings component for generating query embeddings.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "variable_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "variable_info",
                "value": "",
                "display_name": "Variable Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Processed CMIP6 variable information from the previous component.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import numpy as np\r\nfrom typing import List, Dict, Any\r\nfrom pydantic import BaseModel, Field\r\n\r\nfrom langflow.base.langchain_utilities.model import LCToolComponent\r\nfrom langflow.io import HandleInput, MessageTextInput, IntInput, Output\r\nfrom langflow.schema import Data\r\nfrom langflow.field_typing import Tool\r\nfrom langchain.tools import StructuredTool\r\n\r\nclass VariableMatcherToolComponent(LCToolComponent):\r\n    display_name = \"CMIP6 Variable Matcher\"\r\n    description = \"Matches CMIP6 variables based on LLM output using cosine similarity.\"\r\n    icon = \"match\"\r\n    name = \"variable_matcher\"\r\n    variable_embeddings = None\r\n    variables_data = None\r\n    \r\n    inputs = [\r\n        HandleInput(\r\n            name=\"variable_info\",\r\n            display_name=\"Variable Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Processed CMIP6 variable information from the previous component.\",\r\n        ),\r\n        HandleInput(\r\n            name=\"embeddings\",\r\n            display_name=\"Embeddings\",\r\n            input_types=[\"Embeddings\"],\r\n            info=\"Embeddings component for generating query embeddings.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"llm_output\",\r\n            display_name=\"LLM Output\",\r\n            info=\"Output from the LLM containing variable-related keywords. Can be a single string or comma-separated list.\",\r\n        ),\r\n        IntInput(\r\n            name=\"top_n\",\r\n            display_name=\"Number of Results\",\r\n            info=\"Number of top matching variables to return.\",\r\n            value=5,\r\n        ),\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(display_name=\"Matched Variables\", name=\"matched_variables\", method=\"match_variables\"),\r\n        Output(display_name=\"Tool\", name=\"tool\", method=\"build_tool\"),\r\n    ]\r\n\r\n    class VariableMatcherSchema(BaseModel):\r\n        keywords: str = Field(\r\n            ..., \r\n            description=\"Keywords or description of the variable(s) to search for. Can be a comma-separated list.\"\r\n        )\r\n        top_n: int = Field(\r\n            5, \r\n            description=\"Number of top matching variables to return.\"\r\n        )\r\n\r\n    def cosine_similarity(self, a, b):\r\n        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\r\n\r\n    def _process_matches(self, keywords: str, top_n: int) -> List[Dict[str, Any]]:\r\n        \"\"\"Internal method to process variable matches\"\"\"\r\n        if not isinstance(self.variable_info, Data) or 'variable_info' not in self.variable_info.data:\r\n            raise ValueError(\"Invalid variable info input. Expected Data object with 'variable_info' key.\")\r\n        \r\n        varsdf = self.variable_info.data['variable_info']\r\n        \r\n        if 'embeds' not in varsdf.columns:\r\n            raise ValueError(\"Expected 'embeds' column in variable info DataFrame.\")\r\n\r\n        # Initialize variable embeddings if not already done\r\n        if self.variable_embeddings is None:\r\n            self.variable_embeddings = np.array(varsdf['embeds'].tolist())\r\n            self.variables_data = varsdf.drop('embeds', axis=1)\r\n\r\n        # Split keywords\r\n        keyword_list = [kw.strip() for kw in keywords.split(',')]\r\n        \r\n        # Generate embeddings for each keyword\r\n        keyword_embeddings = [self.embeddings.embed_query(kw) for kw in keyword_list]\r\n        \r\n        # Use the average embedding as the query\r\n        query_embedding = np.mean(keyword_embeddings, axis=0)\r\n        \r\n        # Calculate cosine similarity\r\n        similarities = np.array([\r\n            self.cosine_similarity(query_embedding, vec) \r\n            for vec in self.variable_embeddings\r\n        ])\r\n        \r\n        # Get top N matches\r\n        top_indices = np.argsort(similarities)[-top_n:][::-1]\r\n        \r\n        # Prepare results\r\n        results = self.variables_data.iloc[top_indices].copy()\r\n        results['similarity_score'] = similarities[top_indices]\r\n        \r\n        # Convert to list of dictionaries\r\n        return [\r\n            {\r\n                'variable': row['variable'],\r\n                'long_name': row['long_name'],\r\n                'comment': row['comment'],\r\n                'similarity_score': float(row['similarity_score'])\r\n            }\r\n            for _, row in results.iterrows()\r\n        ]\r\n\r\n    def match_variables(self) -> List[Data]:\r\n        \"\"\"Method for component output\"\"\"\r\n        try:\r\n            results = self._process_matches(self.llm_output, self.top_n)\r\n            data_list = [Data(data=result) for result in results]\r\n            self.status = data_list\r\n            return data_list\r\n            \r\n        except Exception as e:\r\n            error_message = f\"Error matching variables: {str(e)}\"\r\n            self.status = error_message\r\n            return [Data(data={\"error\": error_message})]\r\n\r\n    def build_tool(self) -> Tool:\r\n        \"\"\"Build and return the tool\"\"\"\r\n        return StructuredTool.from_function(\r\n            name=\"variable_matcher\",\r\n            description=\"Match CMIP6 variables based on keywords using semantic similarity. \"\r\n                      \"Input should be keywords or descriptions of the variables you're looking for.\",\r\n            func=self._tool_function,\r\n            args_schema=self.VariableMatcherSchema,\r\n        )\r\n\r\n    def _tool_function(self, keywords: str, top_n: int = 5) -> List[Dict[str, Any]]:\r\n        \"\"\"Function to be called by the tool\"\"\"\r\n        try:\r\n            return self._process_matches(keywords, top_n)\r\n        except Exception as e:\r\n            return [{\"error\": f\"Error matching variables: {str(e)}\"}]",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "llm_output": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "llm_output",
                "value": "",
                "display_name": "LLM Output",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Output from the LLM containing variable-related keywords. Can be a single string or comma-separated list.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "top_n": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "top_n",
                "value": 10,
                "display_name": "Number of Results",
                "advanced": false,
                "dynamic": false,
                "info": "Number of top matching variables to return.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput",
                "load_from_db": false
              }
            },
            "description": "Matches CMIP6 variables based on LLM output using cosine similarity.",
            "icon": "match",
            "base_classes": [
              "Data",
              "Tool"
            ],
            "display_name": "CMIP Variable Tool Check",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "matched_variables",
                "display_name": "Matched Variables",
                "method": "match_variables",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              },
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "variable_info",
              "embeddings",
              "llm_output",
              "top_n"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.1.1"
          },
          "id": "variable_matcher-pUtyv"
        },
        "selected": false,
        "width": 320,
        "height": 347,
        "positionAbsolute": {
          "x": 3666.3057680460593,
          "y": -1060.990373856476
        },
        "dragging": false
      },
      {
        "id": "note-sX80c",
        "type": "noteNode",
        "position": {
          "x": 3804.112527509932,
          "y": -1112.5000011889613
        },
        "data": {
          "node": {
            "description": " ",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note",
          "id": "note-sX80c"
        },
        "selected": false,
        "width": 600,
        "height": 355,
        "dragging": false,
        "style": {
          "width": 600,
          "height": 355
        },
        "resizing": false,
        "positionAbsolute": {
          "x": 3804.112527509932,
          "y": -1112.5000011889613
        }
      },
      {
        "id": "CurrentDateComponent-eu2F1",
        "type": "genericNode",
        "position": {
          "x": 3005.1083801447135,
          "y": 93.71069763839861
        },
        "data": {
          "type": "CurrentDateComponent",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from datetime import datetime\r\nfrom zoneinfo import ZoneInfo\r\nfrom typing import List\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import DropdownInput, Output\r\nfrom langflow.schema.message import Message\r\n\r\nclass CurrentDateComponent(Component):\r\n    display_name = \"Current Date 🕰️\"\r\n    description = \"Returns the current date and time in the selected timezone.\"\r\n    icon = \"clock\"\r\n\r\n    inputs = [\r\n        DropdownInput(\r\n            name=\"timezone\",\r\n            display_name=\"Timezone\",\r\n            options=[\r\n                \"UTC\",\r\n                \"US/Eastern\",\r\n                \"US/Central\",\r\n                \"US/Mountain\",\r\n                \"US/Pacific\",\r\n                \"Europe/London\",\r\n                \"Europe/Paris\",\r\n                \"Asia/Tokyo\",\r\n                \"Australia/Sydney\",\r\n                \"America/Sao_Paulo\",\r\n                \"America/Cuiaba\",\r\n            ],\r\n            value=\"UTC\",\r\n            info=\"Select the timezone for the current date and time.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Current Date\", name=\"current_date\", method=\"get_current_date\"),\r\n    ]\r\n\r\n    def get_current_date(self) -> Message:\r\n        try:\r\n            tz = ZoneInfo(self.timezone)\r\n            current_date = datetime.now(tz).strftime(\"%Y-%m-%d %H:%M:%S %Z\")\r\n            result = f\"Current date and time in {self.timezone}: {current_date}\"\r\n            self.status = result\r\n            return Message(text=result)\r\n        except Exception as e:\r\n            error_message = f\"Error: {str(e)}\"\r\n            self.status = error_message\r\n            return Message(text=error_message)",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "timezone": {
                "trace_as_metadata": true,
                "options": [
                  "UTC",
                  "US/Eastern",
                  "US/Central",
                  "US/Mountain",
                  "US/Pacific",
                  "Europe/London",
                  "Europe/Paris",
                  "Asia/Tokyo",
                  "Australia/Sydney",
                  "America/Sao_Paulo",
                  "America/Cuiaba"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "timezone",
                "value": "America/Sao_Paulo",
                "display_name": "Timezone",
                "advanced": false,
                "dynamic": false,
                "info": "Select the timezone for the current date and time.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              }
            },
            "description": "Returns the current date and time in the selected timezone.",
            "icon": "clock",
            "base_classes": [
              "Message"
            ],
            "display_name": "Current Date",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "current_date",
                "display_name": "Current Date",
                "method": "get_current_date",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "timezone"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.0.18",
            "official": false
          },
          "id": "CurrentDateComponent-eu2F1",
          "showNode": false
        },
        "selected": false,
        "width": 192,
        "height": 65,
        "positionAbsolute": {
          "x": 3005.1083801447135,
          "y": 93.71069763839861
        },
        "dragging": false
      },
      {
        "id": "note-Ar3m6",
        "type": "noteNode",
        "position": {
          "x": 4280.8973999719465,
          "y": -2415.3972398695923
        },
        "data": {
          "node": {
            "description": "# Dataset Filtering Process",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "lime"
            }
          },
          "type": "note",
          "id": "note-Ar3m6"
        },
        "selected": false,
        "width": 600,
        "height": 334,
        "positionAbsolute": {
          "x": 4280.8973999719465,
          "y": -2415.3972398695923
        },
        "dragging": false,
        "style": {
          "width": 600,
          "height": 334
        },
        "resizing": false
      },
      {
        "id": "Agent-0sXKr",
        "type": "genericNode",
        "position": {
          "x": 4048.5987473550076,
          "y": -1060.7208915189365
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": "",
                "display_name": "External Memory",
                "advanced": true,
                "input_types": [
                  "BaseChatMessageHistory"
                ],
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "tools": {
                "trace_as_metadata": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools",
                "value": "",
                "display_name": "Tools",
                "advanced": false,
                "input_types": [
                  "Tool",
                  "BaseTool",
                  "StructuredTool"
                ],
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "add_current_date_tool": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "add_current_date_tool",
                "value": true,
                "display_name": "Add tool Current Date",
                "advanced": true,
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "agent_description": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_description",
                "value": "A helpful assistant with access to the following tools:",
                "display_name": "Agent Description",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "agent_llm": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Amazon Bedrock",
                  "Anthropic",
                  "Azure OpenAI",
                  "Groq",
                  "NVIDIA",
                  "OpenAI",
                  "Custom"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_llm",
                "value": "OpenAI",
                "display_name": "Model Provider",
                "advanced": true,
                "input_types": [],
                "dynamic": false,
                "info": "The provider of the language model that the agent will use to generate responses.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "api_key": {
                "load_from_db": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_core.tools import StructuredTool\n\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.base.models.model_input_constants import ALL_PROVIDER_FIELDS, MODEL_PROVIDERS_DICT\nfrom langflow.base.models.model_utils import get_model_name\nfrom langflow.components.helpers import CurrentDateComponent\nfrom langflow.components.helpers.memory import MemoryComponent\nfrom langflow.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom langflow.io import BoolInput, DropdownInput, MultilineInput, Output\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            input_types=[],\n        ),\n        *MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"],\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        *LCToolsAgentComponent._base_inputs,\n        *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Add tool Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [Output(name=\"response\", display_name=\"Response\", method=\"message_response\")]\n\n    async def message_response(self) -> Message:\n        llm_model, display_name = self.get_llm()\n        self.model_name = get_model_name(llm_model, display_name=display_name)\n        if llm_model is None:\n            msg = \"No language model selected\"\n            raise ValueError(msg)\n        self.chat_history = self.get_memory_data()\n\n        if self.add_current_date_tool:\n            if not isinstance(self.tools, list):  # type: ignore[has-type]\n                self.tools = []\n            # Convert CurrentDateComponent to a StructuredTool\n            current_date_tool = CurrentDateComponent().to_toolkit()[0]\n            if isinstance(current_date_tool, StructuredTool):\n                self.tools.append(current_date_tool)\n            else:\n                msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                raise ValueError(msg)\n\n        if not self.tools:\n            msg = \"Tools are required to run the agent.\"\n            raise ValueError(msg)\n        self.set(\n            llm=llm_model,\n            tools=self.tools,\n            chat_history=self.chat_history,\n            input_value=self.input_value,\n            system_prompt=self.system_prompt,\n        )\n        agent = self.create_agent_runnable()\n        return await self.run_agent(agent)\n\n    def get_memory_data(self):\n        memory_kwargs = {\n            component_input.name: getattr(self, f\"{component_input.name}\") for component_input in self.memory_inputs\n        }\n\n        return MemoryComponent().set(**memory_kwargs).retrieve_messages()\n\n    def get_llm(self):\n        if isinstance(self.agent_llm, str):\n            try:\n                provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n                if provider_info:\n                    component_class = provider_info.get(\"component_class\")\n                    display_name = component_class.display_name\n                    inputs = provider_info.get(\"inputs\")\n                    prefix = provider_info.get(\"prefix\", \"\")\n                    return self._build_llm_model(component_class, inputs, prefix), display_name\n            except Exception as e:\n                msg = f\"Error building {self.agent_llm} language model\"\n                raise ValueError(msg) from e\n        return self.agent_llm, None\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n        return component.set(**model_kwargs).build_model()\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    def update_build_config(self, build_config: dotdict, field_value: str, field_name: str | None = None) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name == \"agent_llm\":\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = component_class.update_build_config(build_config, field_value, field_name)\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n            elif field_value == \"Custom\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n                    value=\"Custom\",\n                    real_time_refresh=True,\n                    input_types=[\"LanguageModel\"],\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if isinstance(self.agent_llm, str) and self.agent_llm in MODEL_PROVIDERS_DICT:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = component_class.update_build_config(build_config, field_value, field_name)\n\n        return build_config\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "handle_parsing_errors": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "handle_parsing_errors",
                "value": true,
                "display_name": "Handle Parse Errors",
                "advanced": true,
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "input_value": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_iterations": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_iterations",
                "value": 15,
                "display_name": "Max Iterations",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o-mini",
                "display_name": "Model Name",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "n_messages": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "n_messages",
                "value": 100,
                "display_name": "Number of Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "order": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "order",
                "value": "Ascending",
                "display_name": "Order",
                "advanced": true,
                "dynamic": false,
                "info": "Order of the messages.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled. [DEPRECATED]",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine and User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Filter by sender type.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Filter by sender name.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "system_prompt": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_prompt",
                "value": "You are a helpful assistant that can use tools to answer questions and perform tasks.",
                "display_name": "Agent Instructions",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{sender_name}: {text}",
                "display_name": "Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "verbose": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "verbose",
                "value": true,
                "display_name": "Verbose",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "icon": "bot",
            "base_classes": [
              "Message"
            ],
            "display_name": "VariableSelector",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "response",
                "display_name": "Response",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "agent_llm",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "output_parser",
              "system_prompt",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template",
              "add_current_date_tool"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "agents",
            "key": "Agent",
            "score": 1.1732828199964098e-19,
            "lf_version": "1.1.1"
          },
          "type": "Agent",
          "id": "Agent-0sXKr"
        },
        "selected": false,
        "width": 320,
        "height": 385,
        "positionAbsolute": {
          "x": 4048.5987473550076,
          "y": -1060.7208915189365
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-FSmMW",
        "type": "genericNode",
        "position": {
          "x": 4023.225274127163,
          "y": -1387.9401682772288
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "🧪",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, _id: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if _id:\n            source_dict[\"id\"] = _id\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    def message_response(self) -> Message:\n        _source, _icon, _display_name, _source_id = self.get_properties_from_source_component()\n        _background_color = self.background_color\n        _text_color = self.text_color\n        if self.chat_icon:\n            _icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(_source_id, _display_name, _source)\n        message.properties.icon = _icon\n        message.properties.background_color = _background_color\n        message.properties.text_color = _text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "Experiment",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "ExperimentSelector Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "ChatOutput",
          "id": "ChatOutput-FSmMW",
          "showNode": false
        },
        "selected": false,
        "width": 192,
        "height": 65,
        "positionAbsolute": {
          "x": 4023.225274127163,
          "y": -1387.9401682772288
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-5uWbw",
        "type": "genericNode",
        "position": {
          "x": 3990.090987621923,
          "y": -1849.081183813862
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "🧪",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, _id: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if _id:\n            source_dict[\"id\"] = _id\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    def message_response(self) -> Message:\n        _source, _icon, _display_name, _source_id = self.get_properties_from_source_component()\n        _background_color = self.background_color\n        _text_color = self.text_color\n        if self.chat_icon:\n            _icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(_source_id, _display_name, _source)\n        message.properties.icon = _icon\n        message.properties.background_color = _background_color\n        message.properties.text_color = _text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "MIP",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "MIPSelector Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "ChatOutput",
          "id": "ChatOutput-5uWbw",
          "showNode": false
        },
        "selected": false,
        "width": 192,
        "height": 65,
        "positionAbsolute": {
          "x": 3990.090987621923,
          "y": -1849.081183813862
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-Ppiin",
        "type": "genericNode",
        "position": {
          "x": 4420.290209494043,
          "y": -760.6068921644619
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "🧪",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, _id: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if _id:\n            source_dict[\"id\"] = _id\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    def message_response(self) -> Message:\n        _source, _icon, _display_name, _source_id = self.get_properties_from_source_component()\n        _background_color = self.background_color\n        _text_color = self.text_color\n        if self.chat_icon:\n            _icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(_source_id, _display_name, _source)\n        message.properties.icon = _icon\n        message.properties.background_color = _background_color\n        message.properties.text_color = _text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "Variable",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "VariableSelector Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "ChatOutput",
          "id": "ChatOutput-Ppiin",
          "showNode": false
        },
        "selected": false,
        "width": 192,
        "height": 65,
        "positionAbsolute": {
          "x": 4420.290209494043,
          "y": -760.6068921644619
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-4GELo",
        "type": "genericNode",
        "position": {
          "x": 3975.5057365391876,
          "y": -420.05443882834027
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "🧪",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, _id: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if _id:\n            source_dict[\"id\"] = _id\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    def message_response(self) -> Message:\n        _source, _icon, _display_name, _source_id = self.get_properties_from_source_component()\n        _background_color = self.background_color\n        _text_color = self.text_color\n        if self.chat_icon:\n            _icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(_source_id, _display_name, _source)\n        message.properties.icon = _icon\n        message.properties.background_color = _background_color\n        message.properties.text_color = _text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "Temporal Resolution",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "TemporalSelector Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "ChatOutput",
          "id": "ChatOutput-4GELo",
          "showNode": false
        },
        "selected": false,
        "width": 192,
        "height": 65,
        "positionAbsolute": {
          "x": 3975.5057365391876,
          "y": -420.05443882834027
        },
        "dragging": false
      },
      {
        "id": "ChatOutput-k8jRL",
        "type": "genericNode",
        "position": {
          "x": 4001.302322677998,
          "y": 136.59348434065427
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "🧪",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, _id: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if _id:\n            source_dict[\"id\"] = _id\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            source_dict[\"source\"] = source\n        return Source(**source_dict)\n\n    def message_response(self) -> Message:\n        _source, _icon, _display_name, _source_id = self.get_properties_from_source_component()\n        _background_color = self.background_color\n        _text_color = self.text_color\n        if self.chat_icon:\n            _icon = self.chat_icon\n        message = self.input_value if isinstance(self.input_value, Message) else Message(text=self.input_value)\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(_source_id, _display_name, _source)\n        message.properties.icon = _icon\n        message.properties.background_color = _background_color\n        message.properties.text_color = _text_color\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "Date Range",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "RangeSelector Output",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "ChatOutput",
          "id": "ChatOutput-k8jRL",
          "showNode": false
        },
        "selected": false,
        "width": 192,
        "height": 65,
        "positionAbsolute": {
          "x": 4001.302322677998,
          "y": 136.59348434065427
        },
        "dragging": false
      },
      {
        "id": "CustomComponent-JaWam",
        "type": "genericNode",
        "position": {
          "x": 7888.979029767216,
          "y": -411.95199647431195
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\r\nfrom langflow.io import MessageTextInput, Output\r\nfrom langflow.schema import Data\r\nimport json\r\nimport os\r\n\r\nclass SaveConfigComponent(Component):\r\n    display_name = \"Save Search Configuration\"\r\n    description = \"Save search configuration parameters including URL, temporal resolution, date range, MIP, experiment, variable, and user query to a JSON file\"\r\n    icon = \"save\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"url\",\r\n            display_name=\"URL\",\r\n            info=\"The URL to save in the JSON file\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"temporal_resolution\",\r\n            display_name=\"Temporal Resolution\",\r\n            info=\"The temporal resolution of the data\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"date_range\",\r\n            display_name=\"Date Range\",\r\n            info=\"The date range for the data\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"mip\",\r\n            display_name=\"MIP\",\r\n            info=\"The MIP (Model Intercomparison Project) identifier\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"experiment\",\r\n            display_name=\"Experiment\",\r\n            info=\"The experiment name or identifier\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"variable\",\r\n            display_name=\"Variable\",\r\n            info=\"The variable name or identifier\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"user_query\",\r\n            display_name=\"User Query\",\r\n            info=\"The original user query\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"file_name\",\r\n            display_name=\"File Name\",\r\n            info=\"The name of the JSON file to save (without .json extension)\",\r\n            advanced=True,\r\n            value=\"search_config\"\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(name=\"saved_data\", display_name=\"Saved Data\", method=\"save_config\"),\r\n    ]\r\n\r\n    def save_config(self) -> Data:\r\n        try:\r\n            # Validate required fields\r\n            if not self.url:\r\n                url = \"No Match\"\r\n            else:\r\n                url = self.url\r\n            # Prepare the data dictionary\r\n            data = {\r\n                \"url\": url,\r\n                \"temporal_resolution\": self.temporal_resolution,\r\n                \"date_range\": self.date_range,\r\n                \"mip\": self.mip,\r\n                \"experiment\": self.experiment,\r\n                \"variable\": self.variable,\r\n                \"user_query\": self.user_query,\r\n                \"run_id\": self.graph.run_id,\r\n                \"session_id\": self.graph.session_id\r\n            }\r\n\r\n            # Clean the data dictionary by removing None values\r\n            data = {k: v for k, v in data.items() if v is not None}\r\n\r\n            # Prepare file name\r\n            file_name = f\"{self.file_name}.json\" if self.file_name else \"search_config.json\"\r\n\r\n            # Save to JSON file\r\n            with open(file_name, 'w') as json_file:\r\n                json.dump(data, json_file, indent=2)\r\n\r\n            self.log(f\"Configuration saved to {file_name}\")\r\n            \r\n            return Data(data=data)\r\n\r\n        except Exception as e:\r\n            error_message = f\"An error occurred while saving the configuration: {str(e)}\"\r\n            self.log(error_message)\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "date_range": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "date_range",
                "value": "",
                "display_name": "Date Range",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The date range for the data",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "experiment": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "experiment",
                "value": "",
                "display_name": "Experiment",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The experiment name or identifier",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "file_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "file_name",
                "value": "url_data",
                "display_name": "File Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The name of the JSON file to save (without .json extension)",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "mip": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "mip",
                "value": "",
                "display_name": "MIP",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The MIP (Model Intercomparison Project) identifier",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temporal_resolution": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temporal_resolution",
                "value": "",
                "display_name": "Temporal Resolution",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The temporal resolution of the data",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "url": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "url",
                "value": "",
                "display_name": "URL",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The URL to save in the JSON file",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "user_query": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "user_query",
                "value": "",
                "display_name": "User Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The original user query",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "variable": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "variable",
                "value": "",
                "display_name": "Variable",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The variable name or identifier",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Save search configuration parameters including URL, temporal resolution, date range, MIP, experiment, variable, and user query to a JSON file",
            "icon": "save",
            "base_classes": [
              "Data"
            ],
            "display_name": "Save Search Configuration",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "saved_data",
                "display_name": "Saved Data",
                "method": "save_config",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "url",
              "temporal_resolution",
              "date_range",
              "mip",
              "experiment",
              "variable",
              "user_query",
              "file_name"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.1.1"
          },
          "type": "CustomComponent",
          "id": "CustomComponent-JaWam"
        },
        "selected": true,
        "width": 320,
        "height": 808,
        "positionAbsolute": {
          "x": 7888.979029767216,
          "y": -411.95199647431195
        },
        "dragging": false
      },
      {
        "id": "ParseData-5KQTl",
        "type": "genericNode",
        "position": {
          "x": 2117.4988669157246,
          "y": -1519.1432643033322
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "trace_as_input": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Parse Data\"\n    description = \"Convert Data into plain text following a specified template.\"\n    icon = \"braces\"\n    name = \"ParseData\"\n\n    inputs = [\n        DataInput(name=\"data\", display_name=\"Data\", info=\"The data to convert to text.\"),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"parse_data\"),\n    ]\n\n    def parse_data(self) -> Message:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n\n        result_string = data_to_text(template, data, sep=self.sep)\n        self.status = result_string\n        return Message(text=result_string)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{text}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data into plain text following a specified template.",
            "icon": "braces",
            "base_classes": [
              "Message"
            ],
            "display_name": "Search Query",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "display_name": "Text",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "processing",
            "key": "ParseData",
            "score": 0.007568328950209746,
            "lf_version": "1.1.1"
          },
          "type": "ParseData",
          "id": "ParseData-5KQTl"
        },
        "selected": false,
        "width": 320,
        "height": 299,
        "dragging": false,
        "positionAbsolute": {
          "x": 2117.4988669157246,
          "y": -1519.1432643033322
        }
      },
      {
        "id": "note-n9qnE",
        "type": "noteNode",
        "position": {
          "x": 2039.5844260837744,
          "y": -1604.1485298807581
        },
        "data": {
          "node": {
            "description": "# Dataset Search System",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note",
          "id": "note-n9qnE"
        },
        "selected": false,
        "width": 600,
        "height": 324,
        "positionAbsolute": {
          "x": 2039.5844260837744,
          "y": -1604.1485298807581
        },
        "dragging": false,
        "style": {
          "width": 600,
          "height": 324
        },
        "resizing": false
      },
      {
        "id": "note-CUgb2",
        "type": "noteNode",
        "position": {
          "x": 7842.0084292551865,
          "y": -480.80259983764756
        },
        "data": {
          "node": {
            "description": "# Save Search Config",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "blue"
            }
          },
          "type": "note",
          "id": "note-CUgb2"
        },
        "selected": false,
        "width": 421,
        "height": 324,
        "positionAbsolute": {
          "x": 7842.0084292551865,
          "y": -480.80259983764756
        },
        "dragging": false,
        "resizing": false,
        "style": {
          "width": 421,
          "height": 324
        }
      },
      {
        "id": "MessagetoData-wMfau",
        "type": "genericNode",
        "position": {
          "x": 1566.4876170489356,
          "y": -1529.860052916314
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from loguru import logger\n\nfrom langflow.custom import Component\nfrom langflow.io import MessageInput, Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass MessageToDataComponent(Component):\n    display_name = \"Message to Data\"\n    description = \"Convert a Message object to a Data object\"\n    icon = \"message-square-share\"\n    beta = True\n    name = \"MessagetoData\"\n\n    inputs = [\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The Message object to convert to a Data object\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"convert_message_to_data\"),\n    ]\n\n    def convert_message_to_data(self) -> Data:\n        if isinstance(self.message, Message):\n            # Convert Message to Data\n            return Data(data=self.message.data)\n\n        msg = \"Error converting Message to Data: Input must be a Message object\"\n        logger.opt(exception=True).debug(msg)\n        self.status = msg\n        return Data(data={\"error\": msg})\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "message",
                "value": "",
                "display_name": "Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The Message object to convert to a Data object",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              }
            },
            "description": "Convert a Message object to a Data object",
            "icon": "message-square-share",
            "base_classes": [
              "Data"
            ],
            "display_name": "Message to Data",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "convert_message_to_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "message"
            ],
            "beta": true,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "processing",
            "key": "MessagetoData",
            "score": 0.008222426499470714,
            "lf_version": "1.1.1"
          },
          "type": "MessagetoData",
          "id": "MessagetoData-wMfau"
        },
        "selected": false,
        "width": 320,
        "height": 232,
        "dragging": false,
        "positionAbsolute": {
          "x": 1566.4876170489356,
          "y": -1529.860052916314
        }
      }
    ],
    "edges": [
      {
        "source": "CMIP6DatasetProcessorComponent-Ce7RN",
        "target": "TemporalResolutionFilterComponent-tc5z8",
        "sourceHandle": "{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-Ce7RNœ,œnameœ:œprocessed_dfœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œdataset_infoœ,œidœ:œTemporalResolutionFilterComponent-tc5z8œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-CMIP6DatasetProcessorComponent-Ce7RN{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-Ce7RNœ,œnameœ:œprocessed_dfœ,œoutput_typesœ:[œDataœ]}-TemporalResolutionFilterComponent-tc5z8{œfieldNameœ:œdataset_infoœ,œidœ:œTemporalResolutionFilterComponent-tc5z8œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "dataset_info",
            "id": "TemporalResolutionFilterComponent-tc5z8",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CMIP6DatasetProcessorComponent",
            "id": "CMIP6DatasetProcessorComponent-Ce7RN",
            "name": "processed_df",
            "output_types": [
              "Data"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "TemporalResolutionFilterComponent-tc5z8",
        "target": "YearRangeFilterComponent-veOZo",
        "sourceHandle": "{œdataTypeœ:œTemporalResolutionFilterComponentœ,œidœ:œTemporalResolutionFilterComponent-tc5z8œ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œdataset_infoœ,œidœ:œYearRangeFilterComponent-veOZoœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-TemporalResolutionFilterComponent-tc5z8{œdataTypeœ:œTemporalResolutionFilterComponentœ,œidœ:œTemporalResolutionFilterComponent-tc5z8œ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}-YearRangeFilterComponent-veOZo{œfieldNameœ:œdataset_infoœ,œidœ:œYearRangeFilterComponent-veOZoœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "dataset_info",
            "id": "YearRangeFilterComponent-veOZo",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "TemporalResolutionFilterComponent",
            "id": "TemporalResolutionFilterComponent-tc5z8",
            "name": "filtered_datasets",
            "output_types": [
              "Data"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "YearRangeFilterComponent-veOZo",
        "target": "URLExtractorComponent-8YWrk",
        "sourceHandle": "{œdataTypeœ:œYearRangeFilterComponentœ,œidœ:œYearRangeFilterComponent-veOZoœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œdataset_infoœ,œidœ:œURLExtractorComponent-8YWrkœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-YearRangeFilterComponent-veOZo{œdataTypeœ:œYearRangeFilterComponentœ,œidœ:œYearRangeFilterComponent-veOZoœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}-URLExtractorComponent-8YWrk{œfieldNameœ:œdataset_infoœ,œidœ:œURLExtractorComponent-8YWrkœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "dataset_info",
            "id": "URLExtractorComponent-8YWrk",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "YearRangeFilterComponent",
            "id": "YearRangeFilterComponent-veOZo",
            "name": "filtered_datasets",
            "output_types": [
              "Data"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "Prompt-s0t9t",
        "target": "OpenAIModel-Ra6hC",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-s0t9tœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-Ra6hCœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-Prompt-s0t9t{œdataTypeœ:œPromptœ,œidœ:œPrompt-s0t9tœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-Ra6hC{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-Ra6hCœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-Ra6hC",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-s0t9t",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "OpenAIModel-Ra6hC",
        "target": "YearRangeFilterComponent-veOZo",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-Ra6hCœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œyear_rangeœ,œidœ:œYearRangeFilterComponent-veOZoœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-OpenAIModel-Ra6hC{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-Ra6hCœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-YearRangeFilterComponent-veOZo{œfieldNameœ:œyear_rangeœ,œidœ:œYearRangeFilterComponent-veOZoœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "year_range",
            "id": "YearRangeFilterComponent-veOZo",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-Ra6hC",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "Prompt-dr6NU",
        "target": "OpenAIModel-1xWtn",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-dr6NUœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-1xWtnœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-Prompt-dr6NU{œdataTypeœ:œPromptœ,œidœ:œPrompt-dr6NUœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-1xWtn{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-1xWtnœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-1xWtn",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-dr6NU",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "OpenAIModel-1xWtn",
        "target": "TemporalResolutionFilterComponent-tc5z8",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-1xWtnœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œresolutionœ,œidœ:œTemporalResolutionFilterComponent-tc5z8œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-OpenAIModel-1xWtn{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-1xWtnœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-TemporalResolutionFilterComponent-tc5z8{œfieldNameœ:œresolutionœ,œidœ:œTemporalResolutionFilterComponent-tc5z8œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "resolution",
            "id": "TemporalResolutionFilterComponent-tc5z8",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-1xWtn",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "CMIP6DatasetProcessorComponent-Ce7RN",
        "target": "CMIP6VariableProcessorFromZip-owuWY",
        "sourceHandle": "{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-Ce7RNœ,œnameœ:œprocessed_dfœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œdataset_infoœ,œidœ:œCMIP6VariableProcessorFromZip-owuWYœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-CMIP6DatasetProcessorComponent-Ce7RN{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-Ce7RNœ,œnameœ:œprocessed_dfœ,œoutput_typesœ:[œDataœ]}-CMIP6VariableProcessorFromZip-owuWY{œfieldNameœ:œdataset_infoœ,œidœ:œCMIP6VariableProcessorFromZip-owuWYœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "dataset_info",
            "id": "CMIP6VariableProcessorFromZip-owuWY",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CMIP6DatasetProcessorComponent",
            "id": "CMIP6DatasetProcessorComponent-Ce7RN",
            "name": "processed_df",
            "output_types": [
              "Data"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "OpenAIEmbeddings-RdeOk",
        "target": "CMIP6VariableProcessorFromZip-owuWY",
        "sourceHandle": "{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-RdeOkœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "targetHandle": "{œfieldNameœ:œembeddingsœ,œidœ:œCMIP6VariableProcessorFromZip-owuWYœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-OpenAIEmbeddings-RdeOk{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-RdeOkœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-CMIP6VariableProcessorFromZip-owuWY{œfieldNameœ:œembeddingsœ,œidœ:œCMIP6VariableProcessorFromZip-owuWYœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "embeddings",
            "id": "CMIP6VariableProcessorFromZip-owuWY",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIEmbeddings",
            "id": "OpenAIEmbeddings-RdeOk",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "URLExtractorComponent-8YWrk",
        "target": "ParseData-IO8gV",
        "sourceHandle": "{œdataTypeœ:œURLExtractorComponentœ,œidœ:œURLExtractorComponent-8YWrkœ,œnameœ:œextracted_urlsœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-IO8gVœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-URLExtractorComponent-8YWrk{œdataTypeœ:œURLExtractorComponentœ,œidœ:œURLExtractorComponent-8YWrkœ,œnameœ:œextracted_urlsœ,œoutput_typesœ:[œDataœ]}-ParseData-IO8gV{œfieldNameœ:œdataœ,œidœ:œParseData-IO8gVœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-IO8gV",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "URLExtractorComponent",
            "id": "URLExtractorComponent-8YWrk",
            "name": "extracted_urls",
            "output_types": [
              "Data"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "CMIP6DatasetProcessorComponent-Ce7RN",
        "sourceHandle": "{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-Ce7RNœ,œnameœ:œunique_experimentsœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-fNUvy",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-fNUvyœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-fNUvy",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CMIP6DatasetProcessorComponent",
            "id": "CMIP6DatasetProcessorComponent-Ce7RN",
            "name": "unique_experiments",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CMIP6DatasetProcessorComponent-Ce7RN{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-Ce7RNœ,œnameœ:œunique_experimentsœ,œoutput_typesœ:[œDataœ]}-ParseData-fNUvy{œfieldNameœ:œdataœ,œidœ:œParseData-fNUvyœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "CMIP6DatasetProcessorComponent-Ce7RN",
        "sourceHandle": "{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-Ce7RNœ,œnameœ:œunique_mipsœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-mEftS",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-mEftSœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-mEftS",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CMIP6DatasetProcessorComponent",
            "id": "CMIP6DatasetProcessorComponent-Ce7RN",
            "name": "unique_mips",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CMIP6DatasetProcessorComponent-Ce7RN{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-Ce7RNœ,œnameœ:œunique_mipsœ,œoutput_typesœ:[œDataœ]}-ParseData-mEftS{œfieldNameœ:œdataœ,œidœ:œParseData-mEftSœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "Prompt-QYews",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-QYewsœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-6kjJN",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-6kjJNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-6kjJN",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-QYews",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-QYews{œdataTypeœ:œPromptœ,œidœ:œPrompt-QYewsœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-6kjJN{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-6kjJNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "className": "",
        "animated": false
      },
      {
        "source": "Prompt-8BkYc",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-8BkYcœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-w4BlI",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-w4BlIœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-w4BlI",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-8BkYc",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-8BkYc{œdataTypeœ:œPromptœ,œidœ:œPrompt-8BkYcœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-w4BlI{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-w4BlIœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": "",
        "selected": false,
        "animated": false
      },
      {
        "source": "ParseData-fNUvy",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-fNUvyœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-8BkYc",
        "targetHandle": "{œfieldNameœ:œEXPERIMENT_LISTœ,œidœ:œPrompt-8BkYcœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "EXPERIMENT_LIST",
            "id": "Prompt-8BkYc",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-fNUvy",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-fNUvy{œdataTypeœ:œParseDataœ,œidœ:œParseData-fNUvyœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-8BkYc{œfieldNameœ:œEXPERIMENT_LISTœ,œidœ:œPrompt-8BkYcœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": "",
        "selected": false,
        "animated": false
      },
      {
        "source": "ParseData-mEftS",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-mEftSœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-QYews",
        "targetHandle": "{œfieldNameœ:œmip_listœ,œidœ:œPrompt-QYewsœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "mip_list",
            "id": "Prompt-QYews",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-mEftS",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-mEftS{œdataTypeœ:œParseDataœ,œidœ:œParseData-mEftSœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-QYews{œfieldNameœ:œmip_listœ,œidœ:œPrompt-QYewsœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": "",
        "selected": false,
        "animated": false
      },
      {
        "source": "CMIP6DatasetProcessorComponent-Ce7RN",
        "sourceHandle": "{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-Ce7RNœ,œnameœ:œprocessed_dfœ,œoutput_typesœ:[œDataœ]}",
        "target": "MIPFilterComponent-NmATT",
        "targetHandle": "{œfieldNameœ:œdataset_infoœ,œidœ:œMIPFilterComponent-NmATTœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "dataset_info",
            "id": "MIPFilterComponent-NmATT",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CMIP6DatasetProcessorComponent",
            "id": "CMIP6DatasetProcessorComponent-Ce7RN",
            "name": "processed_df",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CMIP6DatasetProcessorComponent-Ce7RN{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-Ce7RNœ,œnameœ:œprocessed_dfœ,œoutput_typesœ:[œDataœ]}-MIPFilterComponent-NmATT{œfieldNameœ:œdataset_infoœ,œidœ:œMIPFilterComponent-NmATTœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "selected": false,
        "animated": false
      },
      {
        "source": "MIPFilterComponent-NmATT",
        "sourceHandle": "{œdataTypeœ:œMIPFilterComponentœ,œidœ:œMIPFilterComponent-NmATTœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}",
        "target": "ExperimentFilterComponent-2Twis",
        "targetHandle": "{œfieldNameœ:œdataset_infoœ,œidœ:œExperimentFilterComponent-2Twisœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "dataset_info",
            "id": "ExperimentFilterComponent-2Twis",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "MIPFilterComponent",
            "id": "MIPFilterComponent-NmATT",
            "name": "filtered_datasets",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-MIPFilterComponent-NmATT{œdataTypeœ:œMIPFilterComponentœ,œidœ:œMIPFilterComponent-NmATTœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}-ExperimentFilterComponent-2Twis{œfieldNameœ:œdataset_infoœ,œidœ:œExperimentFilterComponent-2Twisœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "OpenAIModel-6kjJN",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-6kjJNœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "MIPFilterComponent-NmATT",
        "targetHandle": "{œfieldNameœ:œmip_valueœ,œidœ:œMIPFilterComponent-NmATTœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "mip_value",
            "id": "MIPFilterComponent-NmATT",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-6kjJN",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-6kjJN{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-6kjJNœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-MIPFilterComponent-NmATT{œfieldNameœ:œmip_valueœ,œidœ:œMIPFilterComponent-NmATTœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "OpenAIModel-w4BlI",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-w4BlIœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ExperimentFilterComponent-2Twis",
        "targetHandle": "{œfieldNameœ:œexperiment_valueœ,œidœ:œExperimentFilterComponent-2Twisœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "experiment_value",
            "id": "ExperimentFilterComponent-2Twis",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-w4BlI",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-w4BlI{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-w4BlIœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ExperimentFilterComponent-2Twis{œfieldNameœ:œexperiment_valueœ,œidœ:œExperimentFilterComponent-2Twisœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "CMIP6VariableProcessorFromZip-owuWY",
        "sourceHandle": "{œdataTypeœ:œCMIP6VariableProcessorFromZipœ,œidœ:œCMIP6VariableProcessorFromZip-owuWYœ,œnameœ:œvariable_infoœ,œoutput_typesœ:[œDataœ]}",
        "target": "FilteredVariableInfoComponent-cuXJv",
        "targetHandle": "{œfieldNameœ:œvariable_infoœ,œidœ:œFilteredVariableInfoComponent-cuXJvœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "variable_info",
            "id": "FilteredVariableInfoComponent-cuXJv",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CMIP6VariableProcessorFromZip",
            "id": "CMIP6VariableProcessorFromZip-owuWY",
            "name": "variable_info",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CMIP6VariableProcessorFromZip-owuWY{œdataTypeœ:œCMIP6VariableProcessorFromZipœ,œidœ:œCMIP6VariableProcessorFromZip-owuWYœ,œnameœ:œvariable_infoœ,œoutput_typesœ:[œDataœ]}-FilteredVariableInfoComponent-cuXJv{œfieldNameœ:œvariable_infoœ,œidœ:œFilteredVariableInfoComponent-cuXJvœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "ExperimentFilterComponent-2Twis",
        "sourceHandle": "{œdataTypeœ:œExperimentFilterComponentœ,œidœ:œExperimentFilterComponent-2Twisœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}",
        "target": "FilteredVariableInfoComponent-cuXJv",
        "targetHandle": "{œfieldNameœ:œfiltered_datasetsœ,œidœ:œFilteredVariableInfoComponent-cuXJvœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "filtered_datasets",
            "id": "FilteredVariableInfoComponent-cuXJv",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "ExperimentFilterComponent",
            "id": "ExperimentFilterComponent-2Twis",
            "name": "filtered_datasets",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-ExperimentFilterComponent-2Twis{œdataTypeœ:œExperimentFilterComponentœ,œidœ:œExperimentFilterComponent-2Twisœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}-FilteredVariableInfoComponent-cuXJv{œfieldNameœ:œfiltered_datasetsœ,œidœ:œFilteredVariableInfoComponent-cuXJvœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "FilteredVariableInfoComponent-cuXJv",
        "sourceHandle": "{œdataTypeœ:œFilteredVariableInfoComponentœ,œidœ:œFilteredVariableInfoComponent-cuXJvœ,œnameœ:œfiltered_variable_infoœ,œoutput_typesœ:[œDataœ]}",
        "target": "variable_matcher-Fdn7i",
        "targetHandle": "{œfieldNameœ:œvariable_infoœ,œidœ:œvariable_matcher-Fdn7iœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "variable_info",
            "id": "variable_matcher-Fdn7i",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "FilteredVariableInfoComponent",
            "id": "FilteredVariableInfoComponent-cuXJv",
            "name": "filtered_variable_info",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-FilteredVariableInfoComponent-cuXJv{œdataTypeœ:œFilteredVariableInfoComponentœ,œidœ:œFilteredVariableInfoComponent-cuXJvœ,œnameœ:œfiltered_variable_infoœ,œoutput_typesœ:[œDataœ]}-variable_matcher-Fdn7i{œfieldNameœ:œvariable_infoœ,œidœ:œvariable_matcher-Fdn7iœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "FilteredVariableInfoComponent-cuXJv",
        "sourceHandle": "{œdataTypeœ:œFilteredVariableInfoComponentœ,œidœ:œFilteredVariableInfoComponent-cuXJvœ,œnameœ:œfiltered_variable_infoœ,œoutput_typesœ:[œDataœ]}",
        "target": "variable_matcher-pUtyv",
        "targetHandle": "{œfieldNameœ:œvariable_infoœ,œidœ:œvariable_matcher-pUtyvœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "variable_info",
            "id": "variable_matcher-pUtyv",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "FilteredVariableInfoComponent",
            "id": "FilteredVariableInfoComponent-cuXJv",
            "name": "filtered_variable_info",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-FilteredVariableInfoComponent-cuXJv{œdataTypeœ:œFilteredVariableInfoComponentœ,œidœ:œFilteredVariableInfoComponent-cuXJvœ,œnameœ:œfiltered_variable_infoœ,œoutput_typesœ:[œDataœ]}-variable_matcher-pUtyv{œfieldNameœ:œvariable_infoœ,œidœ:œvariable_matcher-pUtyvœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "OpenAIEmbeddings-RdeOk",
        "sourceHandle": "{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-RdeOkœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "target": "variable_matcher-pUtyv",
        "targetHandle": "{œfieldNameœ:œembeddingsœ,œidœ:œvariable_matcher-pUtyvœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "embeddings",
            "id": "variable_matcher-pUtyv",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIEmbeddings",
            "id": "OpenAIEmbeddings-RdeOk",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIEmbeddings-RdeOk{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-RdeOkœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-variable_matcher-pUtyv{œfieldNameœ:œembeddingsœ,œidœ:œvariable_matcher-pUtyvœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "variable_matcher-Fdn7i",
        "sourceHandle": "{œdataTypeœ:œvariable_matcherœ,œidœ:œvariable_matcher-Fdn7iœ,œnameœ:œmatched_variablesœ,œoutput_typesœ:[œDataœ]}",
        "target": "TemporalResolutionFilterComponent-tc5z8",
        "targetHandle": "{œfieldNameœ:œmatched_variablesœ,œidœ:œTemporalResolutionFilterComponent-tc5z8œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "matched_variables",
            "id": "TemporalResolutionFilterComponent-tc5z8",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "variable_matcher",
            "id": "variable_matcher-Fdn7i",
            "name": "matched_variables",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-variable_matcher-Fdn7i{œdataTypeœ:œvariable_matcherœ,œidœ:œvariable_matcher-Fdn7iœ,œnameœ:œmatched_variablesœ,œoutput_typesœ:[œDataœ]}-TemporalResolutionFilterComponent-tc5z8{œfieldNameœ:œmatched_variablesœ,œidœ:œTemporalResolutionFilterComponent-tc5z8œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "CurrentDateComponent-eu2F1",
        "sourceHandle": "{œdataTypeœ:œCurrentDateComponentœ,œidœ:œCurrentDateComponent-eu2F1œ,œnameœ:œcurrent_dateœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-s0t9t",
        "targetHandle": "{œfieldNameœ:œcurrent_dateœ,œidœ:œPrompt-s0t9tœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "current_date",
            "id": "Prompt-s0t9t",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "CurrentDateComponent",
            "id": "CurrentDateComponent-eu2F1",
            "name": "current_date",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-CurrentDateComponent-eu2F1{œdataTypeœ:œCurrentDateComponentœ,œidœ:œCurrentDateComponent-eu2F1œ,œnameœ:œcurrent_dateœ,œoutput_typesœ:[œMessageœ]}-Prompt-s0t9t{œfieldNameœ:œcurrent_dateœ,œidœ:œPrompt-s0t9tœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "Prompt-s5f6Z",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-s5f6Zœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Agent-0sXKr",
        "targetHandle": "{œfieldNameœ:œsystem_promptœ,œidœ:œAgent-0sXKrœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "system_prompt",
            "id": "Agent-0sXKr",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-s5f6Z",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "className": "",
        "id": "reactflow__edge-Prompt-s5f6Z{œdataTypeœ:œPromptœ,œidœ:œPrompt-s5f6Zœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-Agent-0sXKr{œfieldNameœ:œsystem_promptœ,œidœ:œAgent-0sXKrœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "selected": false
      },
      {
        "source": "variable_matcher-pUtyv",
        "sourceHandle": "{œdataTypeœ:œvariable_matcherœ,œidœ:œvariable_matcher-pUtyvœ,œnameœ:œtoolœ,œoutput_typesœ:[œToolœ]}",
        "target": "Agent-0sXKr",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œAgent-0sXKrœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-0sXKr",
            "inputTypes": [
              "Tool",
              "BaseTool",
              "StructuredTool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "variable_matcher",
            "id": "variable_matcher-pUtyv",
            "name": "tool",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "reactflow__edge-variable_matcher-pUtyv{œdataTypeœ:œvariable_matcherœ,œidœ:œvariable_matcher-pUtyvœ,œnameœ:œtoolœ,œoutput_typesœ:[œToolœ]}-Agent-0sXKr{œfieldNameœ:œtoolsœ,œidœ:œAgent-0sXKrœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "Agent-0sXKr",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-0sXKrœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "variable_matcher-Fdn7i",
        "targetHandle": "{œfieldNameœ:œvariable_nameœ,œidœ:œvariable_matcher-Fdn7iœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "variable_name",
            "id": "variable_matcher-Fdn7i",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-0sXKr",
            "name": "response",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Agent-0sXKr{œdataTypeœ:œAgentœ,œidœ:œAgent-0sXKrœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-variable_matcher-Fdn7i{œfieldNameœ:œvariable_nameœ,œidœ:œvariable_matcher-Fdn7iœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "OpenAIModel-w4BlI",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-w4BlIœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-FSmMW",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-FSmMWœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-FSmMW",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-w4BlI",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "animated": false,
        "className": "",
        "id": "reactflow__edge-OpenAIModel-w4BlI{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-w4BlIœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-FSmMW{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-FSmMWœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false
      },
      {
        "source": "OpenAIModel-6kjJN",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-6kjJNœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-5uWbw",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-5uWbwœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-5uWbw",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-6kjJN",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-6kjJN{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-6kjJNœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-5uWbw{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-5uWbwœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "Agent-0sXKr",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-0sXKrœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-Ppiin",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-Ppiinœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-Ppiin",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-0sXKr",
            "name": "response",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Agent-0sXKr{œdataTypeœ:œAgentœ,œidœ:œAgent-0sXKrœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-Ppiin{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-Ppiinœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "OpenAIModel-1xWtn",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-1xWtnœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-4GELo",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-4GELoœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-4GELo",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-1xWtn",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-1xWtn{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-1xWtnœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-4GELo{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-4GELoœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "OpenAIModel-Ra6hC",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-Ra6hCœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-k8jRL",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-k8jRLœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-k8jRL",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-Ra6hC",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-Ra6hC{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-Ra6hCœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-k8jRL{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-k8jRLœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "ParseData-IO8gV",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-IO8gVœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-JaWam",
        "targetHandle": "{œfieldNameœ:œurlœ,œidœ:œCustomComponent-JaWamœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "url",
            "id": "CustomComponent-JaWam",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-IO8gV",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-IO8gV{œdataTypeœ:œParseDataœ,œidœ:œParseData-IO8gVœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-JaWam{œfieldNameœ:œurlœ,œidœ:œCustomComponent-JaWamœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "Agent-0sXKr",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-0sXKrœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-JaWam",
        "targetHandle": "{œfieldNameœ:œvariableœ,œidœ:œCustomComponent-JaWamœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "variable",
            "id": "CustomComponent-JaWam",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-0sXKr",
            "name": "response",
            "output_types": [
              "Message"
            ]
          }
        },
        "animated": false,
        "className": "",
        "id": "reactflow__edge-Agent-0sXKr{œdataTypeœ:œAgentœ,œidœ:œAgent-0sXKrœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-JaWam{œfieldNameœ:œvariableœ,œidœ:œCustomComponent-JaWamœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false
      },
      {
        "source": "OpenAIModel-1xWtn",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-1xWtnœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-JaWam",
        "targetHandle": "{œfieldNameœ:œtemporal_resolutionœ,œidœ:œCustomComponent-JaWamœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "temporal_resolution",
            "id": "CustomComponent-JaWam",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-1xWtn",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "animated": false,
        "className": "",
        "id": "reactflow__edge-OpenAIModel-1xWtn{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-1xWtnœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-JaWam{œfieldNameœ:œtemporal_resolutionœ,œidœ:œCustomComponent-JaWamœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false
      },
      {
        "source": "OpenAIModel-Ra6hC",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-Ra6hCœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-JaWam",
        "targetHandle": "{œfieldNameœ:œdate_rangeœ,œidœ:œCustomComponent-JaWamœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "date_range",
            "id": "CustomComponent-JaWam",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-Ra6hC",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "animated": false,
        "className": "",
        "id": "reactflow__edge-OpenAIModel-Ra6hC{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-Ra6hCœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-JaWam{œfieldNameœ:œdate_rangeœ,œidœ:œCustomComponent-JaWamœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false
      },
      {
        "source": "OpenAIModel-w4BlI",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-w4BlIœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-JaWam",
        "targetHandle": "{œfieldNameœ:œexperimentœ,œidœ:œCustomComponent-JaWamœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "experiment",
            "id": "CustomComponent-JaWam",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-w4BlI",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "animated": false,
        "className": "",
        "id": "reactflow__edge-OpenAIModel-w4BlI{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-w4BlIœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-JaWam{œfieldNameœ:œexperimentœ,œidœ:œCustomComponent-JaWamœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false
      },
      {
        "source": "OpenAIModel-6kjJN",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-6kjJNœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-JaWam",
        "targetHandle": "{œfieldNameœ:œmipœ,œidœ:œCustomComponent-JaWamœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "mip",
            "id": "CustomComponent-JaWam",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-6kjJN",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "animated": false,
        "className": "",
        "id": "reactflow__edge-OpenAIModel-6kjJN{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-6kjJNœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-JaWam{œfieldNameœ:œmipœ,œidœ:œCustomComponent-JaWamœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false
      },
      {
        "source": "ParseData-5KQTl",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-5KQTlœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-QYews",
        "targetHandle": "{œfieldNameœ:œqueryœ,œidœ:œPrompt-QYewsœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "query",
            "id": "Prompt-QYews",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-5KQTl",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-5KQTl{œdataTypeœ:œParseDataœ,œidœ:œParseData-5KQTlœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-QYews{œfieldNameœ:œqueryœ,œidœ:œPrompt-QYewsœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "ParseData-5KQTl",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-5KQTlœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-8BkYc",
        "targetHandle": "{œfieldNameœ:œqueryœ,œidœ:œPrompt-8BkYcœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "query",
            "id": "Prompt-8BkYc",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-5KQTl",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-5KQTl{œdataTypeœ:œParseDataœ,œidœ:œParseData-5KQTlœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-8BkYc{œfieldNameœ:œqueryœ,œidœ:œPrompt-8BkYcœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "ParseData-5KQTl",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-5KQTlœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-s5f6Z",
        "targetHandle": "{œfieldNameœ:œqueryœ,œidœ:œPrompt-s5f6Zœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "query",
            "id": "Prompt-s5f6Z",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-5KQTl",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-5KQTl{œdataTypeœ:œParseDataœ,œidœ:œParseData-5KQTlœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-s5f6Z{œfieldNameœ:œqueryœ,œidœ:œPrompt-s5f6Zœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "ParseData-5KQTl",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-5KQTlœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-dr6NU",
        "targetHandle": "{œfieldNameœ:œqueryœ,œidœ:œPrompt-dr6NUœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "query",
            "id": "Prompt-dr6NU",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-5KQTl",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-5KQTl{œdataTypeœ:œParseDataœ,œidœ:œParseData-5KQTlœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-dr6NU{œfieldNameœ:œqueryœ,œidœ:œPrompt-dr6NUœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "ParseData-5KQTl",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-5KQTlœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-s0t9t",
        "targetHandle": "{œfieldNameœ:œqueryœ,œidœ:œPrompt-s0t9tœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "query",
            "id": "Prompt-s0t9t",
            "inputTypes": [
              "Message",
              "Text"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-5KQTl",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-5KQTl{œdataTypeœ:œParseDataœ,œidœ:œParseData-5KQTlœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-s0t9t{œfieldNameœ:œqueryœ,œidœ:œPrompt-s0t9tœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "ParseData-5KQTl",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-5KQTlœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-JaWam",
        "targetHandle": "{œfieldNameœ:œuser_queryœ,œidœ:œCustomComponent-JaWamœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "user_query",
            "id": "CustomComponent-JaWam",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-5KQTl",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-5KQTl{œdataTypeœ:œParseDataœ,œidœ:œParseData-5KQTlœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-JaWam{œfieldNameœ:œuser_queryœ,œidœ:œCustomComponent-JaWamœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "className": "",
        "animated": false
      },
      {
        "source": "ChatInput-yzRsT",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-yzRsTœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "MessagetoData-wMfau",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œMessagetoData-wMfauœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "message",
            "id": "MessagetoData-wMfau",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-yzRsT",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-yzRsT{œdataTypeœ:œChatInputœ,œidœ:œChatInput-yzRsTœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-MessagetoData-wMfau{œfieldNameœ:œmessageœ,œidœ:œMessagetoData-wMfauœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "MessagetoData-wMfau",
        "sourceHandle": "{œdataTypeœ:œMessagetoDataœ,œidœ:œMessagetoData-wMfauœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-5KQTl",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-5KQTlœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-5KQTl",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "MessagetoData",
            "id": "MessagetoData-wMfau",
            "name": "data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-MessagetoData-wMfau{œdataTypeœ:œMessagetoDataœ,œidœ:œMessagetoData-wMfauœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-ParseData-5KQTl{œfieldNameœ:œdataœ,œidœ:œParseData-5KQTlœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      }
    ],
    "viewport": {
      "x": -3061.783153278097,
      "y": 348.27392979950946,
      "zoom": 0.47138378414825316
    }
  },
  "icon_bg_color": null,
  "user_id": "7a67f6b4-7f06-44c2-bac9-af8d8a0c053a",
  "gradient": null,
  "icon": null,
  "is_component": false,
  "tags": null,
  "updated_at": "2025-03-04T18:32:28+00:00",
  "folder_id": "54aad242-ee9a-4a53-960f-3fe4f6177497",
  "webhook": false
}