{
  "id": "b28b3af9-2779-4d13-a86a-e7235ce95b00",
  "data": {
    "nodes": [
      {
        "id": "ChatInput-nXUUg",
        "type": "genericNode",
        "position": {
          "x": 1136.0836818107007,
          "y": -1476.8237613939023
        },
        "data": {
          "id": "ChatInput-nXUUg",
          "node": {
            "template": {
              "_type": "Component",
              "files": {
                "trace_as_metadata": true,
                "file_path": "",
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "list": true,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "files",
                "value": "",
                "display_name": "Files",
                "advanced": true,
                "dynamic": false,
                "info": "Files to be sent with the message.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput"
              },
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        background_color = self.background_color\n        text_color = self.text_color\n        icon = self.chat_icon\n\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\n                \"background_color\": background_color,\n                \"text_color\": text_color,\n                \"icon\": icon,\n            },\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "Provide all the times Ames, Iowa had over 50 frost days from 1980 to 2014 in a historical simulation.",
                "display_name": "Text",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "Message to be passed as input.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "User",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Get chat inputs from the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Input",
            "documentation": "",
            "minimized": true,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "hidden": null,
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "type": "ChatInput",
          "description": "Get chat inputs from the Playground.",
          "display_name": "Dataset Description"
        },
        "selected": false,
        "width": 320,
        "height": 233,
        "positionAbsolute": {
          "x": 1136.0836818107007,
          "y": -1476.8237613939023
        },
        "dragging": false,
        "measured": {
          "width": 320,
          "height": 233
        }
      },
      {
        "id": "CMIP6DatasetProcessorComponent-TaOPv",
        "type": "genericNode",
        "position": {
          "x": 2135.035516520518,
          "y": -2749.5015248796835
        },
        "data": {
          "type": "CMIP6DatasetProcessorComponent",
          "node": {
            "template": {
              "_type": "Component",
              "csv_file": {
                "trace_as_metadata": true,
                "file_path": "1cecff9d-0db7-4c8f-a807-ae301f84ab25/2025-03-04_18-26-01_model_experiment_fields_ScenarioMIP_CMIP_filename_dates (1).csv",
                "fileTypes": [
                  "csv"
                ],
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "csv_file",
                "value": "",
                "display_name": "CSV File",
                "advanced": false,
                "dynamic": false,
                "info": "Upload the CSV file containing CMIP6 dataset information.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput",
                "load_from_db": false
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import pandas as pd\r\nimport numpy as np\r\nfrom pathlib import Path\r\nfrom langflow.custom import Component\r\nfrom langflow.io import FileInput, MessageTextInput, Output\r\nfrom langflow.schema.data import Data\r\n\r\nclass CMIP6DatasetProcessorComponent(Component):\r\n    display_name = \"CMIP6 Dataset Processor\"\r\n    description = \"Process a CSV file containing CMIP6 dataset information into a usable DataFrame.\"\r\n    icon = \"table\"\r\n    \r\n    inputs = [\r\n        FileInput(\r\n            name=\"csv_file\",\r\n            display_name=\"CSV File\",\r\n            file_types=[\"csv\"],\r\n            info=\"Upload the CSV file containing CMIP6 dataset information.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"csv_path\",\r\n            display_name=\"CSV File Path\",\r\n            info=\"Provide the path to the CSV file as pure text\",\r\n        ),\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(display_name=\"Processed DataFrame\", name=\"processed_df\", method=\"process_csv\"),\r\n        Output(display_name=\"Unique MIPs\", name=\"unique_mips\", method=\"get_unique_mips\"),\r\n        Output(display_name=\"Unique Experiments\", name=\"unique_experiments\", method=\"get_unique_experiments\"),\r\n    ]\r\n\r\n    def _process_dataframe(self):\r\n        \"\"\"Helper method to process the dataframe and cache it for multiple outputs\"\"\"\r\n        if not hasattr(self, '_cached_df'):\r\n            if sum(bool(field) for field in [self.csv_file, self.csv_path]) != 1:\r\n                raise ValueError(\"Please provide exactly one of: CSV file or file path.\")\r\n            \r\n            try:\r\n                # Read the CSV file based on input type\r\n                if self.csv_file:\r\n                    df = pd.read_csv(self.csv_file)\r\n                else:\r\n                    if not Path(self.csv_path).exists():\r\n                        raise FileNotFoundError(f\"File not found: {self.csv_path}\")\r\n                    df = pd.read_csv(self.csv_path)\r\n                \r\n                # Process the DataFrame as before\r\n                df['collection'] = 'giss_cmip6'\r\n                df['org'] = 'NASA-GISS'\r\n                \r\n                # Select and rename columns\r\n                df = df[['collection', 'MIP', 'org', 'model', 'experiment', 'variant', \r\n                         'tableID', 'variable', 'grid', 'version', 'start_YM', 'end_YM', 'filename']]\r\n                df.columns = ['collection', 'MIP', 'org', 'model', 'experiment', 'variant', \r\n                             'temporal resolution', 'variable', 'grid', 'version', 'start year', 'end year', 'filename']\r\n                \r\n                # Rest of the processing...\r\n                df = df.astype(str)\r\n                \r\n                def generate_url(x):\r\n                    cols = '/'.join([val for val in x])\r\n                    return 'https://portal.nccs.nasa.gov/datashare/' + cols\r\n                \r\n                url_col_names = df.columns[:-3].to_list() + ['filename']\r\n                urldf = df[url_col_names]\r\n                df['URL'] = urldf.apply(lambda x: generate_url(x), axis=1)\r\n                \r\n                def safe_year_convert(x):\r\n                    try:\r\n                        return int(x[:4])\r\n                    except ValueError:\r\n                        return np.nan\r\n                \r\n                df['start year'] = df['start year'].apply(safe_year_convert)\r\n                df['end year'] = df['end year'].apply(safe_year_convert)\r\n                \r\n                df = df.sort_values(df.columns.to_list(), ascending=True).drop_duplicates(\r\n                    subset=set(df.columns.to_list()) - set(['version', 'filename', 'URL']),\r\n                    ignore_index=True, keep='last')\r\n                \r\n                def clean_resolution(reso):\r\n                    resos = ['hr', 'day', 'mon']\r\n                    for q in resos:\r\n                        if q in reso:\r\n                            return q\r\n                    return 'NA'\r\n                \r\n                df['temporal resolution'] = df.apply(lambda x: clean_resolution(x['temporal resolution']), axis=1)\r\n                \r\n                self._cached_df = df\r\n                \r\n            except Exception as e:\r\n                raise ValueError(f\"Error processing CSV: {str(e)}\")\r\n        \r\n        return self._cached_df\r\n\r\n    def process_csv(self) -> Data:\r\n        try:\r\n            df = self._process_dataframe()\r\n            self.status = f\"DataFrame processed successfully. Shape: {df.shape}\"\r\n            return Data(data={\"df\": df})\r\n        except Exception as e:\r\n            error_message = f\"Error processing CSV: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})\r\n\r\n    def get_unique_mips(self) -> list[Data]:\r\n        \"\"\"Return a list of Data objects containing unique MIP values\"\"\"\r\n        try:\r\n            df = self._process_dataframe()\r\n            unique_mips = df['MIP'].unique().tolist()\r\n            return [Data(data={\"MIP\": mip}) for mip in sorted(unique_mips)]\r\n        except Exception as e:\r\n            error_message = f\"Error getting unique MIPs: {str(e)}\"\r\n            self.status = error_message\r\n            return [Data(data={\"error\": error_message})]\r\n\r\n    def get_unique_experiments(self) -> list[Data]:\r\n        \"\"\"Return a list of Data objects containing unique experiment values\"\"\"\r\n        try:\r\n            df = self._process_dataframe()\r\n            unique_experiments = df['experiment'].unique().tolist()\r\n            return [Data(data={\"experiment\": exp}) for exp in sorted(unique_experiments)]\r\n        except Exception as e:\r\n            error_message = f\"Error getting unique experiments: {str(e)}\"\r\n            self.status = error_message\r\n            return [Data(data={\"error\": error_message})]",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "csv_path": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "csv_path",
                "value": "",
                "display_name": "CSV File Path",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Provide the path to the CSV file as pure text",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Process a CSV file containing CMIP6 dataset information into a usable DataFrame.",
            "icon": "table",
            "base_classes": [
              "Data"
            ],
            "display_name": "CMIP6 Dataset Processor",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": true,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "processed_df",
                "display_name": "Processed DataFrame",
                "method": "process_csv",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "unique_mips",
                "display_name": "Unique MIPs",
                "method": "get_unique_mips",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "unique_experiments",
                "display_name": "Unique Experiments",
                "method": "get_unique_experiments",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "csv_file",
              "csv_path"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.2.0"
          },
          "id": "CMIP6DatasetProcessorComponent-TaOPv"
        },
        "selected": false,
        "width": 320,
        "height": 433,
        "dragging": false,
        "positionAbsolute": {
          "x": 2135.035516520518,
          "y": -2749.5015248796835
        },
        "measured": {
          "width": 320,
          "height": 433
        }
      },
      {
        "id": "CMIP6VariableProcessorFromZip-X8bHD",
        "type": "genericNode",
        "position": {
          "x": 3249.743385806226,
          "y": -2877.5011036218298
        },
        "data": {
          "type": "CMIP6VariableProcessorFromZip",
          "node": {
            "template": {
              "_type": "Component",
              "dataset_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dataset_info",
                "value": "",
                "display_name": "Dataset Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Processed CMIP6 dataset information for filtering variables.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "embeddings": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embeddings",
                "value": "",
                "display_name": "Embeddings",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "Embeddings component for generating embeddings.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "zip_file": {
                "trace_as_metadata": true,
                "file_path": "1cecff9d-0db7-4c8f-a807-ae301f84ab25/2025-03-04_18-25-44_cmip6-cmor-tables-main.zip",
                "fileTypes": [
                  "zip"
                ],
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "zip_file",
                "value": "",
                "display_name": "Zip File",
                "advanced": false,
                "dynamic": false,
                "info": "Upload a zip file containing CMIP6 JSON files.",
                "title_case": false,
                "type": "file",
                "_input_type": "FileInput",
                "load_from_db": false
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import zipfile\r\nimport json\r\nimport pandas as pd\r\nimport numpy as np\r\nfrom pathlib import Path\r\nfrom langflow.custom import Component\r\nfrom langflow.io import FileInput, HandleInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass CMIP6VariableProcessorFromZip(Component):\r\n    display_name = \"CMIP6 Variable Processor (Zip)\"\r\n    description = \"Processes CMIP6 variable information JSON files from a zip file and generates embeddings.\"\r\n    icon = \"file-zip\"\r\n    \r\n    inputs = [\r\n        FileInput(\r\n            name=\"zip_file\",\r\n            display_name=\"Zip File\",\r\n            file_types=[\"zip\"],\r\n            info=\"Upload a zip file containing CMIP6 JSON files.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"zip_path\",\r\n            display_name=\"Zip File Path\",\r\n            info=\"Provide the path to the zip file as pure text\",\r\n        ),\r\n        HandleInput(\r\n            name=\"dataset_info\",\r\n            display_name=\"Dataset Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Processed CMIP6 dataset information for filtering variables.\",\r\n        ),\r\n        HandleInput(\r\n            name=\"embeddings\",\r\n            display_name=\"Embeddings\",\r\n            input_types=[\"Embeddings\"],\r\n            info=\"Embeddings component for generating embeddings.\",\r\n        ),\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(display_name=\"CMIP6 Variable Info\", name=\"variable_info\", method=\"process_zip_file\"),\r\n    ]\r\n\r\n    def process_zip_file(self) -> Data:\r\n        # Validate inputs\r\n        if sum(bool(field) for field in [self.zip_file, self.zip_path]) != 1:\r\n            raise ValueError(\"Please provide exactly one of: zip file or file path.\")\r\n\r\n        try:\r\n            # Get the correct file path\r\n            if self.zip_file:\r\n                file_path = self.resolve_path(self.zip_file)\r\n            else:\r\n                file_path = self.zip_path\r\n                if not Path(file_path).exists():\r\n                    raise FileNotFoundError(f\"File not found: {file_path}\")\r\n\r\n            # Process the zip file\r\n            jdfs = []\r\n            with zipfile.ZipFile(file_path, 'r') as zip_ref:\r\n                for file_name in zip_ref.namelist():\r\n                    if file_name.endswith('.json') and 'Tables' in file_name:\r\n                        self.log(f\"Processing file: {file_name}\")\r\n                        with zip_ref.open(file_name) as file:\r\n                            content = file.read()\r\n                            d = json.loads(content.decode('utf-8'))\r\n                            try:\r\n                                jdf = pd.DataFrame.from_dict(d['variable_entry'], orient='index')\r\n                                jdf['temporal resolution'] = file_name.split('_')[-1].split('.')[0]\r\n                                jdfs.append(jdf)\r\n                            except KeyError:\r\n                                self.log(f\"Skipping {file_name} due to formatting issue\")\r\n\r\n            if not jdfs:\r\n                raise ValueError(\"No valid JSON files were found in the zip file\")\r\n\r\n            # Create the combined DataFrame\r\n            varsdf = pd.concat(jdfs)\r\n            varsdf.rename(columns={'out_name': 'variable'}, inplace=True)\r\n            varsdf = varsdf.loc[:, ['long_name', 'comment', 'variable']]\r\n            varsdf.drop_duplicates(inplace=True)\r\n            \r\n            # Create extended comment\r\n            varsdf['extended_comment'] = varsdf.apply(\r\n                lambda x: f\"{x['long_name']} ({x['variable']}): {x['comment']}\", \r\n                axis=1\r\n            )\r\n            \r\n            # Filter variables based on the dataset_info\r\n            if isinstance(self.dataset_info, Data) and 'df' in self.dataset_info.data:\r\n                df = pd.DataFrame(self.dataset_info.data['df'])\r\n                varsdf = varsdf[varsdf['variable'].isin(df['variable'].unique())]\r\n            else:\r\n                self.log(\"Warning: No dataset info provided for filtering variables.\")\r\n\r\n            # Generate embeddings\r\n            varsdf.loc[varsdf['extended_comment'].isna(), 'extended_comment'] = ''\r\n            varsdf['embeds'] = list(np.asarray(\r\n                self.embeddings.embed_documents(varsdf['extended_comment'].tolist())\r\n            ))\r\n\r\n            self.status = f\"Variable info processed and embeddings generated successfully. Shape: {varsdf.shape}\"\r\n            return Data(data={\"variable_info\": varsdf})\r\n\r\n        except Exception as e:\r\n            error_message = f\"Error processing zip file or generating embeddings: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "zip_path": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "zip_path",
                "value": "",
                "display_name": "Zip File Path",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Provide the path to the zip file as pure text",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Processes CMIP6 variable information JSON files from a zip file and generates embeddings.",
            "icon": "file-zip",
            "base_classes": [
              "Data"
            ],
            "display_name": "CMIP6 Variable Processor (Zip)",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": true,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "variable_info",
                "display_name": "CMIP6 Variable Info",
                "method": "process_zip_file",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "zip_file",
              "zip_path",
              "dataset_info",
              "embeddings"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.2.0"
          },
          "id": "CMIP6VariableProcessorFromZip-X8bHD"
        },
        "selected": false,
        "width": 320,
        "height": 367,
        "positionAbsolute": {
          "x": 3249.743385806226,
          "y": -2877.5011036218298
        },
        "dragging": false,
        "measured": {
          "width": 320,
          "height": 367
        }
      },
      {
        "id": "variable_matcher-S6K64",
        "type": "genericNode",
        "position": {
          "x": 6506.221303108063,
          "y": -2121.814126395997
        },
        "data": {
          "type": "variable_matcher",
          "node": {
            "template": {
              "_type": "Component",
              "variable_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "variable_info",
                "value": "",
                "display_name": "Variable Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Processed CMIP6 variable information from the previous component.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from typing import List, Dict, Any\r\nfrom pydantic import BaseModel, Field\r\nimport pandas as pd\r\n\r\nfrom langflow.base.langchain_utilities.model import LCToolComponent\r\nfrom langflow.io import HandleInput, MessageTextInput, IntInput, Output\r\nfrom langflow.schema import Data\r\nfrom langflow.field_typing import Tool\r\nfrom langchain.tools import StructuredTool\r\n\r\nclass VariableMatcherToolComponent(LCToolComponent):\r\n    display_name = \"CMIP6 Variable Matcher\"\r\n    description = \"Filters CMIP6 variables based on exact variable name matches.\"\r\n    icon = \"match\"\r\n    name = \"variable_matcher\"\r\n    \r\n    inputs = [\r\n        HandleInput(\r\n            name=\"variable_info\",\r\n            display_name=\"Variable Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Processed CMIP6 variable information from the previous component.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"variable_name\",\r\n            display_name=\"Variable Name\",\r\n            info=\"The exact variable name to filter for (e.g., 'tas').\",\r\n        ),\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(display_name=\"Matched Variables\", name=\"matched_variables\", method=\"match_variables\"),\r\n        Output(display_name=\"Tool\", name=\"tool\", method=\"build_tool\"),\r\n    ]\r\n\r\n    class VariableMatcherSchema(BaseModel):\r\n        variable_name: str = Field(\r\n            ..., \r\n            description=\"The exact variable name to filter for (e.g., 'tas')\"\r\n        )\r\n\r\n    def _process_matches(self, variable_name: str) -> List[Dict[str, Any]]:\r\n        \"\"\"Internal method to filter variables by exact name match\"\"\"\r\n        if not isinstance(self.variable_info, Data) or 'variable_info' not in self.variable_info.data:\r\n            raise ValueError(\"Invalid variable info input. Expected Data object with 'variable_info' key.\")\r\n        \r\n        varsdf = self.variable_info.data['variable_info']\r\n        \r\n        try:\r\n            # Filter for exact matches\r\n            filtered_df = varsdf[varsdf['variable'].str.lower() == variable_name.lower()]\r\n            \r\n            if filtered_df.empty:\r\n                return [{\"message\": f\"No matches found for variable '{variable_name}'\"}]\r\n            \r\n            # Convert results to list of dictionaries\r\n            results = [\r\n                {\r\n                    'variable': row['variable'],\r\n                    'long_name': row['long_name'],\r\n                    'comment': row['comment'],\r\n                }\r\n                for _, row in filtered_df.iterrows()\r\n            ]\r\n            \r\n            return results\r\n\r\n        except Exception as e:\r\n            return [{\"error\": f\"Error filtering variables: {str(e)}\"}]\r\n\r\n    def match_variables(self) -> List[Data]:\r\n        \"\"\"Method for component output\"\"\"\r\n        try:\r\n            results = self._process_matches(self.variable_name)\r\n            data_list = [Data(data=result) for result in results]\r\n            self.status = data_list\r\n            return data_list\r\n            \r\n        except Exception as e:\r\n            error_message = f\"Error matching variables: {str(e)}\"\r\n            self.status = error_message\r\n            return [Data(data={\"error\": error_message})]\r\n\r\n    def build_tool(self) -> Tool:\r\n        \"\"\"Build and return the tool\"\"\"\r\n        return StructuredTool.from_function(\r\n            name=\"variable_matcher\",\r\n            description=\"Filter CMIP6 variables by exact variable name match. \"\r\n                      \"Input should be the exact variable name (e.g., 'tas').\",\r\n            func=self._tool_function,\r\n            args_schema=self.VariableMatcherSchema,\r\n        )\r\n\r\n    def _tool_function(self, variable_name: str) -> List[Dict[str, Any]]:\r\n        \"\"\"Function to be called by the tool\"\"\"\r\n        try:\r\n            return self._process_matches(variable_name)\r\n        except Exception as e:\r\n            return [{\"error\": f\"Error matching variables: {str(e)}\"}]",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "variable_name": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "variable_name",
                "value": "",
                "display_name": "Variable Name",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The exact variable name to filter for (e.g., 'tas').",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Filters CMIP6 variables based on exact variable name matches.",
            "icon": "match",
            "base_classes": [
              "Data",
              "Tool"
            ],
            "display_name": "CMIP6 Variable Matcher",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "matched_variables",
                "display_name": "Matched Variables",
                "method": "match_variables",
                "value": "__UNDEFINED__",
                "cache": true
              },
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              }
            ],
            "field_order": [
              "variable_info",
              "variable_name"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.2.0"
          },
          "id": "variable_matcher-S6K64"
        },
        "selected": false,
        "width": 320,
        "height": 301,
        "dragging": false,
        "positionAbsolute": {
          "x": 5643.319471179704,
          "y": -1459.7994934350872
        },
        "measured": {
          "width": 320,
          "height": 301
        }
      },
      {
        "id": "OpenAIEmbeddings-XsKPV",
        "type": "genericNode",
        "position": {
          "x": 2888.1600442024533,
          "y": -2819.285701514933
        },
        "data": {
          "type": "OpenAIEmbeddings",
          "node": {
            "template": {
              "_type": "Component",
              "chunk_size": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chunk_size",
                "value": 1000,
                "display_name": "Chunk Size",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "client": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "client",
                "value": "",
                "display_name": "Client",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_openai import OpenAIEmbeddings\n\nfrom langflow.base.embeddings.model import LCEmbeddingsModel\nfrom langflow.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass OpenAIEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIEmbeddings\"\n\n    inputs = [\n        DictInput(\n            name=\"default_headers\",\n            display_name=\"Default Headers\",\n            advanced=True,\n            info=\"Default headers to use for the API request.\",\n        ),\n        DictInput(\n            name=\"default_query\",\n            display_name=\"Default Query\",\n            advanced=True,\n            info=\"Default query parameters to use for the API request.\",\n        ),\n        IntInput(name=\"chunk_size\", display_name=\"Chunk Size\", advanced=True, value=1000),\n        MessageTextInput(name=\"client\", display_name=\"Client\", advanced=True),\n        MessageTextInput(name=\"deployment\", display_name=\"Deployment\", advanced=True),\n        IntInput(name=\"embedding_ctx_length\", display_name=\"Embedding Context Length\", advanced=True, value=1536),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=\"text-embedding-3-small\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\", required=True),\n        MessageTextInput(name=\"openai_api_base\", display_name=\"OpenAI API Base\", advanced=True),\n        MessageTextInput(name=\"openai_api_type\", display_name=\"OpenAI API Type\", advanced=True),\n        MessageTextInput(name=\"openai_api_version\", display_name=\"OpenAI API Version\", advanced=True),\n        MessageTextInput(\n            name=\"openai_organization\",\n            display_name=\"OpenAI Organization\",\n            advanced=True,\n        ),\n        MessageTextInput(name=\"openai_proxy\", display_name=\"OpenAI Proxy\", advanced=True),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n        BoolInput(name=\"show_progress_bar\", display_name=\"Show Progress Bar\", advanced=True),\n        BoolInput(name=\"skip_empty\", display_name=\"Skip Empty\", advanced=True),\n        MessageTextInput(\n            name=\"tiktoken_model_name\",\n            display_name=\"TikToken Model Name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tiktoken_enable\",\n            display_name=\"TikToken Enable\",\n            advanced=True,\n            value=True,\n            info=\"If False, you must have transformers installed.\",\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. \"\n            \"Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return OpenAIEmbeddings(\n            client=self.client or None,\n            model=self.model,\n            dimensions=self.dimensions or None,\n            deployment=self.deployment or None,\n            api_version=self.openai_api_version or None,\n            base_url=self.openai_api_base or None,\n            openai_api_type=self.openai_api_type or None,\n            openai_proxy=self.openai_proxy or None,\n            embedding_ctx_length=self.embedding_ctx_length,\n            api_key=self.openai_api_key or None,\n            organization=self.openai_organization or None,\n            allowed_special=\"all\",\n            disallowed_special=\"all\",\n            chunk_size=self.chunk_size,\n            max_retries=self.max_retries,\n            timeout=self.request_timeout or None,\n            tiktoken_enabled=self.tiktoken_enable,\n            tiktoken_model_name=self.tiktoken_model_name or None,\n            show_progress_bar=self.show_progress_bar,\n            model_kwargs=self.model_kwargs,\n            skip_empty=self.skip_empty,\n            default_headers=self.default_headers or None,\n            default_query=self.default_query or None,\n        )\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "default_headers": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "default_headers",
                "value": {},
                "display_name": "Default Headers",
                "advanced": true,
                "dynamic": false,
                "info": "Default headers to use for the API request.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "default_query": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "default_query",
                "value": {},
                "display_name": "Default Query",
                "advanced": true,
                "dynamic": false,
                "info": "Default query parameters to use for the API request.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "deployment": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "deployment",
                "value": "",
                "display_name": "Deployment",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "dimensions": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dimensions",
                "value": "",
                "display_name": "Dimensions",
                "advanced": true,
                "dynamic": false,
                "info": "The number of dimensions the resulting output embeddings should have. Only supported by certain models.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "embedding_ctx_length": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embedding_ctx_length",
                "value": 1536,
                "display_name": "Embedding Context Length",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "max_retries": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_retries",
                "value": 3,
                "display_name": "Max Retries",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "text-embedding-3-small",
                  "text-embedding-3-large",
                  "text-embedding-ada-002"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model",
                "value": "text-embedding-3-large",
                "display_name": "Model",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "model_kwargs": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "openai_api_base": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_api_key": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "openai_api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "openai_api_type": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_type",
                "value": "",
                "display_name": "OpenAI API Type",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_api_version": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_version",
                "value": "",
                "display_name": "OpenAI API Version",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_organization": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_organization",
                "value": "",
                "display_name": "OpenAI Organization",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "openai_proxy": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_proxy",
                "value": "",
                "display_name": "OpenAI Proxy",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "request_timeout": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "request_timeout",
                "value": "",
                "display_name": "Request Timeout",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              },
              "show_progress_bar": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "show_progress_bar",
                "value": false,
                "display_name": "Show Progress Bar",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "skip_empty": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "skip_empty",
                "value": false,
                "display_name": "Skip Empty",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "tiktoken_enable": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tiktoken_enable",
                "value": true,
                "display_name": "TikToken Enable",
                "advanced": true,
                "dynamic": false,
                "info": "If False, you must have transformers installed.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "tiktoken_model_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tiktoken_model_name",
                "value": "",
                "display_name": "TikToken Model Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Generate embeddings using OpenAI models.",
            "icon": "OpenAI",
            "base_classes": [
              "Embeddings"
            ],
            "display_name": "OpenAI Embeddings",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Embeddings"
                ],
                "selected": "Embeddings",
                "name": "embeddings",
                "hidden": null,
                "display_name": "Embeddings",
                "method": "build_embeddings",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [
                  "openai_api_key"
                ],
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "default_headers",
              "default_query",
              "chunk_size",
              "client",
              "deployment",
              "embedding_ctx_length",
              "max_retries",
              "model",
              "model_kwargs",
              "openai_api_key",
              "openai_api_base",
              "openai_api_type",
              "openai_api_version",
              "openai_organization",
              "openai_proxy",
              "request_timeout",
              "show_progress_bar",
              "skip_empty",
              "tiktoken_model_name",
              "tiktoken_enable",
              "dimensions"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "id": "OpenAIEmbeddings-XsKPV",
          "description": "Generate embeddings using OpenAI models.",
          "display_name": "OpenAI Embeddings"
        },
        "selected": false,
        "width": 320,
        "height": 321,
        "dragging": false,
        "positionAbsolute": {
          "x": 2888.1600442024533,
          "y": -2819.285701514933
        },
        "measured": {
          "width": 320,
          "height": 321
        }
      },
      {
        "id": "TemporalResolutionFilterComponent-3pGxq",
        "type": "genericNode",
        "position": {
          "x": 6977.472573856476,
          "y": -1887.2218000794724
        },
        "data": {
          "type": "TemporalResolutionFilterComponent",
          "node": {
            "template": {
              "_type": "Component",
              "dataset_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dataset_info",
                "value": "",
                "display_name": "Dataset Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Processed CMIP6 dataset information from the CMIP6 Dataset Processor.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "matched_variables": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "matched_variables",
                "value": "",
                "display_name": "Matched Variables",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Matched variables from the CMIP6 Variable Matcher.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\r\nfrom langflow.io import HandleInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass TemporalResolutionFilterComponent(Component):\r\n    display_name = \"Temporal Resolution Filter\"\r\n    description = \"Filters CMIP6 datasets based on temporal resolution and matched variables.\"\r\n    icon = \"filter\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"dataset_info\",\r\n            display_name=\"Dataset Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Processed CMIP6 dataset information from the CMIP6 Dataset Processor.\",\r\n        ),\r\n        HandleInput(\r\n            name=\"matched_variables\",\r\n            display_name=\"Matched Variables\",\r\n            input_types=[\"Data\"],\r\n            info=\"Matched variables from the CMIP6 Variable Matcher.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"resolution\",\r\n            display_name=\"Temporal Resolution\",\r\n            info=\"Enter the desired temporal resolution (e.g., hr, day, mon, fx).\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Filtered Datasets\", name=\"filtered_datasets\", method=\"filter_datasets\"),\r\n    ]\r\n\r\n    def filter_datasets(self) -> Data:\r\n        if not isinstance(self.dataset_info, Data) or 'df' not in self.dataset_info.data:\r\n            raise ValueError(\"Invalid dataset info input. Expected Data object with 'df' key.\")\r\n\r\n        if not isinstance(self.matched_variables, list) or not all(isinstance(x, Data) for x in self.matched_variables):\r\n            raise ValueError(\"Invalid matched variables input. Expected list of Data objects.\")\r\n\r\n        df = self.dataset_info.data['df']\r\n\r\n        if 'temporal resolution' not in df.columns or 'variable' not in df.columns:\r\n            raise ValueError(\"Expected 'temporal resolution' and 'variable' columns in dataset info DataFrame.\")\r\n\r\n        try:\r\n            resolution = self.resolution.strip().lower()\r\n            \r\n            # Get the list of matched variable names\r\n            matched_var_names = [v.data['variable'] for v in self.matched_variables if 'variable' in v.data]\r\n            \r\n            # Filter the dataset\r\n            filtered_df = df[\r\n                (df['temporal resolution'] == resolution) &\r\n                (df['variable'].isin(matched_var_names))\r\n            ]\r\n            \r\n            self.status = f\"Filtered {len(filtered_df)} datasets with {resolution} temporal resolution and matching variables.\"\r\n            return Data(data={\"filtered_df\": filtered_df})\r\n\r\n        except Exception as e:\r\n            error_message = f\"Error filtering datasets: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "resolution": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "resolution",
                "value": "",
                "display_name": "Temporal Resolution",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Enter the desired temporal resolution (e.g., hr, day, mon, fx).",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Filters CMIP6 datasets based on temporal resolution and matched variables.",
            "icon": "filter",
            "base_classes": [
              "Data"
            ],
            "display_name": "Temporal Resolution Filter",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "filtered_datasets",
                "display_name": "Filtered Datasets",
                "method": "filter_datasets",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "dataset_info",
              "matched_variables",
              "resolution"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.2.0"
          },
          "id": "TemporalResolutionFilterComponent-3pGxq"
        },
        "selected": false,
        "width": 320,
        "height": 349,
        "dragging": false,
        "positionAbsolute": {
          "x": 6114.570741928117,
          "y": -1225.2071671185627
        },
        "measured": {
          "width": 320,
          "height": 349
        }
      },
      {
        "id": "YearRangeFilterComponent-VS8WD",
        "type": "genericNode",
        "position": {
          "x": 7434.966354097621,
          "y": -1671.115317791148
        },
        "data": {
          "type": "YearRangeFilterComponent",
          "node": {
            "template": {
              "_type": "Component",
              "dataset_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dataset_info",
                "value": "",
                "display_name": "Dataset Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Processed CMIP6 dataset information from the previous filter.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\r\nfrom langflow.io import HandleInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass YearRangeFilterComponent(Component):\r\n    display_name = \"Year Range Filter\"\r\n    description = \"Filters CMIP6 datasets based on a specified year range.\"\r\n    icon = \"calendar\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"dataset_info\",\r\n            display_name=\"Dataset Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Processed CMIP6 dataset information from the previous filter.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"year_range\",\r\n            display_name=\"Year Range\",\r\n            info=\"The year range for filtering (format: START-END, e.g., '1980-2014' or '1000-NA' or 'NA-2100').\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Filtered Datasets\", name=\"filtered_datasets\", method=\"filter_datasets\"),\r\n    ]\r\n\r\n    def parse_year_range(self, year_range: str):\r\n        start, end = year_range.split('-')\r\n        start = int(start) if start.lower() != 'na' else None\r\n        end = int(end) if end.lower() != 'na' else None\r\n        return start, end\r\n\r\n    def filter_datasets(self) -> Data:\r\n        if not isinstance(self.dataset_info, Data) or 'filtered_df' not in self.dataset_info.data:\r\n            raise ValueError(\"Invalid dataset info input. Expected Data object with 'filtered_df' key.\")\r\n\r\n        df = self.dataset_info.data['filtered_df']\r\n\r\n        if 'start year' not in df.columns or 'end year' not in df.columns:\r\n            raise ValueError(\"Expected 'start year' and 'end year' columns in dataset info DataFrame.\")\r\n\r\n        try:\r\n            start_year, end_year = self.parse_year_range(self.year_range.strip())\r\n            \r\n            if start_year is not None:\r\n                df = df[df['end year'] >= start_year]\r\n            if end_year is not None:\r\n                df = df[df['start year'] <= end_year]\r\n            \r\n            year_range_str = f\"{start_year if start_year else 'NA'}-{end_year if end_year else 'NA'}\"\r\n            self.status = f\"Filtered datasets within the year range {year_range_str}. {len(df)} datasets remain.\"\r\n            return Data(data={\"filtered_df\": df})\r\n\r\n        except ValueError:\r\n            error_message = \"Invalid year range input. Please enter a valid range (e.g., '1980-2014' or '1000-NA' or 'NA-2100').\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})\r\n        except Exception as e:\r\n            error_message = f\"Error filtering datasets: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "year_range": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "year_range",
                "value": "",
                "display_name": "Year Range",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The year range for filtering (format: START-END, e.g., '1980-2014' or '1000-NA' or 'NA-2100').",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Filters CMIP6 datasets based on a specified year range.",
            "icon": "calendar",
            "base_classes": [
              "Data"
            ],
            "display_name": "Year Range Filter",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "filtered_datasets",
                "display_name": "Filtered Datasets",
                "method": "filter_datasets",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "dataset_info",
              "year_range"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.2.0"
          },
          "id": "YearRangeFilterComponent-VS8WD"
        },
        "selected": false,
        "width": 320,
        "height": 301,
        "dragging": false,
        "positionAbsolute": {
          "x": 6572.064522169262,
          "y": -1009.1006848302384
        },
        "measured": {
          "width": 320,
          "height": 301
        }
      },
      {
        "id": "URLExtractorComponent-mEoFP",
        "type": "genericNode",
        "position": {
          "x": 7853.689701687734,
          "y": -1411.5418461853583
        },
        "data": {
          "type": "URLExtractorComponent",
          "node": {
            "template": {
              "_type": "Component",
              "dataset_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dataset_info",
                "value": "",
                "display_name": "Filtered Dataset Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Filtered CMIP6 dataset information from the previous filters.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\r\nfrom langflow.io import HandleInput, IntInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass URLExtractorComponent(Component):\r\n    display_name = \"URL Extractor\"\r\n    description = \"Extracts URLs from filtered CMIP6 datasets.\"\r\n    icon = \"link\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"dataset_info\",\r\n            display_name=\"Filtered Dataset Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Filtered CMIP6 dataset information from the previous filters.\",\r\n        ),\r\n        IntInput(\r\n            name=\"max_urls\",\r\n            display_name=\"Maximum URLs\",\r\n            info=\"Maximum number of URLs to extract (0 for all).\",\r\n            value=5,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Extracted URLs\", name=\"extracted_urls\", method=\"extract_urls\"),\r\n    ]\r\n\r\n    def extract_urls(self) -> Data:\r\n        if not isinstance(self.dataset_info, Data) or 'filtered_df' not in self.dataset_info.data:\r\n            raise ValueError(\"Invalid dataset info input. Expected Data object with 'filtered_df' key.\")\r\n\r\n        df = self.dataset_info.data['filtered_df']\r\n\r\n        if 'URL' not in df.columns:\r\n            raise ValueError(\"Expected 'URL' column in dataset info DataFrame.\")\r\n\r\n        try:\r\n            if self.max_urls > 0:\r\n                urls = df['URL'].head(self.max_urls).tolist()\r\n            else:\r\n                urls = df['URL'].tolist()\r\n\r\n            result = []\r\n            for i, url in enumerate(urls, 1):\r\n                result.append(Data(data={\r\n                    \"url\": url,\r\n                    \"index\": i,\r\n                    \"filename\": url.split('/')[-1]\r\n                }))\r\n\r\n            self.status = result\r\n            return result\r\n\r\n        except Exception as e:\r\n            error_message = f\"Error extracting URLs: {str(e)}\"\r\n            self.status = error_message\r\n            return [Data(data={\"error\": error_message})]",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "max_urls": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_urls",
                "value": 1,
                "display_name": "Maximum URLs",
                "advanced": false,
                "dynamic": false,
                "info": "Maximum number of URLs to extract (0 for all).",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput",
                "load_from_db": false
              }
            },
            "description": "Extracts URLs from filtered CMIP6 datasets.",
            "icon": "link",
            "base_classes": [
              "Data"
            ],
            "display_name": "URL Extractor",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "extracted_urls",
                "display_name": "Extracted URLs",
                "method": "extract_urls",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "dataset_info",
              "max_urls"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.2.0"
          },
          "id": "URLExtractorComponent-mEoFP"
        },
        "selected": false,
        "width": 320,
        "height": 281,
        "positionAbsolute": {
          "x": 6990.787869759375,
          "y": -749.5272132244486
        },
        "dragging": false,
        "measured": {
          "width": 320,
          "height": 281
        }
      },
      {
        "id": "Prompt-LB8oS",
        "type": "genericNode",
        "position": {
          "x": 3275.87882069038,
          "y": 139.50954830557845
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "You are an expert climate scientist. \n\nDoes the following CMIP6 query require or specify a year range for the data required to answer.\n\nIf yes, provide the year range in format START-END, for instance 196001-197012 or 201501-205012 If no, respond NA-NA. \n\nIf only the start or end is specified, provide just that year in format START-NA (eg 210001-NA) or NA-END (eg NA-190012).\n\nProvide only the year range in this format and nothing else.\n\nToday is: {current_date}\n\n\nQuery: ",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput",
                "load_from_db": false
              },
              "tool_placeholder": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tool_placeholder",
                "value": "",
                "display_name": "Tool Placeholder",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "current_date": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "current_date",
                "display_name": "current_date",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "minimized": false,
            "custom_fields": {
              "template": [
                "current_date"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "beta": false,
            "legacy": false,
            "error": null,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "id": "Prompt-LB8oS",
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Date Range Prompt"
        },
        "selected": false,
        "width": 320,
        "height": 431,
        "dragging": false,
        "positionAbsolute": {
          "x": 3264.4647752945025,
          "y": -123.01349579960996
        },
        "measured": {
          "width": 320,
          "height": 431
        }
      },
      {
        "id": "OpenAIModel-3HdPb",
        "type": "genericNode",
        "position": {
          "x": 3631.2579791902544,
          "y": 233.33228849317237
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\", display_name=\"Temperature\", value=0.1, range_spec=RangeSpec(min=0, max=1, step=0.01)\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = self.json_mode\n        seed = self.seed\n        max_retries = self.max_retries\n        timeout = self.timeout\n\n        api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n            max_retries=max_retries,\n            request_timeout=timeout,\n        )\n        if json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_retries": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_retries",
                "value": 5,
                "display_name": "Max Retries",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "max_tokens": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "openai_api_base": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "seed": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": false,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "temperature": {
                "tool_mode": false,
                "min_label": "",
                "max_label": "",
                "min_label_icon": "",
                "max_label_icon": "",
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 1,
                  "step": 0.01
                },
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "slider",
                "_input_type": "SliderInput"
              },
              "timeout": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "timeout",
                "value": 700,
                "display_name": "Timeout",
                "advanced": true,
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "OpenAI",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "hidden": null,
                "display_name": "Message",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [],
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "hidden": null,
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [
                  "api_key"
                ],
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "id": "OpenAIModel-3HdPb",
          "description": "Generates text using OpenAI LLMs.",
          "display_name": "RangeSelector"
        },
        "selected": false,
        "width": 320,
        "height": 233,
        "dragging": false,
        "positionAbsolute": {
          "x": 3619.843933794377,
          "y": -29.190755612016034
        },
        "measured": {
          "width": 320,
          "height": 233
        }
      },
      {
        "id": "Prompt-zA0Up",
        "type": "genericNode",
        "position": {
          "x": 3266.07640414577,
          "y": -450.1734247346066
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "You are an expert climate scientist. Is the following CMIP6-related query best answered using data gathered at which of the following resolutions: \n\n- 'hr': hour\n- 'day': day\n- 'mon': month\n- 'NA': not applicable, none of the above, or unclear\n\n\nRespond with only the short term of one following corresponding to your choice and nothing else. \n\nIf a query does not specify any given temporal resolution, like the query \"plot average temperature\", then choose \noption NA\n\n\nQuery: ",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput",
                "load_from_db": false
              },
              "tool_placeholder": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tool_placeholder",
                "value": "",
                "display_name": "Tool Placeholder",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "minimized": false,
            "custom_fields": {
              "template": []
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "beta": false,
            "legacy": false,
            "error": null,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "id": "Prompt-zA0Up",
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Temporal Resolution Prompt"
        },
        "selected": false,
        "width": 320,
        "height": 345,
        "positionAbsolute": {
          "x": 3266.07640414577,
          "y": -598.5560148810174
        },
        "dragging": false,
        "measured": {
          "width": 320,
          "height": 345
        }
      },
      {
        "id": "OpenAIModel-AXjuD",
        "type": "genericNode",
        "position": {
          "x": 3650.2405993147727,
          "y": -502.3019448026218
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\", display_name=\"Temperature\", value=0.1, range_spec=RangeSpec(min=0, max=1, step=0.01)\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = self.json_mode\n        seed = self.seed\n        max_retries = self.max_retries\n        timeout = self.timeout\n\n        api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n            max_retries=max_retries,\n            request_timeout=timeout,\n        )\n        if json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_retries": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_retries",
                "value": 5,
                "display_name": "Max Retries",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "max_tokens": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o-mini",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "openai_api_base": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "seed": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": false,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "temperature": {
                "tool_mode": false,
                "min_label": "",
                "max_label": "",
                "min_label_icon": "",
                "max_label_icon": "",
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 1,
                  "step": 0.01
                },
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "slider",
                "_input_type": "SliderInput"
              },
              "timeout": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "timeout",
                "value": 700,
                "display_name": "Timeout",
                "advanced": true,
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "OpenAI",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "hidden": null,
                "display_name": "Message",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [],
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "hidden": null,
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [
                  "api_key"
                ],
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "id": "OpenAIModel-AXjuD",
          "description": "Generates text using OpenAI LLMs.",
          "display_name": "TemporalSelector"
        },
        "selected": false,
        "width": 320,
        "height": 233,
        "dragging": false,
        "positionAbsolute": {
          "x": 3613.7156540479637,
          "y": -566.2205990195372
        },
        "measured": {
          "width": 320,
          "height": 233
        }
      },
      {
        "id": "Prompt-Q27xi",
        "type": "genericNode",
        "position": {
          "x": 3262.920008885303,
          "y": -1045.856817683067
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "You are a climate scientist and expert on the CMIP6 dataset. Given a colleague's query, find CMIP6 **variables** most likely to help answer the query. \n\nTo find these variables: \n\n1. summarize the variable-related keywords in the query (e.g. \"rain\", not analysis words like \"plot\") using words that are useful for describing the CMIP 6 datasets. For instance, instead of \"weather month\", say temperature precipitation wind\", because \"month\" is not relevant to the variable choice and temperature precipitation wind\" is more specific than \"weather\". \nIf the query relates to whether a variable surpasses some threshold, you may wish to search for the \"min\" or \"max\" versions of variables.\n\n2. connect your list of summary words into one comma separated string.\n\nAdd as much as relevant, don't be shy\n\nUse the tool to check the variables, and at the end output the actual needed query. \n\nYour output should be only the variable name that you found most accurate for the query. No explanations\n\nQuery: ",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput",
                "load_from_db": false
              },
              "tool_placeholder": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tool_placeholder",
                "value": "",
                "display_name": "Tool Placeholder",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Prompt",
            "documentation": "",
            "minimized": false,
            "custom_fields": {
              "template": []
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "beta": false,
            "legacy": false,
            "error": null,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "id": "Prompt-Q27xi",
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Variables Prompt"
        },
        "selected": false,
        "width": 320,
        "height": 345,
        "positionAbsolute": {
          "x": 3262.920008885303,
          "y": -1045.856817683067
        },
        "dragging": false,
        "measured": {
          "width": 320,
          "height": 345
        }
      },
      {
        "id": "ParseData-FSrn8",
        "type": "genericNode",
        "position": {
          "x": 8268.12020673104,
          "y": -1315.5382116744377
        },
        "data": {
          "type": "ParseData",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": true,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{url}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "icon": "message-square",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Data to Message",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "hidden": null,
                "display_name": "Message",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data_list",
                "hidden": null,
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "id": "ParseData-FSrn8",
          "description": "Convert Data into plain text following a specified template.",
          "display_name": "Parse Data"
        },
        "selected": false,
        "width": 320,
        "height": 301,
        "positionAbsolute": {
          "x": 7405.218374802683,
          "y": -653.5235787135279
        },
        "dragging": false,
        "measured": {
          "width": 320,
          "height": 301
        }
      },
      {
        "id": "ParseData-owi82",
        "type": "genericNode",
        "position": {
          "x": 2511.0347784734704,
          "y": -2439.1016070685455
        },
        "data": {
          "type": "ParseData",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": true,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{experiment}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "icon": "message-square",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Data to Message",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": true,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "hidden": null,
                "display_name": "Message",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data_list",
                "hidden": null,
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "id": "ParseData-owi82",
          "description": "Convert Data into plain text following a specified template.",
          "display_name": "Experiment"
        },
        "selected": false,
        "width": 320,
        "height": 301,
        "positionAbsolute": {
          "x": 2511.0347784734704,
          "y": -2439.1016070685455
        },
        "dragging": false,
        "measured": {
          "width": 320,
          "height": 301
        }
      },
      {
        "id": "ParseData-vmr1o",
        "type": "genericNode",
        "position": {
          "x": 2503.418552215972,
          "y": -2796.495319491069
        },
        "data": {
          "type": "ParseData",
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": true,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{MIP}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "icon": "message-square",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Data to Message",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": true,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "hidden": null,
                "display_name": "Message",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data_list",
                "hidden": null,
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "id": "ParseData-vmr1o",
          "description": "Convert Data into plain text following a specified template.",
          "display_name": "MIP"
        },
        "selected": false,
        "width": 320,
        "height": 301,
        "dragging": false,
        "positionAbsolute": {
          "x": 2503.418552215972,
          "y": -2796.495319491069
        },
        "measured": {
          "width": 320,
          "height": 301
        }
      },
      {
        "id": "Prompt-qCzNO",
        "type": "genericNode",
        "position": {
          "x": 3307.6436269610394,
          "y": -2326.167181450361
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "You are an expert climate scientist working with CMIP6.\n\nHere is a list of the MIPs you work with:\n<MIP_LIST>\n{mip_list}\n</MIP_LIST>\n\nBased on the following query, which of the above MIPs would you use? Return ONLY the name of the MIP and nothing else. If the choice of MIP does not matter, return 'None'.\n\nQuery:\n",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput",
                "load_from_db": false
              },
              "tool_placeholder": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tool_placeholder",
                "value": "",
                "display_name": "Tool Placeholder",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "mip_list": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "mip_list",
                "display_name": "mip_list",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "base_classes": [
              "Message"
            ],
            "display_name": "Prompt",
            "documentation": "",
            "minimized": false,
            "custom_fields": {
              "template": [
                "mip_list"
              ]
            },
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "id": "Prompt-qCzNO",
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Date Range Prompt"
        },
        "selected": false,
        "width": 320,
        "height": 345,
        "dragging": false,
        "positionAbsolute": {
          "x": 3267.897612365564,
          "y": -2095.6402967966023
        },
        "measured": {
          "width": 320,
          "height": 345
        }
      },
      {
        "id": "OpenAIModel-3ayFc",
        "type": "genericNode",
        "position": {
          "x": 3699.3023801875593,
          "y": -2501.007431384229
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "output_parser": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_parser",
                "value": "",
                "display_name": "Output Parser",
                "advanced": true,
                "input_types": [
                  "OutputParser"
                ],
                "dynamic": false,
                "info": "The parser to use to parse the output of the model",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\nfrom langflow.inputs.inputs import HandleInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. \"\n            \"You must pass the word JSON in the prompt. \"\n            \"If left blank, JSON mode will be disabled. [DEPRECATED]\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=[*OPENAI_MODEL_NAMES, 'o3-mini'],\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_tokens": {
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "trace_as_input": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125",
                  "o3-mini"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "openai_api_base": {
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "output_schema": {
                "trace_as_input": true,
                "list": true,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "output_schema",
                "value": {},
                "display_name": "Schema",
                "advanced": true,
                "dynamic": false,
                "info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled. [DEPRECATED]",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "seed": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": false,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temperature": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "float",
                "_input_type": "FloatInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "MIPSelector",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "display_name": "Text",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": []
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "output_schema",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "output_parser"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "id": "OpenAIModel-3ayFc",
          "description": "Generates text using OpenAI LLMs.",
          "display_name": "MIPSelector"
        },
        "selected": false,
        "width": 320,
        "height": 671,
        "dragging": false,
        "positionAbsolute": {
          "x": 3659.5563655920837,
          "y": -2270.4805467304705
        },
        "measured": {
          "width": 320,
          "height": 671
        }
      },
      {
        "id": "Prompt-Z36He",
        "type": "genericNode",
        "position": {
          "x": 3298.7567018148375,
          "y": -1883.7387399239117
        },
        "data": {
          "type": "Prompt",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "You are an expert climate scientist working with CMIP6.\n\nHere is a list of the experiments you work with:\n<EXPERIMENT_LIST>\n{EXPERIMENT_LIST}\n</EXPERIMENT_LIST>\nBased on the following query, which of the above experiments would you use? Return ONLY the name of the experiment and nothing else. If the choice of experiment does not matter, return 'None'.\n\nQuery: ",
                "display_name": "Template",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "prompt",
                "_input_type": "PromptInput",
                "load_from_db": false
              },
              "tool_placeholder": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tool_placeholder",
                "value": "",
                "display_name": "Tool Placeholder",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "EXPERIMENT_LIST": {
                "field_type": "str",
                "required": false,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "",
                "fileTypes": [],
                "file_path": "",
                "name": "EXPERIMENT_LIST",
                "display_name": "EXPERIMENT_LIST",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "title_case": false,
                "type": "str"
              }
            },
            "description": "Create a prompt template with dynamic variables.",
            "icon": "prompts",
            "is_input": null,
            "is_output": null,
            "is_composition": null,
            "base_classes": [
              "Message"
            ],
            "name": "",
            "display_name": "Experiment Prompt",
            "documentation": "",
            "minimized": false,
            "custom_fields": {
              "template": [
                "EXPERIMENT_LIST"
              ]
            },
            "output_types": [],
            "full_path": null,
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "prompt",
                "hidden": null,
                "display_name": "Prompt Message",
                "method": "build_prompt",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "beta": false,
            "legacy": false,
            "error": null,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "id": "Prompt-Z36He",
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt"
        },
        "selected": false,
        "width": 320,
        "height": 431,
        "dragging": false,
        "positionAbsolute": {
          "x": 3267.2895934065823,
          "y": -1570.378785358372
        },
        "measured": {
          "width": 320,
          "height": 431
        }
      },
      {
        "id": "OpenAIModel-jdoTk",
        "type": "genericNode",
        "position": {
          "x": 3658.593576968653,
          "y": -1798.8027518588829
        },
        "data": {
          "type": "OpenAIModel",
          "node": {
            "template": {
              "_type": "Component",
              "api_key": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\", display_name=\"Temperature\", value=0.1, range_spec=RangeSpec(min=0, max=1, step=0.01)\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = self.json_mode\n        seed = self.seed\n        max_retries = self.max_retries\n        timeout = self.timeout\n\n        api_key = SecretStr(openai_api_key).get_secret_value() if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n            max_retries=max_retries,\n            request_timeout=timeout,\n        )\n        if json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "input_value": {
                "trace_as_input": true,
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              },
              "json_mode": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_retries": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_retries",
                "value": 5,
                "display_name": "Max Retries",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "max_tokens": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput",
                "load_from_db": false
              },
              "openai_api_base": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "seed": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "stream": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "stream",
                "value": false,
                "display_name": "Stream",
                "advanced": false,
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "system_message": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_message",
                "value": "",
                "display_name": "System Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System message to pass to the model.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "temperature": {
                "tool_mode": false,
                "min_label": "",
                "max_label": "",
                "min_label_icon": "",
                "max_label_icon": "",
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 1,
                  "step": 0.01
                },
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": false,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "slider",
                "_input_type": "SliderInput"
              },
              "timeout": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "timeout",
                "value": 700,
                "display_name": "Timeout",
                "advanced": true,
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              }
            },
            "description": "Generates text using OpenAI LLMs.",
            "icon": "OpenAI",
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "display_name": "OpenAI",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text_output",
                "hidden": null,
                "display_name": "Message",
                "method": "text_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [],
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "LanguageModel"
                ],
                "selected": "LanguageModel",
                "name": "model_output",
                "hidden": null,
                "display_name": "Language Model",
                "method": "build_model",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": [
                  "api_key"
                ],
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "id": "OpenAIModel-jdoTk",
          "description": "Generates text using OpenAI LLMs.",
          "display_name": "OpenAI"
        },
        "selected": false,
        "width": 320,
        "height": 233,
        "dragging": false,
        "positionAbsolute": {
          "x": 3627.126468560398,
          "y": -1485.4427972933431
        },
        "measured": {
          "width": 320,
          "height": 233
        }
      },
      {
        "id": "note-NJEJb",
        "type": "noteNode",
        "position": {
          "x": 3275.8111357961466,
          "y": -1933.7084884270566
        },
        "data": {
          "node": {
            "description": "# Experiment Selector",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note",
          "id": "note-NJEJb"
        },
        "selected": false,
        "width": 600,
        "height": 369,
        "positionAbsolute": {
          "x": 3244.3440273878914,
          "y": -1620.348533861517
        },
        "dragging": false,
        "style": {
          "width": 600,
          "height": 369
        },
        "resizing": false,
        "measured": {
          "width": 601,
          "height": 369
        }
      },
      {
        "id": "note-Uzmu7",
        "type": "noteNode",
        "position": {
          "x": 3290.952459993251,
          "y": -2387.3349018486665
        },
        "data": {
          "node": {
            "description": "# MIP Selector",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note",
          "id": "note-Uzmu7"
        },
        "selected": false,
        "width": 600,
        "height": 324,
        "positionAbsolute": {
          "x": 3251.2064453977755,
          "y": -2156.8080171949077
        },
        "dragging": false,
        "style": {
          "width": 600,
          "height": 324
        },
        "resizing": false,
        "measured": {
          "width": 601,
          "height": 324
        }
      },
      {
        "id": "note-z4cJs",
        "type": "noteNode",
        "position": {
          "x": 3251.2235651114934,
          "y": -1111.928915575845
        },
        "data": {
          "node": {
            "description": "# Variables Selector",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note",
          "id": "note-z4cJs"
        },
        "selected": false,
        "width": 600,
        "height": 349,
        "positionAbsolute": {
          "x": 3251.2235651114934,
          "y": -1111.928915575845
        },
        "dragging": false,
        "style": {
          "width": 600,
          "height": 349
        },
        "resizing": false,
        "measured": {
          "width": 601,
          "height": 349
        }
      },
      {
        "id": "note-w35hy",
        "type": "noteNode",
        "position": {
          "x": 3241.700118210881,
          "y": -524.4009874683029
        },
        "data": {
          "node": {
            "description": "# Temporal Selector",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note",
          "id": "note-w35hy"
        },
        "selected": false,
        "width": 600,
        "height": 324,
        "positionAbsolute": {
          "x": 3241.700118210881,
          "y": -672.7835776147137
        },
        "dragging": false,
        "resizing": false,
        "style": {
          "width": 600,
          "height": 324
        },
        "measured": {
          "width": 601,
          "height": 324
        }
      },
      {
        "id": "note-x8Agm",
        "type": "noteNode",
        "position": {
          "x": 3253.821888998867,
          "y": 68.64353690310685
        },
        "data": {
          "node": {
            "description": "# Range Selector",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note",
          "id": "note-x8Agm"
        },
        "selected": false,
        "width": 600,
        "height": 324,
        "positionAbsolute": {
          "x": 3242.4078436029895,
          "y": -193.87950720208156
        },
        "dragging": false,
        "style": {
          "width": 600,
          "height": 324
        },
        "resizing": false,
        "measured": {
          "width": 601,
          "height": 324
        }
      },
      {
        "id": "note-Bfrh6",
        "type": "noteNode",
        "position": {
          "x": 2104.4217981304396,
          "y": -2840.3587680822898
        },
        "data": {
          "node": {
            "description": "# Load CMIP6 Datasets",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "blue"
            }
          },
          "type": "note",
          "id": "note-Bfrh6"
        },
        "selected": false,
        "width": 600,
        "height": 344,
        "positionAbsolute": {
          "x": 2104.4217981304396,
          "y": -2840.3587680822898
        },
        "dragging": false,
        "style": {
          "width": 600,
          "height": 344
        },
        "resizing": false,
        "measured": {
          "width": 601,
          "height": 344
        }
      },
      {
        "id": "note-sKQtS",
        "type": "noteNode",
        "position": {
          "x": 2876.2126877207456,
          "y": -2921.831798449466
        },
        "data": {
          "node": {
            "description": "# Load CMIP6 JSON Tables",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "blue"
            }
          },
          "type": "note",
          "id": "note-sKQtS"
        },
        "selected": false,
        "width": 600,
        "height": 324,
        "dragging": false,
        "positionAbsolute": {
          "x": 2876.2126877207456,
          "y": -2921.831798449466
        },
        "resizing": false,
        "style": {
          "width": 600,
          "height": 324
        },
        "measured": {
          "width": 601,
          "height": 324
        }
      },
      {
        "id": "note-k2wwi",
        "type": "noteNode",
        "position": {
          "x": 1025.1235050841265,
          "y": -1588.674099475012
        },
        "data": {
          "node": {
            "description": "# Chat Start",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "lime"
            }
          },
          "type": "note",
          "id": "note-k2wwi"
        },
        "selected": false,
        "width": 325,
        "height": 325,
        "positionAbsolute": {
          "x": 1025.1235050841265,
          "y": -1588.674099475012
        },
        "dragging": false,
        "measured": {
          "width": 326,
          "height": 325
        }
      },
      {
        "id": "MIPFilterComponent-7xtDm",
        "type": "genericNode",
        "position": {
          "x": 5171.500975360026,
          "y": -2948.0567084654076
        },
        "data": {
          "type": "MIPFilterComponent",
          "node": {
            "template": {
              "_type": "Component",
              "dataset_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dataset_info",
                "value": "",
                "display_name": "Dataset Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Processed CMIP6 dataset information from the previous component.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# MIPFilterComponent.py\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import HandleInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass MIPFilterComponent(Component):\r\n    display_name = \"MIP Filter\"\r\n    description = \"Filters CMIP6 datasets based on the predicted MIP.\"\r\n    icon = \"filter\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"dataset_info\",\r\n            display_name=\"Dataset Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Processed CMIP6 dataset information from the previous component.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"mip_value\",\r\n            display_name=\"MIP Value\",\r\n            info=\"The MIP value predicted by the LLM.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Filtered Datasets\", name=\"filtered_datasets\", method=\"filter_datasets_by_mip\"),\r\n    ]\r\n\r\n    def filter_datasets_by_mip(self) -> Data:\r\n        if not isinstance(self.dataset_info, Data) or 'df' not in self.dataset_info.data:\r\n            raise ValueError(\"Invalid dataset info input. Expected Data object with 'df' key.\")\r\n\r\n        df = self.dataset_info.data['df']\r\n\r\n        if 'MIP' not in df.columns:\r\n            raise ValueError(\"Expected 'MIP' column in dataset info DataFrame.\")\r\n\r\n        try:\r\n            mip_value = self.mip_value.strip()\r\n            if mip_value.lower() == 'none':\r\n                # No filtering; pass all datasets\r\n                filtered_df = df\r\n                self.status = \"No MIP filtering applied.\"\r\n            else:\r\n                # Filter the dataframe\r\n                filtered_df = df[df['MIP'] == mip_value]\r\n\r\n                if filtered_df.empty:\r\n                    self.status = f\"No datasets found for MIP '{mip_value}'.\"\r\n                else:\r\n                    self.status = f\"Filtered datasets by MIP '{mip_value}'. Remaining datasets: {len(filtered_df)}\"\r\n\r\n            return Data(data={\"filtered_df\": filtered_df})\r\n\r\n        except Exception as e:\r\n            error_message = f\"Error filtering datasets by MIP: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "mip_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "mip_value",
                "value": "",
                "display_name": "MIP Value",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The MIP value predicted by the LLM.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Filters CMIP6 datasets based on the predicted MIP.",
            "icon": "filter",
            "base_classes": [
              "Data"
            ],
            "display_name": "MIP Filter",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "filtered_datasets",
                "display_name": "Filtered Datasets",
                "method": "filter_datasets_by_mip",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "dataset_info",
              "mip_value"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.2.0"
          },
          "id": "MIPFilterComponent-7xtDm"
        },
        "selected": false,
        "width": 320,
        "height": 301,
        "positionAbsolute": {
          "x": 4308.5991434316675,
          "y": -2286.042075504498
        },
        "dragging": false,
        "measured": {
          "width": 320,
          "height": 301
        }
      },
      {
        "id": "ExperimentFilterComponent-aWhGL",
        "type": "genericNode",
        "position": {
          "x": 5583.622803555076,
          "y": -2627.928609890086
        },
        "data": {
          "type": "ExperimentFilterComponent",
          "node": {
            "template": {
              "_type": "Component",
              "dataset_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "dataset_info",
                "value": "",
                "display_name": "Dataset Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Dataset information from the previous component (after MIP filtering).",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# ExperimentFilterComponent.py\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import HandleInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass ExperimentFilterComponent(Component):\r\n    display_name = \"Experiment Filter\"\r\n    description = \"Filters CMIP6 datasets based on the predicted Experiment.\"\r\n    icon = \"filter\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"dataset_info\",\r\n            display_name=\"Dataset Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Dataset information from the previous component (after MIP filtering).\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"experiment_value\",\r\n            display_name=\"Experiment Value\",\r\n            info=\"The Experiment value predicted by the LLM.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Filtered Datasets\", name=\"filtered_datasets\", method=\"filter_datasets_by_experiment\"),\r\n    ]\r\n\r\n    def filter_datasets_by_experiment(self) -> Data:\r\n        if not isinstance(self.dataset_info, Data) or 'filtered_df' not in self.dataset_info.data:\r\n            raise ValueError(\"Invalid dataset info input. Expected Data object with 'filtered_df' key.\")\r\n\r\n        df = self.dataset_info.data['filtered_df']\r\n\r\n        if 'experiment' not in df.columns:\r\n            raise ValueError(\"Expected 'experiment' column in dataset info DataFrame.\")\r\n\r\n        try:\r\n            experiment_value = self.experiment_value.strip()\r\n            if experiment_value.lower() == 'none':\r\n                # No filtering; pass all datasets\r\n                filtered_df = df\r\n                self.status = \"No Experiment filtering applied.\"\r\n            else:\r\n                # Filter the dataframe\r\n                filtered_df = df[df['experiment'] == experiment_value]\r\n\r\n                if filtered_df.empty:\r\n                    self.status = f\"No datasets found for Experiment '{experiment_value}'.\"\r\n                else:\r\n                    self.status = f\"Filtered datasets by Experiment '{experiment_value}'. Remaining datasets: {len(filtered_df)}\"\r\n\r\n            return Data(data={\"filtered_df\": filtered_df})\r\n\r\n        except Exception as e:\r\n            error_message = f\"Error filtering datasets by Experiment: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "experiment_value": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "experiment_value",
                "value": "",
                "display_name": "Experiment Value",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The Experiment value predicted by the LLM.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Filters CMIP6 datasets based on the predicted Experiment.",
            "icon": "filter",
            "base_classes": [
              "Data"
            ],
            "display_name": "Experiment Filter",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "filtered_datasets",
                "display_name": "Filtered Datasets",
                "method": "filter_datasets_by_experiment",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "dataset_info",
              "experiment_value"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.2.0"
          },
          "id": "ExperimentFilterComponent-aWhGL"
        },
        "selected": false,
        "width": 320,
        "height": 301,
        "positionAbsolute": {
          "x": 4720.720971626717,
          "y": -1965.9139769291764
        },
        "dragging": false,
        "measured": {
          "width": 320,
          "height": 301
        }
      },
      {
        "id": "FilteredVariableInfoComponent-J7SKC",
        "type": "genericNode",
        "position": {
          "x": 6013.680055673617,
          "y": -2311.2708136658603
        },
        "data": {
          "type": "FilteredVariableInfoComponent",
          "node": {
            "template": {
              "_type": "Component",
              "filtered_datasets": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "filtered_datasets",
                "value": "",
                "display_name": "Filtered Datasets",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Filtered datasets after MIP and Experiment filters.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "variable_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "variable_info",
                "value": "",
                "display_name": "Variable Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Original CMIP6 variable information.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "# FilteredVariableInfoComponent.py\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import HandleInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass FilteredVariableInfoComponent(Component):\r\n    display_name = \"Filtered Variable Info\"\r\n    description = \"Filters variable info based on variables present in filtered datasets.\"\r\n    icon = \"filter\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"variable_info\",\r\n            display_name=\"Variable Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Original CMIP6 variable information.\",\r\n        ),\r\n        HandleInput(\r\n            name=\"filtered_datasets\",\r\n            display_name=\"Filtered Datasets\",\r\n            input_types=[\"Data\"],\r\n            info=\"Filtered datasets after MIP and Experiment filters.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(\r\n            display_name=\"Filtered Variable Info\",\r\n            name=\"filtered_variable_info\",\r\n            method=\"filter_variable_info\",\r\n        ),\r\n    ]\r\n\r\n    def filter_variable_info(self) -> Data:\r\n        if not isinstance(self.variable_info, Data) or 'variable_info' not in self.variable_info.data:\r\n            raise ValueError(\"Invalid variable info input. Expected Data object with 'variable_info' key.\")\r\n\r\n        if not isinstance(self.filtered_datasets, Data) or 'filtered_df' not in self.filtered_datasets.data:\r\n            raise ValueError(\"Invalid filtered datasets input. Expected Data object with 'filtered_df' key.\")\r\n\r\n        variable_info_df = self.variable_info.data['variable_info']\r\n        filtered_df = self.filtered_datasets.data['filtered_df']\r\n\r\n        try:\r\n            # Get the list of variables present in the filtered datasets\r\n            variables_in_filtered_datasets = filtered_df['variable'].unique().tolist()\r\n\r\n            # Filter variable info to only include these variables\r\n            filtered_variable_info_df = variable_info_df[variable_info_df['variable'].isin(variables_in_filtered_datasets)]\r\n\r\n            self.status = f\"Filtered variable info. Remaining variables: {len(filtered_variable_info_df)}\"\r\n            return Data(data={\"variable_info\": filtered_variable_info_df})\r\n\r\n        except Exception as e:\r\n            error_message = f\"Error filtering variable info: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})\r\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              }
            },
            "description": "Filters variable info based on variables present in filtered datasets.",
            "icon": "filter",
            "base_classes": [
              "Data"
            ],
            "display_name": "Filtered Variable Info",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "filtered_variable_info",
                "display_name": "Filtered Variable Info",
                "method": "filter_variable_info",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "variable_info",
              "filtered_datasets"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.2.0"
          },
          "id": "FilteredVariableInfoComponent-J7SKC"
        },
        "selected": false,
        "width": 320,
        "height": 263,
        "dragging": false,
        "positionAbsolute": {
          "x": 5150.778223745258,
          "y": -1649.2561807049508
        },
        "measured": {
          "width": 320,
          "height": 263
        }
      },
      {
        "id": "variable_matcher-aUJnq",
        "type": "genericNode",
        "position": {
          "x": 3666.3057680460593,
          "y": -1060.990373856476
        },
        "data": {
          "type": "variable_matcher",
          "node": {
            "template": {
              "_type": "Component",
              "embeddings": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "embeddings",
                "value": "",
                "display_name": "Embeddings",
                "advanced": false,
                "input_types": [
                  "Embeddings"
                ],
                "dynamic": false,
                "info": "Embeddings component for generating query embeddings.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "variable_info": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "variable_info",
                "value": "",
                "display_name": "Variable Info",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "Processed CMIP6 variable information from the previous component.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "import numpy as np\r\nfrom typing import List, Dict, Any\r\nfrom pydantic import BaseModel, Field\r\n\r\nfrom langflow.base.langchain_utilities.model import LCToolComponent\r\nfrom langflow.io import HandleInput, MessageTextInput, IntInput, Output\r\nfrom langflow.schema import Data\r\nfrom langflow.field_typing import Tool\r\nfrom langchain.tools import StructuredTool\r\n\r\nclass VariableMatcherToolComponent(LCToolComponent):\r\n    display_name = \"CMIP6 Variable Matcher\"\r\n    description = \"Matches CMIP6 variables based on LLM output using cosine similarity.\"\r\n    icon = \"match\"\r\n    name = \"variable_matcher\"\r\n    variable_embeddings = None\r\n    variables_data = None\r\n    \r\n    inputs = [\r\n        HandleInput(\r\n            name=\"variable_info\",\r\n            display_name=\"Variable Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Processed CMIP6 variable information from the previous component.\",\r\n        ),\r\n        HandleInput(\r\n            name=\"embeddings\",\r\n            display_name=\"Embeddings\",\r\n            input_types=[\"Embeddings\"],\r\n            info=\"Embeddings component for generating query embeddings.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"llm_output\",\r\n            display_name=\"LLM Output\",\r\n            info=\"Output from the LLM containing variable-related keywords. Can be a single string or comma-separated list.\",\r\n        ),\r\n        IntInput(\r\n            name=\"top_n\",\r\n            display_name=\"Number of Results\",\r\n            info=\"Number of top matching variables to return.\",\r\n            value=5,\r\n        ),\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(display_name=\"Matched Variables\", name=\"matched_variables\", method=\"match_variables\"),\r\n        Output(display_name=\"Tool\", name=\"tool\", method=\"build_tool\"),\r\n    ]\r\n\r\n    class VariableMatcherSchema(BaseModel):\r\n        keywords: str = Field(\r\n            ..., \r\n            description=\"Keywords or description of the variable(s) to search for. Can be a comma-separated list.\"\r\n        )\r\n        top_n: int = Field(\r\n            5, \r\n            description=\"Number of top matching variables to return.\"\r\n        )\r\n\r\n    def cosine_similarity(self, a, b):\r\n        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\r\n\r\n    def _process_matches(self, keywords: str, top_n: int) -> List[Dict[str, Any]]:\r\n        \"\"\"Internal method to process variable matches\"\"\"\r\n        if not isinstance(self.variable_info, Data) or 'variable_info' not in self.variable_info.data:\r\n            raise ValueError(\"Invalid variable info input. Expected Data object with 'variable_info' key.\")\r\n        \r\n        varsdf = self.variable_info.data['variable_info']\r\n        \r\n        if 'embeds' not in varsdf.columns:\r\n            raise ValueError(\"Expected 'embeds' column in variable info DataFrame.\")\r\n\r\n        # Initialize variable embeddings if not already done\r\n        if self.variable_embeddings is None:\r\n            self.variable_embeddings = np.array(varsdf['embeds'].tolist())\r\n            self.variables_data = varsdf.drop('embeds', axis=1)\r\n\r\n        # Split keywords\r\n        keyword_list = [kw.strip() for kw in keywords.split(',')]\r\n        \r\n        # Generate embeddings for each keyword\r\n        keyword_embeddings = [self.embeddings.embed_query(kw) for kw in keyword_list]\r\n        \r\n        # Use the average embedding as the query\r\n        query_embedding = np.mean(keyword_embeddings, axis=0)\r\n        \r\n        # Calculate cosine similarity\r\n        similarities = np.array([\r\n            self.cosine_similarity(query_embedding, vec) \r\n            for vec in self.variable_embeddings\r\n        ])\r\n        \r\n        # Get top N matches\r\n        top_indices = np.argsort(similarities)[-top_n:][::-1]\r\n        \r\n        # Prepare results\r\n        results = self.variables_data.iloc[top_indices].copy()\r\n        results['similarity_score'] = similarities[top_indices]\r\n        \r\n        # Convert to list of dictionaries\r\n        return [\r\n            {\r\n                'variable': row['variable'],\r\n                'long_name': row['long_name'],\r\n                'comment': row['comment'],\r\n                'similarity_score': float(row['similarity_score'])\r\n            }\r\n            for _, row in results.iterrows()\r\n        ]\r\n\r\n    def match_variables(self) -> List[Data]:\r\n        \"\"\"Method for component output\"\"\"\r\n        try:\r\n            results = self._process_matches(self.llm_output, self.top_n)\r\n            data_list = [Data(data=result) for result in results]\r\n            self.status = data_list\r\n            return data_list\r\n            \r\n        except Exception as e:\r\n            error_message = f\"Error matching variables: {str(e)}\"\r\n            self.status = error_message\r\n            return [Data(data={\"error\": error_message})]\r\n\r\n    def build_tool(self) -> Tool:\r\n        \"\"\"Build and return the tool\"\"\"\r\n        return StructuredTool.from_function(\r\n            name=\"variable_matcher\",\r\n            description=\"Match CMIP6 variables based on keywords using semantic similarity. \"\r\n                      \"Input should be keywords or descriptions of the variables you're looking for.\",\r\n            func=self._tool_function,\r\n            args_schema=self.VariableMatcherSchema,\r\n        )\r\n\r\n    def _tool_function(self, keywords: str, top_n: int = 5) -> List[Dict[str, Any]]:\r\n        \"\"\"Function to be called by the tool\"\"\"\r\n        try:\r\n            return self._process_matches(keywords, top_n)\r\n        except Exception as e:\r\n            return [{\"error\": f\"Error matching variables: {str(e)}\"}]",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "llm_output": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "llm_output",
                "value": "",
                "display_name": "LLM Output",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Output from the LLM containing variable-related keywords. Can be a single string or comma-separated list.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "top_n": {
                "trace_as_metadata": true,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "top_n",
                "value": 10,
                "display_name": "Number of Results",
                "advanced": false,
                "dynamic": false,
                "info": "Number of top matching variables to return.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput",
                "load_from_db": false
              }
            },
            "description": "Matches CMIP6 variables based on LLM output using cosine similarity.",
            "icon": "match",
            "base_classes": [
              "Data",
              "Tool"
            ],
            "display_name": "CMIP Variable Tool Check",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "matched_variables",
                "display_name": "Matched Variables",
                "method": "match_variables",
                "value": "__UNDEFINED__",
                "cache": true,
                "hidden": true
              },
              {
                "types": [
                  "Tool"
                ],
                "selected": "Tool",
                "name": "tool",
                "display_name": "Tool",
                "method": "build_tool",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "variable_info",
              "embeddings",
              "llm_output",
              "top_n"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.2.0"
          },
          "id": "variable_matcher-aUJnq"
        },
        "selected": false,
        "width": 320,
        "height": 349,
        "positionAbsolute": {
          "x": 3666.3057680460593,
          "y": -1060.990373856476
        },
        "dragging": false,
        "measured": {
          "width": 320,
          "height": 349
        }
      },
      {
        "id": "note-b9DxR",
        "type": "noteNode",
        "position": {
          "x": 3804.112527509932,
          "y": -1112.5000011889613
        },
        "data": {
          "node": {
            "description": " ",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note",
          "id": "note-b9DxR"
        },
        "selected": false,
        "width": 600,
        "height": 355,
        "dragging": false,
        "style": {
          "width": 600,
          "height": 355
        },
        "resizing": false,
        "positionAbsolute": {
          "x": 3804.112527509932,
          "y": -1112.5000011889613
        },
        "measured": {
          "width": 601,
          "height": 355
        }
      },
      {
        "id": "CurrentDateComponent-qbE6Q",
        "type": "genericNode",
        "position": {
          "x": 3016.522425540591,
          "y": 356.233741743587
        },
        "data": {
          "type": "CurrentDateComponent",
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from datetime import datetime\r\nfrom zoneinfo import ZoneInfo\r\nfrom typing import List\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import DropdownInput, Output\r\nfrom langflow.schema.message import Message\r\n\r\nclass CurrentDateComponent(Component):\r\n    display_name = \"Current Date 🕰️\"\r\n    description = \"Returns the current date and time in the selected timezone.\"\r\n    icon = \"clock\"\r\n\r\n    inputs = [\r\n        DropdownInput(\r\n            name=\"timezone\",\r\n            display_name=\"Timezone\",\r\n            options=[\r\n                \"UTC\",\r\n                \"US/Eastern\",\r\n                \"US/Central\",\r\n                \"US/Mountain\",\r\n                \"US/Pacific\",\r\n                \"Europe/London\",\r\n                \"Europe/Paris\",\r\n                \"Asia/Tokyo\",\r\n                \"Australia/Sydney\",\r\n                \"America/Sao_Paulo\",\r\n                \"America/Cuiaba\",\r\n            ],\r\n            value=\"UTC\",\r\n            info=\"Select the timezone for the current date and time.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Current Date\", name=\"current_date\", method=\"get_current_date\"),\r\n    ]\r\n\r\n    def get_current_date(self) -> Message:\r\n        try:\r\n            tz = ZoneInfo(self.timezone)\r\n            current_date = datetime.now(tz).strftime(\"%Y-%m-%d %H:%M:%S %Z\")\r\n            result = f\"Current date and time in {self.timezone}: {current_date}\"\r\n            self.status = result\r\n            return Message(text=result)\r\n        except Exception as e:\r\n            error_message = f\"Error: {str(e)}\"\r\n            self.status = error_message\r\n            return Message(text=error_message)",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "timezone": {
                "trace_as_metadata": true,
                "options": [
                  "UTC",
                  "US/Eastern",
                  "US/Central",
                  "US/Mountain",
                  "US/Pacific",
                  "Europe/London",
                  "Europe/Paris",
                  "Asia/Tokyo",
                  "Australia/Sydney",
                  "America/Sao_Paulo",
                  "America/Cuiaba"
                ],
                "combobox": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "timezone",
                "value": "America/Sao_Paulo",
                "display_name": "Timezone",
                "advanced": false,
                "dynamic": false,
                "info": "Select the timezone for the current date and time.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              }
            },
            "description": "Returns the current date and time in the selected timezone.",
            "icon": "clock",
            "base_classes": [
              "Message"
            ],
            "display_name": "Current Date",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "current_date",
                "display_name": "Current Date",
                "method": "get_current_date",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "timezone"
            ],
            "beta": false,
            "edited": true,
            "lf_version": "1.2.0",
            "official": false
          },
          "id": "CurrentDateComponent-qbE6Q",
          "showNode": false
        },
        "selected": false,
        "width": 192,
        "height": 65,
        "positionAbsolute": {
          "x": 3005.1083801447135,
          "y": 93.71069763839861
        },
        "dragging": false,
        "measured": {
          "width": 192,
          "height": 65
        }
      },
      {
        "id": "note-3AkWD",
        "type": "noteNode",
        "position": {
          "x": 5143.799231900305,
          "y": -3077.411872830502
        },
        "data": {
          "node": {
            "description": "# Dataset Filtering Process",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "lime"
            }
          },
          "type": "note",
          "id": "note-3AkWD"
        },
        "selected": false,
        "width": 600,
        "height": 334,
        "positionAbsolute": {
          "x": 4280.8973999719465,
          "y": -2415.3972398695923
        },
        "dragging": false,
        "style": {
          "width": 600,
          "height": 334
        },
        "resizing": false,
        "measured": {
          "width": 601,
          "height": 334
        }
      },
      {
        "id": "Agent-wqazV",
        "type": "genericNode",
        "position": {
          "x": 4048.5987473550076,
          "y": -1060.7208915189365
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "memory": {
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "memory",
                "value": "",
                "display_name": "External Memory",
                "advanced": true,
                "input_types": [
                  "Memory"
                ],
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "tools": {
                "trace_as_metadata": true,
                "list": true,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "tools",
                "value": "",
                "display_name": "Tools",
                "advanced": false,
                "input_types": [
                  "Tool"
                ],
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "add_current_date_tool": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "add_current_date_tool",
                "value": false,
                "display_name": "Current Date",
                "advanced": true,
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "agent_description": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_description",
                "value": "A helpful assistant with access to the following tools:",
                "display_name": "Agent Description [Deprecated]",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "agent_llm": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Amazon Bedrock",
                  "Anthropic",
                  "Azure OpenAI",
                  "Google Generative AI",
                  "Groq",
                  "NVIDIA",
                  "OpenAI",
                  "SambaNova",
                  "Custom"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "agent_llm",
                "value": "OpenAI",
                "display_name": "Model Provider",
                "advanced": false,
                "input_types": [],
                "dynamic": false,
                "info": "The provider of the language model that the agent will use to generate responses.",
                "real_time_refresh": true,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "api_key": {
                "load_from_db": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "api_key",
                "value": "",
                "display_name": "OpenAI API Key",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "title_case": false,
                "password": true,
                "type": "str",
                "_input_type": "SecretStrInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langchain_core.tools import StructuredTool\n\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.base.agents.events import ExceptionWithMessageError\nfrom langflow.base.models.model_input_constants import (\n    ALL_PROVIDER_FIELDS,\n    MODEL_DYNAMIC_UPDATE_FIELDS,\n    MODEL_PROVIDERS_DICT,\n)\nfrom langflow.base.models.model_utils import get_model_name\nfrom langflow.components.helpers import CurrentDateComponent\nfrom langflow.components.helpers.memory import MemoryComponent\nfrom langflow.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom langflow.custom.custom_component.component import _get_component_toolkit\nfrom langflow.custom.utils import update_component_build_config\nfrom langflow.field_typing import Tool\nfrom langflow.io import BoolInput, DropdownInput, MultilineInput, Output\nfrom langflow.logging import logger\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            input_types=[],\n        ),\n        *MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"],\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        *LCToolsAgentComponent._base_inputs,\n        *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [Output(name=\"response\", display_name=\"Response\", method=\"message_response\")]\n\n    async def message_response(self) -> Message:\n        try:\n            # Get LLM model and validate\n            llm_model, display_name = self.get_llm()\n            if llm_model is None:\n                msg = \"No language model selected. Please choose a model to proceed.\"\n                raise ValueError(msg)\n            self.model_name = get_model_name(llm_model, display_name=display_name)\n\n            # Get memory data\n            self.chat_history = await self.get_memory_data()\n\n            # Add current date tool if enabled\n            if self.add_current_date_tool:\n                if not isinstance(self.tools, list):  # type: ignore[has-type]\n                    self.tools = []\n                current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n                if not isinstance(current_date_tool, StructuredTool):\n                    msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                    raise TypeError(msg)\n                self.tools.append(current_date_tool)\n\n            # Validate tools\n            if not self.tools:\n                msg = \"Tools are required to run the agent. Please add at least one tool.\"\n                raise ValueError(msg)\n\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools,\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            return await self.run_agent(agent)\n\n        except (ValueError, TypeError, KeyError) as e:\n            logger.error(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            logger.error(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Unexpected error: {e!s}\")\n            raise\n\n    async def get_memory_data(self):\n        memory_kwargs = {\n            component_input.name: getattr(self, f\"{component_input.name}\") for component_input in self.memory_inputs\n        }\n        # filter out empty values\n        memory_kwargs = {k: v for k, v in memory_kwargs.items() if v}\n\n        return await MemoryComponent(**self.get_base_args()).set(**memory_kwargs).retrieve_messages()\n\n    def get_llm(self):\n        if not isinstance(self.agent_llm, str):\n            return self.agent_llm, None\n\n        try:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if not provider_info:\n                msg = f\"Invalid model provider: {self.agent_llm}\"\n                raise ValueError(msg)\n\n            component_class = provider_info.get(\"component_class\")\n            display_name = component_class.display_name\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\", \"\")\n\n            return self._build_llm_model(component_class, inputs, prefix), display_name\n\n        except Exception as e:\n            logger.error(f\"Error building {self.agent_llm} language model: {e!s}\")\n            msg = f\"Failed to initialize language model: {e!s}\"\n            raise ValueError(msg) from e\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n        return component.set(**model_kwargs).build_model()\n\n    def set_component_params(self, component):\n        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n        if provider_info:\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\")\n            model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n\n            return component.set(**model_kwargs)\n        return component\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self, build_config: dotdict, field_value: str, field_name: str | None = None\n    ) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name in (\"agent_llm\",):\n            build_config[\"agent_llm\"][\"value\"] = field_value\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n            elif field_value == \"Custom\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n                    value=\"Custom\",\n                    real_time_refresh=True,\n                    input_types=[\"LanguageModel\"],\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if (\n            isinstance(self.agent_llm, str)\n            and self.agent_llm in MODEL_PROVIDERS_DICT\n            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS\n        ):\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                component_class = self.set_component_params(component_class)\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n\n    async def to_toolkit(self) -> list[Tool]:\n        component_toolkit = _get_component_toolkit()\n        tools_names = self._build_tools_names()\n        agent_description = self.get_tool_description()\n        # TODO: Agent Description Depreciated Feature to be removed\n        description = f\"{agent_description}{tools_names}\"\n        tools = component_toolkit(component=self).get_tools(\n            tool_name=self.get_tool_name(), tool_description=description, callbacks=self.get_langchain_callbacks()\n        )\n        if hasattr(self, \"tools_metadata\"):\n            tools = component_toolkit(component=self, metadata=self.tools_metadata).update_tools_metadata(tools=tools)\n        return tools\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "handle_parsing_errors": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "handle_parsing_errors",
                "value": true,
                "display_name": "Handle Parse Errors",
                "advanced": true,
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "input_value": {
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Input",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "json_mode": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "json_mode",
                "value": false,
                "display_name": "JSON Mode",
                "advanced": true,
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "max_iterations": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_iterations",
                "value": 15,
                "display_name": "Max Iterations",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "max_retries": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_retries",
                "value": 5,
                "display_name": "Max Retries",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "max_tokens": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 128000,
                  "step": 0.1
                },
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "max_tokens",
                "value": "",
                "display_name": "Max Tokens",
                "advanced": true,
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "model_kwargs": {
                "tool_mode": false,
                "trace_as_input": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_kwargs",
                "value": {},
                "display_name": "Model Kwargs",
                "advanced": true,
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "title_case": false,
                "type": "dict",
                "_input_type": "DictInput"
              },
              "model_name": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "gpt-3.5-turbo-0125"
                ],
                "options_metadata": [],
                "combobox": true,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "model_name",
                "value": "gpt-4o-mini",
                "display_name": "Model Name",
                "advanced": false,
                "dynamic": false,
                "info": "To see the model names, first choose a provider. Then, enter your API key and click the refresh button next to the model name.",
                "real_time_refresh": false,
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "n_messages": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "n_messages",
                "value": 100,
                "display_name": "Number of Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "openai_api_base": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "openai_api_base",
                "value": "",
                "display_name": "OpenAI API Base",
                "advanced": true,
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "order": {
                "tool_mode": true,
                "trace_as_metadata": true,
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "order",
                "value": "Ascending",
                "display_name": "Order",
                "advanced": true,
                "dynamic": false,
                "info": "Order of the messages.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "seed": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "seed",
                "value": 1,
                "display_name": "Seed",
                "advanced": true,
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine and User",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Filter by sender type.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Filter by sender name.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "system_prompt": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "system_prompt",
                "value": "You are a helpful assistant that can use tools to answer questions and perform tasks.",
                "display_name": "Agent Instructions",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "temperature": {
                "tool_mode": false,
                "min_label": "",
                "max_label": "",
                "min_label_icon": "",
                "max_label_icon": "",
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "range_spec": {
                  "step_type": "float",
                  "min": 0,
                  "max": 1,
                  "step": 0.01
                },
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temperature",
                "value": 0.1,
                "display_name": "Temperature",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "slider",
                "_input_type": "SliderInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{sender_name}: {text}",
                "display_name": "Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              },
              "timeout": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "timeout",
                "value": 700,
                "display_name": "Timeout",
                "advanced": true,
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "title_case": false,
                "type": "int",
                "_input_type": "IntInput"
              },
              "verbose": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "verbose",
                "value": true,
                "display_name": "Verbose",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              }
            },
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "icon": "bot",
            "base_classes": [
              "Message"
            ],
            "display_name": "Agent",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "response",
                "hidden": null,
                "display_name": "Response",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "agent_llm",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout",
              "system_prompt",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template",
              "add_current_date_tool"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "type": "Agent",
          "id": "Agent-wqazV"
        },
        "selected": false,
        "width": 320,
        "height": 387,
        "positionAbsolute": {
          "x": 4048.5987473550076,
          "y": -1060.7208915189365
        },
        "dragging": false,
        "measured": {
          "width": 320,
          "height": 387
        }
      },
      {
        "id": "ChatOutput-NLJoQ",
        "type": "genericNode",
        "position": {
          "x": 4290.695695597331,
          "y": -1669.8330144345136
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_value": {
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "🧪",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "clean_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "clean_data",
                "value": true,
                "display_name": "Basic Clean Data",
                "advanced": true,
                "dynamic": false,
                "info": "Whether to clean the data",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n                return (\n                    data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n                    .applymap(lambda x: (str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x))\n                    .to_markdown(index=False)\n                )\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "Experiment",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "minimized": true,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "hidden": null,
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "type": "ChatOutput",
          "id": "ChatOutput-NLJoQ",
          "showNode": false
        },
        "selected": false,
        "width": 192,
        "height": 65,
        "positionAbsolute": {
          "x": 4023.225274127163,
          "y": -1387.9401682772288
        },
        "dragging": false,
        "measured": {
          "width": 192,
          "height": 65
        }
      },
      {
        "id": "ChatOutput-XYyZ4",
        "type": "genericNode",
        "position": {
          "x": 4090.112615232146,
          "y": -2118.9182508685435
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_value": {
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "🧪",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "clean_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "clean_data",
                "value": true,
                "display_name": "Basic Clean Data",
                "advanced": true,
                "dynamic": false,
                "info": "Whether to clean the data",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n                return (\n                    data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n                    .applymap(lambda x: (str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x))\n                    .to_markdown(index=False)\n                )\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "MIP",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "minimized": true,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "hidden": null,
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "type": "ChatOutput",
          "id": "ChatOutput-XYyZ4",
          "showNode": true
        },
        "selected": false,
        "width": 320,
        "height": 185,
        "positionAbsolute": {
          "x": 4050.3666006366702,
          "y": -1888.3913662147845
        },
        "dragging": false,
        "measured": {
          "width": 320,
          "height": 185
        }
      },
      {
        "id": "ChatOutput-gYkvt",
        "type": "genericNode",
        "position": {
          "x": 4539.157125659679,
          "y": -706.0623516348445
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_value": {
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "🧪",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "clean_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "clean_data",
                "value": true,
                "display_name": "Basic Clean Data",
                "advanced": true,
                "dynamic": false,
                "info": "Whether to clean the data",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n                return (\n                    data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n                    .applymap(lambda x: (str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x))\n                    .to_markdown(index=False)\n                )\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "Variable",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "minimized": true,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "hidden": null,
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "type": "ChatOutput",
          "id": "ChatOutput-gYkvt",
          "showNode": false
        },
        "selected": false,
        "width": 192,
        "height": 65,
        "positionAbsolute": {
          "x": 4420.290209494043,
          "y": -760.6068921644619
        },
        "dragging": false,
        "measured": {
          "width": 192,
          "height": 65
        }
      },
      {
        "id": "ChatOutput-QNEAa",
        "type": "genericNode",
        "position": {
          "x": 4265.422489594483,
          "y": -182.6422945940829
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_value": {
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "🧪",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "clean_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "clean_data",
                "value": true,
                "display_name": "Basic Clean Data",
                "advanced": true,
                "dynamic": false,
                "info": "Whether to clean the data",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n                return (\n                    data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n                    .applymap(lambda x: (str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x))\n                    .to_markdown(index=False)\n                )\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "Temporal Resolution",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "minimized": true,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "hidden": null,
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "type": "ChatOutput",
          "id": "ChatOutput-QNEAa",
          "showNode": false
        },
        "selected": false,
        "width": 192,
        "height": 65,
        "positionAbsolute": {
          "x": 3975.5057365391876,
          "y": -420.05443882834027
        },
        "dragging": false,
        "measured": {
          "width": 192,
          "height": 65
        }
      },
      {
        "id": "ChatOutput-CAZzq",
        "type": "genericNode",
        "position": {
          "x": 4012.7163680738754,
          "y": 399.1165284458427
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "input_value": {
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "input_value",
                "value": "",
                "display_name": "Text",
                "advanced": false,
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "dynamic": false,
                "info": "Message to be passed as output.",
                "title_case": false,
                "type": "other",
                "_input_type": "HandleInput"
              },
              "background_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "background_color",
                "value": "",
                "display_name": "Background Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The background color of the icon.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "chat_icon": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "chat_icon",
                "value": "🧪",
                "display_name": "Icon",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The icon of the message.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "clean_data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "clean_data",
                "value": true,
                "display_name": "Basic Clean Data",
                "advanced": true,
                "dynamic": false,
                "info": "Whether to clean the data",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n                return (\n                    data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n                    .applymap(lambda x: (str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x))\n                    .to_markdown(index=False)\n                )\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "data_template": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "data_template",
                "value": "{text}",
                "display_name": "Data Template",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "sender": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "combobox": false,
                "dialog_inputs": {},
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender",
                "value": "Machine",
                "display_name": "Sender Type",
                "advanced": true,
                "dynamic": false,
                "info": "Type of sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "DropdownInput"
              },
              "sender_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sender_name",
                "value": "Date Range",
                "display_name": "Sender Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "Name of the sender.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "session_id": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "session_id",
                "value": "",
                "display_name": "Session ID",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "should_store_message": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "should_store_message",
                "value": true,
                "display_name": "Store Messages",
                "advanced": true,
                "dynamic": false,
                "info": "Store the message in the history.",
                "title_case": false,
                "type": "bool",
                "_input_type": "BoolInput"
              },
              "text_color": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "text_color",
                "value": "",
                "display_name": "Text Color",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The text color of the name",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Display a chat message in the Playground.",
            "icon": "MessagesSquare",
            "base_classes": [
              "Message"
            ],
            "display_name": "Chat Output",
            "documentation": "",
            "minimized": true,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "message",
                "hidden": null,
                "display_name": "Message",
                "method": "message_response",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "type": "ChatOutput",
          "id": "ChatOutput-CAZzq",
          "showNode": false
        },
        "selected": false,
        "width": 192,
        "height": 65,
        "positionAbsolute": {
          "x": 4001.302322677998,
          "y": 136.59348434065427
        },
        "dragging": false,
        "measured": {
          "width": 192,
          "height": 65
        }
      },
      {
        "id": "CustomComponent-qg4v7",
        "type": "genericNode",
        "position": {
          "x": 8751.880861695576,
          "y": -1073.9666294352216
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\r\nfrom langflow.io import MessageTextInput, Output\r\nfrom langflow.schema import Data\r\nimport json\r\nimport os\r\n\r\nclass SaveConfigComponent(Component):\r\n    display_name = \"Save Search Configuration\"\r\n    description = \"Save search configuration parameters including URL, temporal resolution, date range, MIP, experiment, variable, and user query to a JSON file\"\r\n    icon = \"save\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"url\",\r\n            display_name=\"URL\",\r\n            info=\"The URL to save in the JSON file\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"temporal_resolution\",\r\n            display_name=\"Temporal Resolution\",\r\n            info=\"The temporal resolution of the data\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"date_range\",\r\n            display_name=\"Date Range\",\r\n            info=\"The date range for the data\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"mip\",\r\n            display_name=\"MIP\",\r\n            info=\"The MIP (Model Intercomparison Project) identifier\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"experiment\",\r\n            display_name=\"Experiment\",\r\n            info=\"The experiment name or identifier\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"variable\",\r\n            display_name=\"Variable\",\r\n            info=\"The variable name or identifier\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"user_query\",\r\n            display_name=\"User Query\",\r\n            info=\"The original user query\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"file_name\",\r\n            display_name=\"File Name\",\r\n            info=\"The name of the JSON file to save (without .json extension)\",\r\n            advanced=True,\r\n            value=\"search_config\"\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(name=\"saved_data\", display_name=\"Saved Data\", method=\"save_config\"),\r\n    ]\r\n\r\n    def save_config(self) -> Data:\r\n        try:\r\n            # Validate required fields\r\n            if not self.url:\r\n                url = \"No Match\"\r\n            else:\r\n                url = self.url\r\n            # Prepare the data dictionary\r\n            data = {\r\n                \"url\": url,\r\n                \"temporal_resolution\": self.temporal_resolution,\r\n                \"date_range\": self.date_range,\r\n                \"mip\": self.mip,\r\n                \"experiment\": self.experiment,\r\n                \"variable\": self.variable,\r\n                \"user_query\": self.user_query,\r\n                \"run_id\": self.graph.run_id,\r\n                \"session_id\": self.graph.session_id\r\n            }\r\n\r\n            # Clean the data dictionary by removing None values\r\n            data = {k: v for k, v in data.items() if v is not None}\r\n\r\n            # Prepare file name\r\n            file_name = f\"{self.file_name}.json\" if self.file_name else \"search_config.json\"\r\n\r\n            # Save to JSON file\r\n            with open(file_name, 'w') as json_file:\r\n                json.dump(data, json_file, indent=2)\r\n\r\n            self.log(f\"Configuration saved to {file_name}\")\r\n            \r\n            return Data(data=data)\r\n\r\n        except Exception as e:\r\n            error_message = f\"An error occurred while saving the configuration: {str(e)}\"\r\n            self.log(error_message)\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "date_range": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "date_range",
                "value": "",
                "display_name": "Date Range",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The date range for the data",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "experiment": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "experiment",
                "value": "",
                "display_name": "Experiment",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The experiment name or identifier",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "file_name": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "file_name",
                "value": "url_data",
                "display_name": "File Name",
                "advanced": true,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The name of the JSON file to save (without .json extension)",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "mip": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "mip",
                "value": "",
                "display_name": "MIP",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The MIP (Model Intercomparison Project) identifier",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "temporal_resolution": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "temporal_resolution",
                "value": "",
                "display_name": "Temporal Resolution",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The temporal resolution of the data",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "url": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "url",
                "value": "",
                "display_name": "URL",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The URL to save in the JSON file",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "user_query": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "user_query",
                "value": "",
                "display_name": "User Query",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The original user query",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              },
              "variable": {
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "variable",
                "value": "",
                "display_name": "Variable",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The variable name or identifier",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageTextInput"
              }
            },
            "description": "Save search configuration parameters including URL, temporal resolution, date range, MIP, experiment, variable, and user query to a JSON file",
            "icon": "save",
            "base_classes": [
              "Data"
            ],
            "display_name": "Save Search Configuration",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "saved_data",
                "display_name": "Saved Data",
                "method": "save_config",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "url",
              "temporal_resolution",
              "date_range",
              "mip",
              "experiment",
              "variable",
              "user_query",
              "file_name"
            ],
            "beta": false,
            "legacy": false,
            "edited": true,
            "metadata": {},
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "type": "CustomComponent",
          "id": "CustomComponent-qg4v7"
        },
        "selected": false,
        "width": 320,
        "height": 809,
        "positionAbsolute": {
          "x": 7888.979029767216,
          "y": -411.95199647431195
        },
        "dragging": false,
        "measured": {
          "width": 320,
          "height": 809
        }
      },
      {
        "id": "ParseData-ZwaO0",
        "type": "genericNode",
        "position": {
          "x": 2117.4988669157246,
          "y": -1519.1432643033322
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "data": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "list": true,
                "list_add_label": "Add More",
                "trace_as_input": true,
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "data",
                "value": "",
                "display_name": "Data",
                "advanced": false,
                "input_types": [
                  "Data"
                ],
                "dynamic": false,
                "info": "The data to convert to text.",
                "title_case": false,
                "type": "other",
                "_input_type": "DataInput"
              },
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "sep": {
                "tool_mode": false,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "sep",
                "value": "\n",
                "display_name": "Separator",
                "advanced": true,
                "dynamic": false,
                "info": "",
                "title_case": false,
                "type": "str",
                "_input_type": "StrInput"
              },
              "template": {
                "tool_mode": false,
                "trace_as_input": true,
                "multiline": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "list_add_label": "Add More",
                "required": true,
                "placeholder": "",
                "show": true,
                "name": "template",
                "value": "{text}",
                "display_name": "Template",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "title_case": false,
                "type": "str",
                "_input_type": "MultilineInput"
              }
            },
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "icon": "message-square",
            "base_classes": [
              "Data",
              "Message"
            ],
            "display_name": "Data to Message",
            "documentation": "",
            "minimized": false,
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Message"
                ],
                "selected": "Message",
                "name": "text",
                "hidden": null,
                "display_name": "Message",
                "method": "parse_data",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              },
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data_list",
                "hidden": null,
                "display_name": "Data List",
                "method": "parse_data_as_list",
                "value": "__UNDEFINED__",
                "cache": true,
                "required_inputs": null,
                "allows_loop": false,
                "tool_mode": true
              }
            ],
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "beta": false,
            "legacy": false,
            "edited": false,
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "tool_mode": false,
            "lf_version": "1.2.0"
          },
          "type": "ParseData",
          "id": "ParseData-ZwaO0"
        },
        "selected": false,
        "width": 320,
        "height": 301,
        "dragging": false,
        "positionAbsolute": {
          "x": 2117.4988669157246,
          "y": -1519.1432643033322
        },
        "measured": {
          "width": 320,
          "height": 301
        }
      },
      {
        "id": "note-5BfxR",
        "type": "noteNode",
        "position": {
          "x": 2039.5844260837744,
          "y": -1604.1485298807581
        },
        "data": {
          "node": {
            "description": "# Dataset Search System",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note",
          "id": "note-5BfxR"
        },
        "selected": false,
        "width": 600,
        "height": 324,
        "positionAbsolute": {
          "x": 2039.5844260837744,
          "y": -1604.1485298807581
        },
        "dragging": false,
        "style": {
          "width": 600,
          "height": 324
        },
        "resizing": false,
        "measured": {
          "width": 601,
          "height": 324
        }
      },
      {
        "id": "note-OFpA9",
        "type": "noteNode",
        "position": {
          "x": 8704.910261183544,
          "y": -1142.8172327985571
        },
        "data": {
          "node": {
            "description": "# Save Search Config",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "blue"
            }
          },
          "type": "note",
          "id": "note-OFpA9"
        },
        "selected": false,
        "width": 421,
        "height": 324,
        "positionAbsolute": {
          "x": 7842.0084292551865,
          "y": -480.80259983764756
        },
        "dragging": false,
        "resizing": false,
        "style": {
          "width": 421,
          "height": 324
        },
        "measured": {
          "width": 422,
          "height": 324
        }
      },
      {
        "id": "MessagetoData-xan5A",
        "type": "genericNode",
        "position": {
          "x": 1566.4876170489356,
          "y": -1529.860052916314
        },
        "data": {
          "node": {
            "template": {
              "_type": "Component",
              "code": {
                "type": "code",
                "required": true,
                "placeholder": "",
                "list": false,
                "show": true,
                "multiline": true,
                "value": "from loguru import logger\n\nfrom langflow.custom import Component\nfrom langflow.io import MessageInput, Output\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass MessageToDataComponent(Component):\n    display_name = \"Message to Data\"\n    description = \"Convert a Message object to a Data object\"\n    icon = \"message-square-share\"\n    beta = True\n    name = \"MessagetoData\"\n\n    inputs = [\n        MessageInput(\n            name=\"message\",\n            display_name=\"Message\",\n            info=\"The Message object to convert to a Data object\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Data\", name=\"data\", method=\"convert_message_to_data\"),\n    ]\n\n    def convert_message_to_data(self) -> Data:\n        if isinstance(self.message, Message):\n            # Convert Message to Data\n            return Data(data=self.message.data)\n\n        msg = \"Error converting Message to Data: Input must be a Message object\"\n        logger.opt(exception=True).debug(msg)\n        self.status = msg\n        return Data(data={\"error\": msg})\n",
                "fileTypes": [],
                "file_path": "",
                "password": false,
                "name": "code",
                "advanced": true,
                "dynamic": true,
                "info": "",
                "load_from_db": false,
                "title_case": false
              },
              "message": {
                "trace_as_input": true,
                "trace_as_metadata": true,
                "load_from_db": false,
                "list": false,
                "required": false,
                "placeholder": "",
                "show": true,
                "name": "message",
                "value": "",
                "display_name": "Message",
                "advanced": false,
                "input_types": [
                  "Message"
                ],
                "dynamic": false,
                "info": "The Message object to convert to a Data object",
                "title_case": false,
                "type": "str",
                "_input_type": "MessageInput"
              }
            },
            "description": "Convert a Message object to a Data object",
            "icon": "message-square-share",
            "base_classes": [
              "Data"
            ],
            "display_name": "Message to Data",
            "documentation": "",
            "custom_fields": {},
            "output_types": [],
            "pinned": false,
            "conditional_paths": [],
            "frozen": false,
            "outputs": [
              {
                "types": [
                  "Data"
                ],
                "selected": "Data",
                "name": "data",
                "display_name": "Data",
                "method": "convert_message_to_data",
                "value": "__UNDEFINED__",
                "cache": true
              }
            ],
            "field_order": [
              "message"
            ],
            "beta": true,
            "legacy": false,
            "edited": false,
            "metadata": {},
            "tool_mode": false,
            "category": "processing",
            "key": "MessagetoData",
            "score": 0.008222426499470714,
            "lf_version": "1.2.0"
          },
          "type": "MessagetoData",
          "id": "MessagetoData-xan5A"
        },
        "selected": false,
        "width": 320,
        "height": 233,
        "dragging": false,
        "positionAbsolute": {
          "x": 1566.4876170489356,
          "y": -1529.860052916314
        },
        "measured": {
          "width": 320,
          "height": 233
        }
      }
    ],
    "edges": [
      {
        "source": "CMIP6DatasetProcessorComponent-TaOPv",
        "target": "TemporalResolutionFilterComponent-3pGxq",
        "sourceHandle": "{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-TaOPvœ,œnameœ:œprocessed_dfœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œdataset_infoœ,œidœ:œTemporalResolutionFilterComponent-3pGxqœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-CMIP6DatasetProcessorComponent-TaOPv{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-TaOPvœ,œnameœ:œprocessed_dfœ,œoutput_typesœ:[œDataœ]}-TemporalResolutionFilterComponent-3pGxq{œfieldNameœ:œdataset_infoœ,œidœ:œTemporalResolutionFilterComponent-3pGxqœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "dataset_info",
            "id": "TemporalResolutionFilterComponent-3pGxq",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CMIP6DatasetProcessorComponent",
            "id": "CMIP6DatasetProcessorComponent-TaOPv",
            "name": "processed_df",
            "output_types": [
              "Data"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "TemporalResolutionFilterComponent-3pGxq",
        "target": "YearRangeFilterComponent-VS8WD",
        "sourceHandle": "{œdataTypeœ:œTemporalResolutionFilterComponentœ,œidœ:œTemporalResolutionFilterComponent-3pGxqœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œdataset_infoœ,œidœ:œYearRangeFilterComponent-VS8WDœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-TemporalResolutionFilterComponent-3pGxq{œdataTypeœ:œTemporalResolutionFilterComponentœ,œidœ:œTemporalResolutionFilterComponent-3pGxqœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}-YearRangeFilterComponent-VS8WD{œfieldNameœ:œdataset_infoœ,œidœ:œYearRangeFilterComponent-VS8WDœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "dataset_info",
            "id": "YearRangeFilterComponent-VS8WD",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "TemporalResolutionFilterComponent",
            "id": "TemporalResolutionFilterComponent-3pGxq",
            "name": "filtered_datasets",
            "output_types": [
              "Data"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "YearRangeFilterComponent-VS8WD",
        "target": "URLExtractorComponent-mEoFP",
        "sourceHandle": "{œdataTypeœ:œYearRangeFilterComponentœ,œidœ:œYearRangeFilterComponent-VS8WDœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œdataset_infoœ,œidœ:œURLExtractorComponent-mEoFPœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-YearRangeFilterComponent-VS8WD{œdataTypeœ:œYearRangeFilterComponentœ,œidœ:œYearRangeFilterComponent-VS8WDœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}-URLExtractorComponent-mEoFP{œfieldNameœ:œdataset_infoœ,œidœ:œURLExtractorComponent-mEoFPœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "dataset_info",
            "id": "URLExtractorComponent-mEoFP",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "YearRangeFilterComponent",
            "id": "YearRangeFilterComponent-VS8WD",
            "name": "filtered_datasets",
            "output_types": [
              "Data"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "OpenAIModel-3HdPb",
        "target": "YearRangeFilterComponent-VS8WD",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-3HdPbœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œyear_rangeœ,œidœ:œYearRangeFilterComponent-VS8WDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-OpenAIModel-3HdPb{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-3HdPbœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-YearRangeFilterComponent-VS8WD{œfieldNameœ:œyear_rangeœ,œidœ:œYearRangeFilterComponent-VS8WDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "year_range",
            "id": "YearRangeFilterComponent-VS8WD",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-3HdPb",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "OpenAIModel-AXjuD",
        "target": "TemporalResolutionFilterComponent-3pGxq",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-AXjuDœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "targetHandle": "{œfieldNameœ:œresolutionœ,œidœ:œTemporalResolutionFilterComponent-3pGxqœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "id": "reactflow__edge-OpenAIModel-AXjuD{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-AXjuDœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-TemporalResolutionFilterComponent-3pGxq{œfieldNameœ:œresolutionœ,œidœ:œTemporalResolutionFilterComponent-3pGxqœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "resolution",
            "id": "TemporalResolutionFilterComponent-3pGxq",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-AXjuD",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "CMIP6DatasetProcessorComponent-TaOPv",
        "target": "CMIP6VariableProcessorFromZip-X8bHD",
        "sourceHandle": "{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-TaOPvœ,œnameœ:œprocessed_dfœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œdataset_infoœ,œidœ:œCMIP6VariableProcessorFromZip-X8bHDœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-CMIP6DatasetProcessorComponent-TaOPv{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-TaOPvœ,œnameœ:œprocessed_dfœ,œoutput_typesœ:[œDataœ]}-CMIP6VariableProcessorFromZip-X8bHD{œfieldNameœ:œdataset_infoœ,œidœ:œCMIP6VariableProcessorFromZip-X8bHDœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "dataset_info",
            "id": "CMIP6VariableProcessorFromZip-X8bHD",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CMIP6DatasetProcessorComponent",
            "id": "CMIP6DatasetProcessorComponent-TaOPv",
            "name": "processed_df",
            "output_types": [
              "Data"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "OpenAIEmbeddings-XsKPV",
        "target": "CMIP6VariableProcessorFromZip-X8bHD",
        "sourceHandle": "{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-XsKPVœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "targetHandle": "{œfieldNameœ:œembeddingsœ,œidœ:œCMIP6VariableProcessorFromZip-X8bHDœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-OpenAIEmbeddings-XsKPV{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-XsKPVœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-CMIP6VariableProcessorFromZip-X8bHD{œfieldNameœ:œembeddingsœ,œidœ:œCMIP6VariableProcessorFromZip-X8bHDœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "embeddings",
            "id": "CMIP6VariableProcessorFromZip-X8bHD",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIEmbeddings",
            "id": "OpenAIEmbeddings-XsKPV",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "URLExtractorComponent-mEoFP",
        "target": "ParseData-FSrn8",
        "sourceHandle": "{œdataTypeœ:œURLExtractorComponentœ,œidœ:œURLExtractorComponent-mEoFPœ,œnameœ:œextracted_urlsœ,œoutput_typesœ:[œDataœ]}",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-FSrn8œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "id": "reactflow__edge-URLExtractorComponent-mEoFP{œdataTypeœ:œURLExtractorComponentœ,œidœ:œURLExtractorComponent-mEoFPœ,œnameœ:œextracted_urlsœ,œoutput_typesœ:[œDataœ]}-ParseData-FSrn8{œfieldNameœ:œdataœ,œidœ:œParseData-FSrn8œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-FSrn8",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "URLExtractorComponent",
            "id": "URLExtractorComponent-mEoFP",
            "name": "extracted_urls",
            "output_types": [
              "Data"
            ]
          }
        },
        "selected": false,
        "animated": false,
        "className": ""
      },
      {
        "source": "CMIP6DatasetProcessorComponent-TaOPv",
        "sourceHandle": "{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-TaOPvœ,œnameœ:œunique_experimentsœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-owi82",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-owi82œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-owi82",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CMIP6DatasetProcessorComponent",
            "id": "CMIP6DatasetProcessorComponent-TaOPv",
            "name": "unique_experiments",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CMIP6DatasetProcessorComponent-TaOPv{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-TaOPvœ,œnameœ:œunique_experimentsœ,œoutput_typesœ:[œDataœ]}-ParseData-owi82{œfieldNameœ:œdataœ,œidœ:œParseData-owi82œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "CMIP6DatasetProcessorComponent-TaOPv",
        "sourceHandle": "{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-TaOPvœ,œnameœ:œunique_mipsœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-vmr1o",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-vmr1oœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-vmr1o",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CMIP6DatasetProcessorComponent",
            "id": "CMIP6DatasetProcessorComponent-TaOPv",
            "name": "unique_mips",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CMIP6DatasetProcessorComponent-TaOPv{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-TaOPvœ,œnameœ:œunique_mipsœ,œoutput_typesœ:[œDataœ]}-ParseData-vmr1o{œfieldNameœ:œdataœ,œidœ:œParseData-vmr1oœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "CMIP6DatasetProcessorComponent-TaOPv",
        "sourceHandle": "{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-TaOPvœ,œnameœ:œprocessed_dfœ,œoutput_typesœ:[œDataœ]}",
        "target": "MIPFilterComponent-7xtDm",
        "targetHandle": "{œfieldNameœ:œdataset_infoœ,œidœ:œMIPFilterComponent-7xtDmœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "dataset_info",
            "id": "MIPFilterComponent-7xtDm",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CMIP6DatasetProcessorComponent",
            "id": "CMIP6DatasetProcessorComponent-TaOPv",
            "name": "processed_df",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CMIP6DatasetProcessorComponent-TaOPv{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-TaOPvœ,œnameœ:œprocessed_dfœ,œoutput_typesœ:[œDataœ]}-MIPFilterComponent-7xtDm{œfieldNameœ:œdataset_infoœ,œidœ:œMIPFilterComponent-7xtDmœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "selected": false,
        "animated": false
      },
      {
        "source": "MIPFilterComponent-7xtDm",
        "sourceHandle": "{œdataTypeœ:œMIPFilterComponentœ,œidœ:œMIPFilterComponent-7xtDmœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}",
        "target": "ExperimentFilterComponent-aWhGL",
        "targetHandle": "{œfieldNameœ:œdataset_infoœ,œidœ:œExperimentFilterComponent-aWhGLœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "dataset_info",
            "id": "ExperimentFilterComponent-aWhGL",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "MIPFilterComponent",
            "id": "MIPFilterComponent-7xtDm",
            "name": "filtered_datasets",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-MIPFilterComponent-7xtDm{œdataTypeœ:œMIPFilterComponentœ,œidœ:œMIPFilterComponent-7xtDmœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}-ExperimentFilterComponent-aWhGL{œfieldNameœ:œdataset_infoœ,œidœ:œExperimentFilterComponent-aWhGLœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "OpenAIModel-3ayFc",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-3ayFcœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "MIPFilterComponent-7xtDm",
        "targetHandle": "{œfieldNameœ:œmip_valueœ,œidœ:œMIPFilterComponent-7xtDmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "mip_value",
            "id": "MIPFilterComponent-7xtDm",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-3ayFc",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-3ayFc{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-3ayFcœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-MIPFilterComponent-7xtDm{œfieldNameœ:œmip_valueœ,œidœ:œMIPFilterComponent-7xtDmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "OpenAIModel-jdoTk",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-jdoTkœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ExperimentFilterComponent-aWhGL",
        "targetHandle": "{œfieldNameœ:œexperiment_valueœ,œidœ:œExperimentFilterComponent-aWhGLœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "experiment_value",
            "id": "ExperimentFilterComponent-aWhGL",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-jdoTk",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIModel-jdoTk{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-jdoTkœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ExperimentFilterComponent-aWhGL{œfieldNameœ:œexperiment_valueœ,œidœ:œExperimentFilterComponent-aWhGLœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "CMIP6VariableProcessorFromZip-X8bHD",
        "sourceHandle": "{œdataTypeœ:œCMIP6VariableProcessorFromZipœ,œidœ:œCMIP6VariableProcessorFromZip-X8bHDœ,œnameœ:œvariable_infoœ,œoutput_typesœ:[œDataœ]}",
        "target": "FilteredVariableInfoComponent-J7SKC",
        "targetHandle": "{œfieldNameœ:œvariable_infoœ,œidœ:œFilteredVariableInfoComponent-J7SKCœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "variable_info",
            "id": "FilteredVariableInfoComponent-J7SKC",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "CMIP6VariableProcessorFromZip",
            "id": "CMIP6VariableProcessorFromZip-X8bHD",
            "name": "variable_info",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-CMIP6VariableProcessorFromZip-X8bHD{œdataTypeœ:œCMIP6VariableProcessorFromZipœ,œidœ:œCMIP6VariableProcessorFromZip-X8bHDœ,œnameœ:œvariable_infoœ,œoutput_typesœ:[œDataœ]}-FilteredVariableInfoComponent-J7SKC{œfieldNameœ:œvariable_infoœ,œidœ:œFilteredVariableInfoComponent-J7SKCœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "ExperimentFilterComponent-aWhGL",
        "sourceHandle": "{œdataTypeœ:œExperimentFilterComponentœ,œidœ:œExperimentFilterComponent-aWhGLœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}",
        "target": "FilteredVariableInfoComponent-J7SKC",
        "targetHandle": "{œfieldNameœ:œfiltered_datasetsœ,œidœ:œFilteredVariableInfoComponent-J7SKCœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "filtered_datasets",
            "id": "FilteredVariableInfoComponent-J7SKC",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "ExperimentFilterComponent",
            "id": "ExperimentFilterComponent-aWhGL",
            "name": "filtered_datasets",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-ExperimentFilterComponent-aWhGL{œdataTypeœ:œExperimentFilterComponentœ,œidœ:œExperimentFilterComponent-aWhGLœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}-FilteredVariableInfoComponent-J7SKC{œfieldNameœ:œfiltered_datasetsœ,œidœ:œFilteredVariableInfoComponent-J7SKCœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "FilteredVariableInfoComponent-J7SKC",
        "sourceHandle": "{œdataTypeœ:œFilteredVariableInfoComponentœ,œidœ:œFilteredVariableInfoComponent-J7SKCœ,œnameœ:œfiltered_variable_infoœ,œoutput_typesœ:[œDataœ]}",
        "target": "variable_matcher-S6K64",
        "targetHandle": "{œfieldNameœ:œvariable_infoœ,œidœ:œvariable_matcher-S6K64œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "variable_info",
            "id": "variable_matcher-S6K64",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "FilteredVariableInfoComponent",
            "id": "FilteredVariableInfoComponent-J7SKC",
            "name": "filtered_variable_info",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-FilteredVariableInfoComponent-J7SKC{œdataTypeœ:œFilteredVariableInfoComponentœ,œidœ:œFilteredVariableInfoComponent-J7SKCœ,œnameœ:œfiltered_variable_infoœ,œoutput_typesœ:[œDataœ]}-variable_matcher-S6K64{œfieldNameœ:œvariable_infoœ,œidœ:œvariable_matcher-S6K64œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "FilteredVariableInfoComponent-J7SKC",
        "sourceHandle": "{œdataTypeœ:œFilteredVariableInfoComponentœ,œidœ:œFilteredVariableInfoComponent-J7SKCœ,œnameœ:œfiltered_variable_infoœ,œoutput_typesœ:[œDataœ]}",
        "target": "variable_matcher-aUJnq",
        "targetHandle": "{œfieldNameœ:œvariable_infoœ,œidœ:œvariable_matcher-aUJnqœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "variable_info",
            "id": "variable_matcher-aUJnq",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "FilteredVariableInfoComponent",
            "id": "FilteredVariableInfoComponent-J7SKC",
            "name": "filtered_variable_info",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-FilteredVariableInfoComponent-J7SKC{œdataTypeœ:œFilteredVariableInfoComponentœ,œidœ:œFilteredVariableInfoComponent-J7SKCœ,œnameœ:œfiltered_variable_infoœ,œoutput_typesœ:[œDataœ]}-variable_matcher-aUJnq{œfieldNameœ:œvariable_infoœ,œidœ:œvariable_matcher-aUJnqœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "OpenAIEmbeddings-XsKPV",
        "sourceHandle": "{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-XsKPVœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "target": "variable_matcher-aUJnq",
        "targetHandle": "{œfieldNameœ:œembeddingsœ,œidœ:œvariable_matcher-aUJnqœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "embeddings",
            "id": "variable_matcher-aUJnq",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIEmbeddings",
            "id": "OpenAIEmbeddings-XsKPV",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          }
        },
        "id": "reactflow__edge-OpenAIEmbeddings-XsKPV{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-XsKPVœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-variable_matcher-aUJnq{œfieldNameœ:œembeddingsœ,œidœ:œvariable_matcher-aUJnqœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "variable_matcher-S6K64",
        "sourceHandle": "{œdataTypeœ:œvariable_matcherœ,œidœ:œvariable_matcher-S6K64œ,œnameœ:œmatched_variablesœ,œoutput_typesœ:[œDataœ]}",
        "target": "TemporalResolutionFilterComponent-3pGxq",
        "targetHandle": "{œfieldNameœ:œmatched_variablesœ,œidœ:œTemporalResolutionFilterComponent-3pGxqœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "matched_variables",
            "id": "TemporalResolutionFilterComponent-3pGxq",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "variable_matcher",
            "id": "variable_matcher-S6K64",
            "name": "matched_variables",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-variable_matcher-S6K64{œdataTypeœ:œvariable_matcherœ,œidœ:œvariable_matcher-S6K64œ,œnameœ:œmatched_variablesœ,œoutput_typesœ:[œDataœ]}-TemporalResolutionFilterComponent-3pGxq{œfieldNameœ:œmatched_variablesœ,œidœ:œTemporalResolutionFilterComponent-3pGxqœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false,
        "selected": false
      },
      {
        "source": "Prompt-Q27xi",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-Q27xiœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Agent-wqazV",
        "targetHandle": "{œfieldNameœ:œsystem_promptœ,œidœ:œAgent-wqazVœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "system_prompt",
            "id": "Agent-wqazV",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-Q27xi",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "className": "",
        "id": "reactflow__edge-Prompt-Q27xi{œdataTypeœ:œPromptœ,œidœ:œPrompt-Q27xiœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-Agent-wqazV{œfieldNameœ:œsystem_promptœ,œidœ:œAgent-wqazVœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "selected": false
      },
      {
        "source": "Agent-wqazV",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-wqazVœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "variable_matcher-S6K64",
        "targetHandle": "{œfieldNameœ:œvariable_nameœ,œidœ:œvariable_matcher-S6K64œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "variable_name",
            "id": "variable_matcher-S6K64",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-wqazV",
            "name": "response",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Agent-wqazV{œdataTypeœ:œAgentœ,œidœ:œAgent-wqazVœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-variable_matcher-S6K64{œfieldNameœ:œvariable_nameœ,œidœ:œvariable_matcher-S6K64œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "ParseData-FSrn8",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-FSrn8œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-qg4v7",
        "targetHandle": "{œfieldNameœ:œurlœ,œidœ:œCustomComponent-qg4v7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "url",
            "id": "CustomComponent-qg4v7",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-FSrn8",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-FSrn8{œdataTypeœ:œParseDataœ,œidœ:œParseData-FSrn8œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-qg4v7{œfieldNameœ:œurlœ,œidœ:œCustomComponent-qg4v7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "Agent-wqazV",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-wqazVœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-qg4v7",
        "targetHandle": "{œfieldNameœ:œvariableœ,œidœ:œCustomComponent-qg4v7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "variable",
            "id": "CustomComponent-qg4v7",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-wqazV",
            "name": "response",
            "output_types": [
              "Message"
            ]
          }
        },
        "animated": false,
        "className": "",
        "id": "reactflow__edge-Agent-wqazV{œdataTypeœ:œAgentœ,œidœ:œAgent-wqazVœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-qg4v7{œfieldNameœ:œvariableœ,œidœ:œCustomComponent-qg4v7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false
      },
      {
        "source": "OpenAIModel-AXjuD",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-AXjuDœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-qg4v7",
        "targetHandle": "{œfieldNameœ:œtemporal_resolutionœ,œidœ:œCustomComponent-qg4v7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "temporal_resolution",
            "id": "CustomComponent-qg4v7",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-AXjuD",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "animated": false,
        "className": "",
        "id": "reactflow__edge-OpenAIModel-AXjuD{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-AXjuDœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-qg4v7{œfieldNameœ:œtemporal_resolutionœ,œidœ:œCustomComponent-qg4v7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false
      },
      {
        "source": "OpenAIModel-3HdPb",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-3HdPbœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-qg4v7",
        "targetHandle": "{œfieldNameœ:œdate_rangeœ,œidœ:œCustomComponent-qg4v7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "date_range",
            "id": "CustomComponent-qg4v7",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-3HdPb",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "animated": false,
        "className": "",
        "id": "reactflow__edge-OpenAIModel-3HdPb{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-3HdPbœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-qg4v7{œfieldNameœ:œdate_rangeœ,œidœ:œCustomComponent-qg4v7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false
      },
      {
        "source": "OpenAIModel-jdoTk",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-jdoTkœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-qg4v7",
        "targetHandle": "{œfieldNameœ:œexperimentœ,œidœ:œCustomComponent-qg4v7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "experiment",
            "id": "CustomComponent-qg4v7",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-jdoTk",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "animated": false,
        "className": "",
        "id": "reactflow__edge-OpenAIModel-jdoTk{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-jdoTkœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-qg4v7{œfieldNameœ:œexperimentœ,œidœ:œCustomComponent-qg4v7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false
      },
      {
        "source": "OpenAIModel-3ayFc",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-3ayFcœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-qg4v7",
        "targetHandle": "{œfieldNameœ:œmipœ,œidœ:œCustomComponent-qg4v7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "mip",
            "id": "CustomComponent-qg4v7",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-3ayFc",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "animated": false,
        "className": "",
        "id": "reactflow__edge-OpenAIModel-3ayFc{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-3ayFcœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-qg4v7{œfieldNameœ:œmipœ,œidœ:œCustomComponent-qg4v7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false
      },
      {
        "source": "ParseData-ZwaO0",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-ZwaO0œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-qg4v7",
        "targetHandle": "{œfieldNameœ:œuser_queryœ,œidœ:œCustomComponent-qg4v7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "user_query",
            "id": "CustomComponent-qg4v7",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-ZwaO0",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-ZwaO0{œdataTypeœ:œParseDataœ,œidœ:œParseData-ZwaO0œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-qg4v7{œfieldNameœ:œuser_queryœ,œidœ:œCustomComponent-qg4v7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "className": "",
        "animated": false
      },
      {
        "source": "ChatInput-nXUUg",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-nXUUgœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "MessagetoData-xan5A",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œMessagetoData-xan5Aœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "message",
            "id": "MessagetoData-xan5A",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-nXUUg",
            "name": "message",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ChatInput-nXUUg{œdataTypeœ:œChatInputœ,œidœ:œChatInput-nXUUgœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-MessagetoData-xan5A{œfieldNameœ:œmessageœ,œidœ:œMessagetoData-xan5Aœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "MessagetoData-xan5A",
        "sourceHandle": "{œdataTypeœ:œMessagetoDataœ,œidœ:œMessagetoData-xan5Aœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-ZwaO0",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-ZwaO0œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-ZwaO0",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "MessagetoData",
            "id": "MessagetoData-xan5A",
            "name": "data",
            "output_types": [
              "Data"
            ]
          }
        },
        "id": "reactflow__edge-MessagetoData-xan5A{œdataTypeœ:œMessagetoDataœ,œidœ:œMessagetoData-xan5Aœ,œnameœ:œdataœ,œoutput_typesœ:[œDataœ]}-ParseData-ZwaO0{œfieldNameœ:œdataœ,œidœ:œParseData-ZwaO0œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      },
      {
        "source": "Prompt-qCzNO",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-qCzNOœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-3ayFc",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-3ayFcœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "system_message",
            "id": "OpenAIModel-3ayFc",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-qCzNO",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-Prompt-qCzNO{œdataTypeœ:œPromptœ,œidœ:œPrompt-qCzNOœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-3ayFc{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-3ayFcœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "ParseData-ZwaO0",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-ZwaO0œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-3ayFc",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-3ayFcœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-3ayFc",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-ZwaO0",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "reactflow__edge-ParseData-ZwaO0{œdataTypeœ:œParseDataœ,œidœ:œParseData-ZwaO0œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-3ayFc{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-3ayFcœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "animated": false,
        "className": "",
        "selected": false
      },
      {
        "source": "ParseData-vmr1o",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-vmr1oœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-qCzNO",
        "targetHandle": "{œfieldNameœ:œmip_listœ,œidœ:œPrompt-qCzNOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "mip_list",
            "id": "Prompt-qCzNO",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-vmr1o",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__ParseData-vmr1o{œdataTypeœ:œParseDataœ,œidœ:œParseData-vmr1oœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-qCzNO{œfieldNameœ:œmip_listœ,œidœ:œPrompt-qCzNOœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "ParseData-owi82",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-owi82œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-Z36He",
        "targetHandle": "{œfieldNameœ:œEXPERIMENT_LISTœ,œidœ:œPrompt-Z36Heœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "EXPERIMENT_LIST",
            "id": "Prompt-Z36He",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-owi82",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__ParseData-owi82{œdataTypeœ:œParseDataœ,œidœ:œParseData-owi82œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-Z36He{œfieldNameœ:œEXPERIMENT_LISTœ,œidœ:œPrompt-Z36Heœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "className": "",
        "animated": false
      },
      {
        "source": "OpenAIModel-3ayFc",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-3ayFcœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-XYyZ4",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-XYyZ4œ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-XYyZ4",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-3ayFc",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__OpenAIModel-3ayFc{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-3ayFcœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-XYyZ4{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-XYyZ4œ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "OpenAIModel-jdoTk",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-jdoTkœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-NLJoQ",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-NLJoQœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-NLJoQ",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-jdoTk",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__OpenAIModel-jdoTk{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-jdoTkœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-NLJoQ{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-NLJoQœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "ParseData-ZwaO0",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-ZwaO0œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-jdoTk",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-jdoTkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-jdoTk",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-ZwaO0",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__ParseData-ZwaO0{œdataTypeœ:œParseDataœ,œidœ:œParseData-ZwaO0œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-jdoTk{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-jdoTkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "Prompt-Z36He",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-Z36Heœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-jdoTk",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-jdoTkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "system_message",
            "id": "OpenAIModel-jdoTk",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-Z36He",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__Prompt-Z36He{œdataTypeœ:œPromptœ,œidœ:œPrompt-Z36Heœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-jdoTk{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-jdoTkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "ParseData-ZwaO0",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-ZwaO0œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Agent-wqazV",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œAgent-wqazVœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "Agent-wqazV",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-ZwaO0",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__ParseData-ZwaO0{œdataTypeœ:œParseDataœ,œidœ:œParseData-ZwaO0œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Agent-wqazV{œfieldNameœ:œinput_valueœ,œidœ:œAgent-wqazVœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "Prompt-zA0Up",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-zA0Upœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-AXjuD",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-AXjuDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "system_message",
            "id": "OpenAIModel-AXjuD",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-zA0Up",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__Prompt-zA0Up{œdataTypeœ:œPromptœ,œidœ:œPrompt-zA0Upœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-AXjuD{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-AXjuDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "className": "",
        "animated": false
      },
      {
        "source": "Agent-wqazV",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-wqazVœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-gYkvt",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-gYkvtœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-gYkvt",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-wqazV",
            "name": "response",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__Agent-wqazV{œdataTypeœ:œAgentœ,œidœ:œAgent-wqazVœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-gYkvt{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-gYkvtœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "OpenAIModel-AXjuD",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-AXjuDœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-QNEAa",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-QNEAaœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-QNEAa",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-AXjuD",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__OpenAIModel-AXjuD{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-AXjuDœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-QNEAa{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-QNEAaœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "className": "",
        "animated": false
      },
      {
        "source": "CurrentDateComponent-qbE6Q",
        "sourceHandle": "{œdataTypeœ:œCurrentDateComponentœ,œidœ:œCurrentDateComponent-qbE6Qœ,œnameœ:œcurrent_dateœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-LB8oS",
        "targetHandle": "{œfieldNameœ:œcurrent_dateœ,œidœ:œPrompt-LB8oSœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "current_date",
            "id": "Prompt-LB8oS",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "CurrentDateComponent",
            "id": "CurrentDateComponent-qbE6Q",
            "name": "current_date",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__CurrentDateComponent-qbE6Q{œdataTypeœ:œCurrentDateComponentœ,œidœ:œCurrentDateComponent-qbE6Qœ,œnameœ:œcurrent_dateœ,œoutput_typesœ:[œMessageœ]}-Prompt-LB8oS{œfieldNameœ:œcurrent_dateœ,œidœ:œPrompt-LB8oSœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "Prompt-LB8oS",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-LB8oSœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-3HdPb",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-3HdPbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "system_message",
            "id": "OpenAIModel-3HdPb",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-LB8oS",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__Prompt-LB8oS{œdataTypeœ:œPromptœ,œidœ:œPrompt-LB8oSœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-3HdPb{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-3HdPbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "ParseData-ZwaO0",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-ZwaO0œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-3HdPb",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-3HdPbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-3HdPb",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-ZwaO0",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__ParseData-ZwaO0{œdataTypeœ:œParseDataœ,œidœ:œParseData-ZwaO0œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-3HdPb{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-3HdPbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "ParseData-ZwaO0",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-ZwaO0œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-AXjuD",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-AXjuDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-AXjuD",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          },
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-ZwaO0",
            "name": "text",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__ParseData-ZwaO0{œdataTypeœ:œParseDataœ,œidœ:œParseData-ZwaO0œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-AXjuD{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-AXjuDœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "OpenAIModel-3HdPb",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-3HdPbœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-CAZzq",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-CAZzqœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-CAZzq",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-3HdPb",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          }
        },
        "id": "xy-edge__OpenAIModel-3HdPb{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-3HdPbœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-CAZzq{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-CAZzqœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "className": "",
        "animated": false
      },
      {
        "source": "variable_matcher-aUJnq",
        "sourceHandle": "{œdataTypeœ:œvariable_matcherœ,œidœ:œvariable_matcher-aUJnqœ,œnameœ:œtoolœ,œoutput_typesœ:[œToolœ]}",
        "target": "Agent-wqazV",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œAgent-wqazVœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "data": {
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-wqazV",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          },
          "sourceHandle": {
            "dataType": "variable_matcher",
            "id": "variable_matcher-aUJnq",
            "name": "tool",
            "output_types": [
              "Tool"
            ]
          }
        },
        "id": "xy-edge__variable_matcher-aUJnq{œdataTypeœ:œvariable_matcherœ,œidœ:œvariable_matcher-aUJnqœ,œnameœ:œtoolœ,œoutput_typesœ:[œToolœ]}-Agent-wqazV{œfieldNameœ:œtoolsœ,œidœ:œAgent-wqazVœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "animated": false,
        "className": ""
      }
    ],
    "viewport": {
      "x": -1676.1648842434238,
      "y": 2148.0293316608254,
      "zoom": 0.6040799976853889
    }
  },
  "description": "Your Toolkit for Text Generation.",
  "name": "Dataset Retrieval - v1.0.4 (QUERY ONLY)",
  "last_tested_version": "1.2.0",
  "endpoint_name": "nasa-dataset-selector-02-1-1-1",
  "is_component": false
}