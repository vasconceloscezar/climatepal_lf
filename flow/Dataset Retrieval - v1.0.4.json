{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CMIP6DatasetProcessorComponent",
            "id": "CMIP6DatasetProcessorComponent-LKKLu",
            "name": "processed_df",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "dataset_info",
            "id": "TemporalResolutionFilterComponent-ZtcSN",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-CMIP6DatasetProcessorComponent-LKKLu{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-LKKLuœ,œnameœ:œprocessed_dfœ,œoutput_typesœ:[œDataœ]}-TemporalResolutionFilterComponent-ZtcSN{œfieldNameœ:œdataset_infoœ,œidœ:œTemporalResolutionFilterComponent-ZtcSNœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CMIP6DatasetProcessorComponent-LKKLu",
        "sourceHandle": "{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-LKKLuœ,œnameœ:œprocessed_dfœ,œoutput_typesœ:[œDataœ]}",
        "target": "TemporalResolutionFilterComponent-ZtcSN",
        "targetHandle": "{œfieldNameœ:œdataset_infoœ,œidœ:œTemporalResolutionFilterComponent-ZtcSNœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TemporalResolutionFilterComponent",
            "id": "TemporalResolutionFilterComponent-ZtcSN",
            "name": "filtered_datasets",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "dataset_info",
            "id": "YearRangeFilterComponent-o9DZU",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-TemporalResolutionFilterComponent-ZtcSN{œdataTypeœ:œTemporalResolutionFilterComponentœ,œidœ:œTemporalResolutionFilterComponent-ZtcSNœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}-YearRangeFilterComponent-o9DZU{œfieldNameœ:œdataset_infoœ,œidœ:œYearRangeFilterComponent-o9DZUœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "TemporalResolutionFilterComponent-ZtcSN",
        "sourceHandle": "{œdataTypeœ:œTemporalResolutionFilterComponentœ,œidœ:œTemporalResolutionFilterComponent-ZtcSNœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}",
        "target": "YearRangeFilterComponent-o9DZU",
        "targetHandle": "{œfieldNameœ:œdataset_infoœ,œidœ:œYearRangeFilterComponent-o9DZUœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "YearRangeFilterComponent",
            "id": "YearRangeFilterComponent-o9DZU",
            "name": "filtered_datasets",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "dataset_info",
            "id": "URLExtractorComponent-ijoej",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-YearRangeFilterComponent-o9DZU{œdataTypeœ:œYearRangeFilterComponentœ,œidœ:œYearRangeFilterComponent-o9DZUœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}-URLExtractorComponent-ijoej{œfieldNameœ:œdataset_infoœ,œidœ:œURLExtractorComponent-ijoejœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "YearRangeFilterComponent-o9DZU",
        "sourceHandle": "{œdataTypeœ:œYearRangeFilterComponentœ,œidœ:œYearRangeFilterComponent-o9DZUœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}",
        "target": "URLExtractorComponent-ijoej",
        "targetHandle": "{œfieldNameœ:œdataset_infoœ,œidœ:œURLExtractorComponent-ijoejœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-if9V0",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "year_range",
            "id": "YearRangeFilterComponent-o9DZU",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-OpenAIModel-if9V0{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-if9V0œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-YearRangeFilterComponent-o9DZU{œfieldNameœ:œyear_rangeœ,œidœ:œYearRangeFilterComponent-o9DZUœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "OpenAIModel-if9V0",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-if9V0œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "YearRangeFilterComponent-o9DZU",
        "targetHandle": "{œfieldNameœ:œyear_rangeœ,œidœ:œYearRangeFilterComponent-o9DZUœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-bRtf6",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "resolution",
            "id": "TemporalResolutionFilterComponent-ZtcSN",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-OpenAIModel-bRtf6{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-bRtf6œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-TemporalResolutionFilterComponent-ZtcSN{œfieldNameœ:œresolutionœ,œidœ:œTemporalResolutionFilterComponent-ZtcSNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "OpenAIModel-bRtf6",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-bRtf6œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "TemporalResolutionFilterComponent-ZtcSN",
        "targetHandle": "{œfieldNameœ:œresolutionœ,œidœ:œTemporalResolutionFilterComponent-ZtcSNœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CMIP6DatasetProcessorComponent",
            "id": "CMIP6DatasetProcessorComponent-LKKLu",
            "name": "processed_df",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "dataset_info",
            "id": "CMIP6VariableProcessorFromZip-9CfEc",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-CMIP6DatasetProcessorComponent-LKKLu{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-LKKLuœ,œnameœ:œprocessed_dfœ,œoutput_typesœ:[œDataœ]}-CMIP6VariableProcessorFromZip-9CfEc{œfieldNameœ:œdataset_infoœ,œidœ:œCMIP6VariableProcessorFromZip-9CfEcœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CMIP6DatasetProcessorComponent-LKKLu",
        "sourceHandle": "{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-LKKLuœ,œnameœ:œprocessed_dfœ,œoutput_typesœ:[œDataœ]}",
        "target": "CMIP6VariableProcessorFromZip-9CfEc",
        "targetHandle": "{œfieldNameœ:œdataset_infoœ,œidœ:œCMIP6VariableProcessorFromZip-9CfEcœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIEmbeddings",
            "id": "OpenAIEmbeddings-XvpND",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          },
          "targetHandle": {
            "fieldName": "embeddings",
            "id": "CMIP6VariableProcessorFromZip-9CfEc",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-OpenAIEmbeddings-XvpND{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-XvpNDœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-CMIP6VariableProcessorFromZip-9CfEc{œfieldNameœ:œembeddingsœ,œidœ:œCMIP6VariableProcessorFromZip-9CfEcœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "OpenAIEmbeddings-XvpND",
        "sourceHandle": "{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-XvpNDœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "target": "CMIP6VariableProcessorFromZip-9CfEc",
        "targetHandle": "{œfieldNameœ:œembeddingsœ,œidœ:œCMIP6VariableProcessorFromZip-9CfEcœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "URLExtractorComponent",
            "id": "URLExtractorComponent-ijoej",
            "name": "extracted_urls",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-HxL7X",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-URLExtractorComponent-ijoej{œdataTypeœ:œURLExtractorComponentœ,œidœ:œURLExtractorComponent-ijoejœ,œnameœ:œextracted_urlsœ,œoutput_typesœ:[œDataœ]}-ParseData-HxL7X{œfieldNameœ:œdataœ,œidœ:œParseData-HxL7Xœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "URLExtractorComponent-ijoej",
        "sourceHandle": "{œdataTypeœ:œURLExtractorComponentœ,œidœ:œURLExtractorComponent-ijoejœ,œnameœ:œextracted_urlsœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-HxL7X",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-HxL7Xœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CMIP6DatasetProcessorComponent",
            "id": "CMIP6DatasetProcessorComponent-LKKLu",
            "name": "unique_experiments",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-93N1M",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-CMIP6DatasetProcessorComponent-LKKLu{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-LKKLuœ,œnameœ:œunique_experimentsœ,œoutput_typesœ:[œDataœ]}-ParseData-93N1M{œfieldNameœ:œdataœ,œidœ:œParseData-93N1Mœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CMIP6DatasetProcessorComponent-LKKLu",
        "sourceHandle": "{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-LKKLuœ,œnameœ:œunique_experimentsœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-93N1M",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-93N1Mœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CMIP6DatasetProcessorComponent",
            "id": "CMIP6DatasetProcessorComponent-LKKLu",
            "name": "unique_mips",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-PqYbG",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-CMIP6DatasetProcessorComponent-LKKLu{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-LKKLuœ,œnameœ:œunique_mipsœ,œoutput_typesœ:[œDataœ]}-ParseData-PqYbG{œfieldNameœ:œdataœ,œidœ:œParseData-PqYbGœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CMIP6DatasetProcessorComponent-LKKLu",
        "sourceHandle": "{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-LKKLuœ,œnameœ:œunique_mipsœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-PqYbG",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-PqYbGœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CMIP6DatasetProcessorComponent",
            "id": "CMIP6DatasetProcessorComponent-LKKLu",
            "name": "processed_df",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "dataset_info",
            "id": "MIPFilterComponent-XWg03",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-CMIP6DatasetProcessorComponent-LKKLu{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-LKKLuœ,œnameœ:œprocessed_dfœ,œoutput_typesœ:[œDataœ]}-MIPFilterComponent-XWg03{œfieldNameœ:œdataset_infoœ,œidœ:œMIPFilterComponent-XWg03œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CMIP6DatasetProcessorComponent-LKKLu",
        "sourceHandle": "{œdataTypeœ:œCMIP6DatasetProcessorComponentœ,œidœ:œCMIP6DatasetProcessorComponent-LKKLuœ,œnameœ:œprocessed_dfœ,œoutput_typesœ:[œDataœ]}",
        "target": "MIPFilterComponent-XWg03",
        "targetHandle": "{œfieldNameœ:œdataset_infoœ,œidœ:œMIPFilterComponent-XWg03œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "MIPFilterComponent",
            "id": "MIPFilterComponent-XWg03",
            "name": "filtered_datasets",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "dataset_info",
            "id": "ExperimentFilterComponent-dIkmu",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-MIPFilterComponent-XWg03{œdataTypeœ:œMIPFilterComponentœ,œidœ:œMIPFilterComponent-XWg03œ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}-ExperimentFilterComponent-dIkmu{œfieldNameœ:œdataset_infoœ,œidœ:œExperimentFilterComponent-dIkmuœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "MIPFilterComponent-XWg03",
        "sourceHandle": "{œdataTypeœ:œMIPFilterComponentœ,œidœ:œMIPFilterComponent-XWg03œ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}",
        "target": "ExperimentFilterComponent-dIkmu",
        "targetHandle": "{œfieldNameœ:œdataset_infoœ,œidœ:œExperimentFilterComponent-dIkmuœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-HOKWH",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "mip_value",
            "id": "MIPFilterComponent-XWg03",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-OpenAIModel-HOKWH{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-HOKWHœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-MIPFilterComponent-XWg03{œfieldNameœ:œmip_valueœ,œidœ:œMIPFilterComponent-XWg03œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "OpenAIModel-HOKWH",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-HOKWHœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "MIPFilterComponent-XWg03",
        "targetHandle": "{œfieldNameœ:œmip_valueœ,œidœ:œMIPFilterComponent-XWg03œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-svP8u",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "experiment_value",
            "id": "ExperimentFilterComponent-dIkmu",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-OpenAIModel-svP8u{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-svP8uœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ExperimentFilterComponent-dIkmu{œfieldNameœ:œexperiment_valueœ,œidœ:œExperimentFilterComponent-dIkmuœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "OpenAIModel-svP8u",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-svP8uœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ExperimentFilterComponent-dIkmu",
        "targetHandle": "{œfieldNameœ:œexperiment_valueœ,œidœ:œExperimentFilterComponent-dIkmuœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CMIP6VariableProcessorFromZip",
            "id": "CMIP6VariableProcessorFromZip-9CfEc",
            "name": "variable_info",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "variable_info",
            "id": "FilteredVariableInfoComponent-vET89",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-CMIP6VariableProcessorFromZip-9CfEc{œdataTypeœ:œCMIP6VariableProcessorFromZipœ,œidœ:œCMIP6VariableProcessorFromZip-9CfEcœ,œnameœ:œvariable_infoœ,œoutput_typesœ:[œDataœ]}-FilteredVariableInfoComponent-vET89{œfieldNameœ:œvariable_infoœ,œidœ:œFilteredVariableInfoComponent-vET89œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CMIP6VariableProcessorFromZip-9CfEc",
        "sourceHandle": "{œdataTypeœ:œCMIP6VariableProcessorFromZipœ,œidœ:œCMIP6VariableProcessorFromZip-9CfEcœ,œnameœ:œvariable_infoœ,œoutput_typesœ:[œDataœ]}",
        "target": "FilteredVariableInfoComponent-vET89",
        "targetHandle": "{œfieldNameœ:œvariable_infoœ,œidœ:œFilteredVariableInfoComponent-vET89œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ExperimentFilterComponent",
            "id": "ExperimentFilterComponent-dIkmu",
            "name": "filtered_datasets",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "filtered_datasets",
            "id": "FilteredVariableInfoComponent-vET89",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-ExperimentFilterComponent-dIkmu{œdataTypeœ:œExperimentFilterComponentœ,œidœ:œExperimentFilterComponent-dIkmuœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}-FilteredVariableInfoComponent-vET89{œfieldNameœ:œfiltered_datasetsœ,œidœ:œFilteredVariableInfoComponent-vET89œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "ExperimentFilterComponent-dIkmu",
        "sourceHandle": "{œdataTypeœ:œExperimentFilterComponentœ,œidœ:œExperimentFilterComponent-dIkmuœ,œnameœ:œfiltered_datasetsœ,œoutput_typesœ:[œDataœ]}",
        "target": "FilteredVariableInfoComponent-vET89",
        "targetHandle": "{œfieldNameœ:œfiltered_datasetsœ,œidœ:œFilteredVariableInfoComponent-vET89œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "FilteredVariableInfoComponent",
            "id": "FilteredVariableInfoComponent-vET89",
            "name": "filtered_variable_info",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "variable_info",
            "id": "variable_matcher-tAMdg",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-FilteredVariableInfoComponent-vET89{œdataTypeœ:œFilteredVariableInfoComponentœ,œidœ:œFilteredVariableInfoComponent-vET89œ,œnameœ:œfiltered_variable_infoœ,œoutput_typesœ:[œDataœ]}-variable_matcher-tAMdg{œfieldNameœ:œvariable_infoœ,œidœ:œvariable_matcher-tAMdgœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "FilteredVariableInfoComponent-vET89",
        "sourceHandle": "{œdataTypeœ:œFilteredVariableInfoComponentœ,œidœ:œFilteredVariableInfoComponent-vET89œ,œnameœ:œfiltered_variable_infoœ,œoutput_typesœ:[œDataœ]}",
        "target": "variable_matcher-tAMdg",
        "targetHandle": "{œfieldNameœ:œvariable_infoœ,œidœ:œvariable_matcher-tAMdgœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "FilteredVariableInfoComponent",
            "id": "FilteredVariableInfoComponent-vET89",
            "name": "filtered_variable_info",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "variable_info",
            "id": "variable_matcher-GNxID",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-FilteredVariableInfoComponent-vET89{œdataTypeœ:œFilteredVariableInfoComponentœ,œidœ:œFilteredVariableInfoComponent-vET89œ,œnameœ:œfiltered_variable_infoœ,œoutput_typesœ:[œDataœ]}-variable_matcher-GNxID{œfieldNameœ:œvariable_infoœ,œidœ:œvariable_matcher-GNxIDœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "FilteredVariableInfoComponent-vET89",
        "sourceHandle": "{œdataTypeœ:œFilteredVariableInfoComponentœ,œidœ:œFilteredVariableInfoComponent-vET89œ,œnameœ:œfiltered_variable_infoœ,œoutput_typesœ:[œDataœ]}",
        "target": "variable_matcher-GNxID",
        "targetHandle": "{œfieldNameœ:œvariable_infoœ,œidœ:œvariable_matcher-GNxIDœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIEmbeddings",
            "id": "OpenAIEmbeddings-XvpND",
            "name": "embeddings",
            "output_types": [
              "Embeddings"
            ]
          },
          "targetHandle": {
            "fieldName": "embeddings",
            "id": "variable_matcher-GNxID",
            "inputTypes": [
              "Embeddings"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-OpenAIEmbeddings-XvpND{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-XvpNDœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}-variable_matcher-GNxID{œfieldNameœ:œembeddingsœ,œidœ:œvariable_matcher-GNxIDœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "OpenAIEmbeddings-XvpND",
        "sourceHandle": "{œdataTypeœ:œOpenAIEmbeddingsœ,œidœ:œOpenAIEmbeddings-XvpNDœ,œnameœ:œembeddingsœ,œoutput_typesœ:[œEmbeddingsœ]}",
        "target": "variable_matcher-GNxID",
        "targetHandle": "{œfieldNameœ:œembeddingsœ,œidœ:œvariable_matcher-GNxIDœ,œinputTypesœ:[œEmbeddingsœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "variable_matcher",
            "id": "variable_matcher-tAMdg",
            "name": "matched_variables",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "matched_variables",
            "id": "TemporalResolutionFilterComponent-ZtcSN",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-variable_matcher-tAMdg{œdataTypeœ:œvariable_matcherœ,œidœ:œvariable_matcher-tAMdgœ,œnameœ:œmatched_variablesœ,œoutput_typesœ:[œDataœ]}-TemporalResolutionFilterComponent-ZtcSN{œfieldNameœ:œmatched_variablesœ,œidœ:œTemporalResolutionFilterComponent-ZtcSNœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "variable_matcher-tAMdg",
        "sourceHandle": "{œdataTypeœ:œvariable_matcherœ,œidœ:œvariable_matcher-tAMdgœ,œnameœ:œmatched_variablesœ,œoutput_typesœ:[œDataœ]}",
        "target": "TemporalResolutionFilterComponent-ZtcSN",
        "targetHandle": "{œfieldNameœ:œmatched_variablesœ,œidœ:œTemporalResolutionFilterComponent-ZtcSNœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-jcZAy",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_prompt",
            "id": "Agent-y4GVw",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt-jcZAy{œdataTypeœ:œPromptœ,œidœ:œPrompt-jcZAyœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-Agent-y4GVw{œfieldNameœ:œsystem_promptœ,œidœ:œAgent-y4GVwœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-jcZAy",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-jcZAyœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Agent-y4GVw",
        "targetHandle": "{œfieldNameœ:œsystem_promptœ,œidœ:œAgent-y4GVwœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-y4GVw",
            "name": "response",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "variable_name",
            "id": "variable_matcher-tAMdg",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Agent-y4GVw{œdataTypeœ:œAgentœ,œidœ:œAgent-y4GVwœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-variable_matcher-tAMdg{œfieldNameœ:œvariable_nameœ,œidœ:œvariable_matcher-tAMdgœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Agent-y4GVw",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-y4GVwœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "variable_matcher-tAMdg",
        "targetHandle": "{œfieldNameœ:œvariable_nameœ,œidœ:œvariable_matcher-tAMdgœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-HxL7X",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "url",
            "id": "CustomComponent-qUYAm",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParseData-HxL7X{œdataTypeœ:œParseDataœ,œidœ:œParseData-HxL7Xœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-qUYAm{œfieldNameœ:œurlœ,œidœ:œCustomComponent-qUYAmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-HxL7X",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-HxL7Xœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-qUYAm",
        "targetHandle": "{œfieldNameœ:œurlœ,œidœ:œCustomComponent-qUYAmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ChatInput",
            "id": "ChatInput-KYwsa",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "message",
            "id": "CustomComponent-e7Nca",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ChatInput-KYwsa{œdataTypeœ:œChatInputœ,œidœ:œChatInput-KYwsaœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-e7Nca{œfieldNameœ:œmessageœ,œidœ:œCustomComponent-e7Ncaœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ChatInput-KYwsa",
        "sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-KYwsaœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-e7Nca",
        "targetHandle": "{œfieldNameœ:œmessageœ,œidœ:œCustomComponent-e7Ncaœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-4cK1Z",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "llm",
            "id": "StructuredOutputComponent-qkVXR",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-OpenAIModel-4cK1Z{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-4cK1Zœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-StructuredOutputComponent-qkVXR{œfieldNameœ:œllmœ,œidœ:œStructuredOutputComponent-qkVXRœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "OpenAIModel-4cK1Z",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-4cK1Zœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "StructuredOutputComponent-qkVXR",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œStructuredOutputComponent-qkVXRœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-y4GVw",
            "name": "response",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "variable",
            "id": "CustomComponent-qUYAm",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Agent-y4GVw{œdataTypeœ:œAgentœ,œidœ:œAgent-y4GVwœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-qUYAm{œfieldNameœ:œvariableœ,œidœ:œCustomComponent-qUYAmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Agent-y4GVw",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-y4GVwœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-qUYAm",
        "targetHandle": "{œfieldNameœ:œvariableœ,œidœ:œCustomComponent-qUYAmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-bRtf6",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "temporal_resolution",
            "id": "CustomComponent-qUYAm",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-OpenAIModel-bRtf6{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-bRtf6œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-qUYAm{œfieldNameœ:œtemporal_resolutionœ,œidœ:œCustomComponent-qUYAmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "OpenAIModel-bRtf6",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-bRtf6œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-qUYAm",
        "targetHandle": "{œfieldNameœ:œtemporal_resolutionœ,œidœ:œCustomComponent-qUYAmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-if9V0",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "date_range",
            "id": "CustomComponent-qUYAm",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-OpenAIModel-if9V0{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-if9V0œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-qUYAm{œfieldNameœ:œdate_rangeœ,œidœ:œCustomComponent-qUYAmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "OpenAIModel-if9V0",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-if9V0œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-qUYAm",
        "targetHandle": "{œfieldNameœ:œdate_rangeœ,œidœ:œCustomComponent-qUYAmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-svP8u",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "experiment",
            "id": "CustomComponent-qUYAm",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-OpenAIModel-svP8u{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-svP8uœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-qUYAm{œfieldNameœ:œexperimentœ,œidœ:œCustomComponent-qUYAmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "OpenAIModel-svP8u",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-svP8uœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-qUYAm",
        "targetHandle": "{œfieldNameœ:œexperimentœ,œidœ:œCustomComponent-qUYAmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-HOKWH",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "mip",
            "id": "CustomComponent-qUYAm",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-OpenAIModel-HOKWH{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-HOKWHœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-qUYAm{œfieldNameœ:œmipœ,œidœ:œCustomComponent-qUYAmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "OpenAIModel-HOKWH",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-HOKWHœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-qUYAm",
        "targetHandle": "{œfieldNameœ:œmipœ,œidœ:œCustomComponent-qUYAmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-4cK1Z",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "StructuredOutputComponent-qkVXR",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-OpenAIModel-4cK1Z{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-4cK1Zœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-StructuredOutputComponent-qkVXR{œfieldNameœ:œinput_valueœ,œidœ:œStructuredOutputComponent-qkVXRœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "OpenAIModel-4cK1Z",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-4cK1Zœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "StructuredOutputComponent-qkVXR",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œStructuredOutputComponent-qkVXRœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-xcvV3",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "OpenAIModel-4cK1Z",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-Prompt-xcvV3{œdataTypeœ:œPromptœ,œidœ:œPrompt-xcvV3œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-4cK1Z{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-4cK1Zœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-xcvV3",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-xcvV3œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-4cK1Z",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-4cK1Zœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "StructuredOutputComponent",
            "id": "StructuredOutputComponent-qkVXR",
            "name": "structured_output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "trigger_data",
            "id": "CustomComponent-6cLV6",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-StructuredOutputComponent-qkVXR{œdataTypeœ:œStructuredOutputComponentœ,œidœ:œStructuredOutputComponent-qkVXRœ,œnameœ:œstructured_outputœ,œoutput_typesœ:[œDataœ]}-CustomComponent-6cLV6{œfieldNameœ:œtrigger_dataœ,œidœ:œCustomComponent-6cLV6œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "StructuredOutputComponent-qkVXR",
        "sourceHandle": "{œdataTypeœ:œStructuredOutputComponentœ,œidœ:œStructuredOutputComponent-qkVXRœ,œnameœ:œstructured_outputœ,œoutput_typesœ:[œDataœ]}",
        "target": "CustomComponent-6cLV6",
        "targetHandle": "{œfieldNameœ:œtrigger_dataœ,œidœ:œCustomComponent-6cLV6œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-6cLV6",
            "name": "cleared_status",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-7GGUs",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-CustomComponent-6cLV6{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-6cLV6œ,œnameœ:œcleared_statusœ,œoutput_typesœ:[œDataœ]}-ParseData-7GGUs{œfieldNameœ:œdataœ,œidœ:œParseData-7GGUsœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-6cLV6",
        "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-6cLV6œ,œnameœ:œcleared_statusœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-7GGUs",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-7GGUsœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-7GGUs",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "OpenAIModel-YQJsh",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParseData-7GGUs{œdataTypeœ:œParseDataœ,œidœ:œParseData-7GGUsœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-YQJsh{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-YQJshœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-7GGUs",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-7GGUsœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-YQJsh",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-YQJshœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "StructuredOutputComponent",
            "id": "StructuredOutputComponent-qkVXR",
            "name": "structured_output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "sentiment_data",
            "id": "CustomComponent-fDa6H",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-StructuredOutputComponent-qkVXR{œdataTypeœ:œStructuredOutputComponentœ,œidœ:œStructuredOutputComponent-qkVXRœ,œnameœ:œstructured_outputœ,œoutput_typesœ:[œDataœ]}-CustomComponent-fDa6H{œfieldNameœ:œsentiment_dataœ,œidœ:œCustomComponent-fDa6Hœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "StructuredOutputComponent-qkVXR",
        "sourceHandle": "{œdataTypeœ:œStructuredOutputComponentœ,œidœ:œStructuredOutputComponent-qkVXRœ,œnameœ:œstructured_outputœ,œoutput_typesœ:[œDataœ]}",
        "target": "CustomComponent-fDa6H",
        "targetHandle": "{œfieldNameœ:œsentiment_dataœ,œidœ:œCustomComponent-fDa6Hœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-8bP1x",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "search_run_id",
            "id": "CustomComponent-fDa6H",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParseData-8bP1x{œdataTypeœ:œParseDataœ,œidœ:œParseData-8bP1xœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-fDa6H{œfieldNameœ:œsearch_run_idœ,œidœ:œCustomComponent-fDa6Hœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-8bP1x",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-8bP1xœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-fDa6H",
        "targetHandle": "{œfieldNameœ:œsearch_run_idœ,œidœ:œCustomComponent-fDa6Hœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-S98qC",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-4cK1Z",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParseData-S98qC{œdataTypeœ:œParseDataœ,œidœ:œParseData-S98qCœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-4cK1Z{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-4cK1Zœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-S98qC",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-S98qCœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-4cK1Z",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-4cK1Zœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-S98qC",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-YQJsh",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParseData-S98qC{œdataTypeœ:œParseDataœ,œidœ:œParseData-S98qCœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-YQJsh{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-YQJshœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-S98qC",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-S98qCœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-YQJsh",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-YQJshœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-qUYAm",
            "name": "saved_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "config_data",
            "id": "CustomComponent-MD44N",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-CustomComponent-qUYAm{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-qUYAmœ,œnameœ:œsaved_dataœ,œoutput_typesœ:[œDataœ]}-CustomComponent-MD44N{œfieldNameœ:œconfig_dataœ,œidœ:œCustomComponent-MD44Nœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-qUYAm",
        "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-qUYAmœ,œnameœ:œsaved_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "CustomComponent-MD44N",
        "targetHandle": "{œfieldNameœ:œconfig_dataœ,œidœ:œCustomComponent-MD44Nœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-NeKJ6",
            "name": "config_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "input_data",
            "id": "CustomComponent-e7Nca",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-CustomComponent-NeKJ6{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-NeKJ6œ,œnameœ:œconfig_dataœ,œoutput_typesœ:[œDataœ]}-CustomComponent-e7Nca{œfieldNameœ:œinput_dataœ,œidœ:œCustomComponent-e7Ncaœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-NeKJ6",
        "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-NeKJ6œ,œnameœ:œconfig_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "CustomComponent-e7Nca",
        "targetHandle": "{œfieldNameœ:œinput_dataœ,œidœ:œCustomComponent-e7Ncaœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-qUYAm",
            "name": "saved_data",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-RW53y",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-CustomComponent-qUYAm{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-qUYAmœ,œnameœ:œsaved_dataœ,œoutput_typesœ:[œDataœ]}-ParseData-RW53y{œfieldNameœ:œdataœ,œidœ:œParseData-RW53yœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-qUYAm",
        "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-qUYAmœ,œnameœ:œsaved_dataœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-RW53y",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-RW53yœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-e7Nca",
            "name": "url_present",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-S98qC",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-CustomComponent-e7Nca{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-e7Ncaœ,œnameœ:œurl_presentœ,œoutput_typesœ:[œDataœ]}-ParseData-S98qC{œfieldNameœ:œdataœ,œidœ:œParseData-S98qCœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-e7Nca",
        "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-e7Ncaœ,œnameœ:œurl_presentœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-S98qC",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-S98qCœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-e7Nca",
            "name": "url_absent",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-8ShCt",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-CustomComponent-e7Nca{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-e7Ncaœ,œnameœ:œurl_absentœ,œoutput_typesœ:[œDataœ]}-ParseData-8ShCt{œfieldNameœ:œdataœ,œidœ:œParseData-8ShCtœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-e7Nca",
        "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-e7Ncaœ,œnameœ:œurl_absentœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-8ShCt",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-8ShCtœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-e7Nca",
            "name": "url_present",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-N0nOq",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-CustomComponent-e7Nca{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-e7Ncaœ,œnameœ:œurl_presentœ,œoutput_typesœ:[œDataœ]}-ParseData-N0nOq{œfieldNameœ:œdataœ,œidœ:œParseData-N0nOqœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-e7Nca",
        "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-e7Ncaœ,œnameœ:œurl_presentœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-N0nOq",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-N0nOqœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-e7Nca",
            "name": "url_present",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "ParseData-8bP1x",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "reactflow__edge-CustomComponent-e7Nca{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-e7Ncaœ,œnameœ:œurl_presentœ,œoutput_typesœ:[œDataœ]}-ParseData-8bP1x{œfieldNameœ:œdataœ,œidœ:œParseData-8bP1xœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "CustomComponent-e7Nca",
        "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-e7Ncaœ,œnameœ:œurl_presentœ,œoutput_typesœ:[œDataœ]}",
        "target": "ParseData-8bP1x",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œParseData-8bP1xœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-8ShCt",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "user_query",
            "id": "CustomComponent-qUYAm",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "reactflow__edge-ParseData-8ShCt{œdataTypeœ:œParseDataœ,œidœ:œParseData-8ShCtœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-qUYAm{œfieldNameœ:œuser_queryœ,œidœ:œCustomComponent-qUYAmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-8ShCt",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-8ShCtœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-qUYAm",
        "targetHandle": "{œfieldNameœ:œuser_queryœ,œidœ:œCustomComponent-qUYAmœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-ajc6r",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-yoJ5n",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__OpenAIModel-ajc6r{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-ajc6rœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-yoJ5n{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-yoJ5nœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "OpenAIModel-ajc6r",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-ajc6rœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-yoJ5n",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-yoJ5nœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-CaGwo",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "OpenAIModel-ajc6r",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt-CaGwo{œdataTypeœ:œPromptœ,œidœ:œPrompt-CaGwoœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-ajc6r{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-ajc6rœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-CaGwo",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-CaGwoœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-ajc6r",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-ajc6rœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-RW53y",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-ajc6r",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParseData-RW53y{œdataTypeœ:œParseDataœ,œidœ:œParseData-RW53yœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-ajc6r{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-ajc6rœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-RW53y",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-RW53yœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-ajc6r",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-ajc6rœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-HOKWH",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-Q0tph",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__OpenAIModel-HOKWH{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-HOKWHœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-Q0tph{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-Q0tphœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "OpenAIModel-HOKWH",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-HOKWHœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-Q0tph",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-Q0tphœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-PqYbG",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "mip_list",
            "id": "Prompt-1pnVb",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParseData-PqYbG{œdataTypeœ:œParseDataœ,œidœ:œParseData-PqYbGœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-1pnVb{œfieldNameœ:œmip_listœ,œidœ:œPrompt-1pnVbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-PqYbG",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-PqYbGœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-1pnVb",
        "targetHandle": "{œfieldNameœ:œmip_listœ,œidœ:œPrompt-1pnVbœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-svP8u",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-7TzLL",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__OpenAIModel-svP8u{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-svP8uœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-7TzLL{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-7TzLLœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "OpenAIModel-svP8u",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-svP8uœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-7TzLL",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-7TzLLœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "variable_matcher",
            "id": "variable_matcher-GNxID",
            "name": "tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "Agent-y4GVw",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__variable_matcher-GNxID{œdataTypeœ:œvariable_matcherœ,œidœ:œvariable_matcher-GNxIDœ,œnameœ:œtoolœ,œoutput_typesœ:[œToolœ]}-Agent-y4GVw{œfieldNameœ:œtoolsœ,œidœ:œAgent-y4GVwœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "variable_matcher-GNxID",
        "sourceHandle": "{œdataTypeœ:œvariable_matcherœ,œidœ:œvariable_matcher-GNxIDœ,œnameœ:œtoolœ,œoutput_typesœ:[œToolœ]}",
        "target": "Agent-y4GVw",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œAgent-y4GVwœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Agent",
            "id": "Agent-y4GVw",
            "name": "response",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-rhTKs",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__Agent-y4GVw{œdataTypeœ:œAgentœ,œidœ:œAgent-y4GVwœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-rhTKs{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-rhTKsœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "Agent-y4GVw",
        "sourceHandle": "{œdataTypeœ:œAgentœ,œidœ:œAgent-y4GVwœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-rhTKs",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-rhTKsœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-93N1M",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "EXPERIMENT_LIST",
            "id": "Prompt-Kxye7",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParseData-93N1M{œdataTypeœ:œParseDataœ,œidœ:œParseData-93N1Mœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-Kxye7{œfieldNameœ:œEXPERIMENT_LISTœ,œidœ:œPrompt-Kxye7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-93N1M",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-93N1Mœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-Kxye7",
        "targetHandle": "{œfieldNameœ:œEXPERIMENT_LISTœ,œidœ:œPrompt-Kxye7œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-bRtf6",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-1ZFPQ",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__OpenAIModel-bRtf6{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-bRtf6œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-1ZFPQ{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-1ZFPQœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "OpenAIModel-bRtf6",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-bRtf6œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-1ZFPQ",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-1ZFPQœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-if9V0",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-KKC4E",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__OpenAIModel-if9V0{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-if9V0œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-KKC4E{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-KKC4Eœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "OpenAIModel-if9V0",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-if9V0œ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-KKC4E",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-KKC4Eœ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CurrentDateComponent",
            "id": "CurrentDateComponent-aEEHi",
            "name": "current_date",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "current_date",
            "id": "Prompt-8LuT6",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__CurrentDateComponent-aEEHi{œdataTypeœ:œCurrentDateComponentœ,œidœ:œCurrentDateComponent-aEEHiœ,œnameœ:œcurrent_dateœ,œoutput_typesœ:[œMessageœ]}-Prompt-8LuT6{œfieldNameœ:œcurrent_dateœ,œidœ:œPrompt-8LuT6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "CurrentDateComponent-aEEHi",
        "sourceHandle": "{œdataTypeœ:œCurrentDateComponentœ,œidœ:œCurrentDateComponent-aEEHiœ,œnameœ:œcurrent_dateœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-8LuT6",
        "targetHandle": "{œfieldNameœ:œcurrent_dateœ,œidœ:œPrompt-8LuT6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-N0nOq",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "search_config",
            "id": "Prompt-xcvV3",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParseData-N0nOq{œdataTypeœ:œParseDataœ,œidœ:œParseData-N0nOqœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt-xcvV3{œfieldNameœ:œsearch_configœ,œidœ:œPrompt-xcvV3œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-N0nOq",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-N0nOqœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt-xcvV3",
        "targetHandle": "{œfieldNameœ:œsearch_configœ,œidœ:œPrompt-xcvV3œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "OpenAIModel",
            "id": "OpenAIModel-YQJsh",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ChatOutput-OIba3",
            "inputTypes": [
              "Data",
              "DataFrame",
              "Message"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__OpenAIModel-YQJsh{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-YQJshœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-OIba3{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-OIba3œ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "OpenAIModel-YQJsh",
        "sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-YQJshœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ChatOutput-OIba3",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-OIba3œ,œinputTypesœ:[œDataœ,œDataFrameœ,œMessageœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-8LuT6",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "OpenAIModel-if9V0",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt-8LuT6{œdataTypeœ:œPromptœ,œidœ:œPrompt-8LuT6œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-if9V0{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-if9V0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-8LuT6",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-8LuT6œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-if9V0",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-if9V0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-zCUQk",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "OpenAIModel-bRtf6",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt-zCUQk{œdataTypeœ:œPromptœ,œidœ:œPrompt-zCUQkœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-bRtf6{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-bRtf6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-zCUQk",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-zCUQkœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-bRtf6",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-bRtf6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-8ShCt",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "Agent-y4GVw",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParseData-8ShCt{œdataTypeœ:œParseDataœ,œidœ:œParseData-8ShCtœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Agent-y4GVw{œfieldNameœ:œinput_valueœ,œidœ:œAgent-y4GVwœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-8ShCt",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-8ShCtœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Agent-y4GVw",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œAgent-y4GVwœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-Kxye7",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "OpenAIModel-svP8u",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt-Kxye7{œdataTypeœ:œPromptœ,œidœ:œPrompt-Kxye7œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-svP8u{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-svP8uœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-Kxye7",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-Kxye7œ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-svP8u",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-svP8uœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-8ShCt",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-svP8u",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParseData-8ShCt{œdataTypeœ:œParseDataœ,œidœ:œParseData-8ShCtœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-svP8u{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-svP8uœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-8ShCt",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-8ShCtœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-svP8u",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-svP8uœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt",
            "id": "Prompt-1pnVb",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "system_message",
            "id": "OpenAIModel-HOKWH",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt-1pnVb{œdataTypeœ:œPromptœ,œidœ:œPrompt-1pnVbœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-HOKWH{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-HOKWHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt-1pnVb",
        "sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-1pnVbœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-HOKWH",
        "targetHandle": "{œfieldNameœ:œsystem_messageœ,œidœ:œOpenAIModel-HOKWHœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-8ShCt",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-if9V0",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParseData-8ShCt{œdataTypeœ:œParseDataœ,œidœ:œParseData-8ShCtœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-if9V0{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-if9V0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-8ShCt",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-8ShCtœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-if9V0",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-if9V0œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ParseData",
            "id": "ParseData-8ShCt",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "OpenAIModel-bRtf6",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ParseData-8ShCt{œdataTypeœ:œParseDataœ,œidœ:œParseData-8ShCtœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-OpenAIModel-bRtf6{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-bRtf6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ParseData-8ShCt",
        "sourceHandle": "{œdataTypeœ:œParseDataœ,œidœ:œParseData-8ShCtœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "OpenAIModel-bRtf6",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œOpenAIModel-bRtf6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "description": "Get chat inputs from the Playground.",
          "display_name": "Chat Input",
          "id": "ChatInput-KYwsa",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "message_response",
                "name": "message",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n            temp_file=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        background_color = self.background_color\n        text_color = self.text_color\n        icon = self.chat_icon\n\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\n                \"background_color\": background_color,\n                \"text_color\": text_color,\n                \"icon\": icon,\n            },\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "_input_type": "FileInput",
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "list_add_label": "Add More",
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "temp_file": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "What fire weather indices can be calculated with CMIP6 output? What will their conditions be in 2100?\n\n\n"
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "ChatInput"
        },
        "dragging": false,
        "height": 231,
        "id": "ChatInput-KYwsa",
        "measured": {
          "height": 231,
          "width": 320
        },
        "position": {
          "x": 235.91722282440833,
          "y": -1030.1822612321982
        },
        "positionAbsolute": {
          "x": 457.9076021166384,
          "y": -1034.53501376734
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "CMIP6DatasetProcessorComponent-LKKLu",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Process a CSV file containing CMIP6 dataset information into a usable DataFrame.",
            "display_name": "CMIP6 Dataset Processor",
            "documentation": "",
            "edited": true,
            "field_order": [
              "csv_file",
              "csv_path"
            ],
            "frozen": false,
            "icon": "table",
            "lf_version": "1.4.1",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Processed DataFrame",
                "hidden": false,
                "method": "process_csv",
                "name": "processed_df",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Unique MIPs",
                "hidden": false,
                "method": "get_unique_mips",
                "name": "unique_mips",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Unique Experiments",
                "hidden": false,
                "method": "get_unique_experiments",
                "name": "unique_experiments",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import pandas as pd\r\nimport numpy as np\r\nfrom pathlib import Path\r\nfrom langflow.custom import Component\r\nfrom langflow.io import FileInput, MessageTextInput, Output\r\nfrom langflow.schema.data import Data\r\n\r\nclass CMIP6DatasetProcessorComponent(Component):\r\n    display_name = \"CMIP6 Dataset Processor\"\r\n    description = \"Process a CSV file containing CMIP6 dataset information into a usable DataFrame.\"\r\n    icon = \"table\"\r\n    \r\n    inputs = [\r\n        FileInput(\r\n            name=\"csv_file\",\r\n            display_name=\"CSV File\",\r\n            file_types=[\"csv\"],\r\n            info=\"Upload the CSV file containing CMIP6 dataset information.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"csv_path\",\r\n            display_name=\"CSV File Path\",\r\n            info=\"Provide the path to the CSV file as pure text\",\r\n        ),\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(display_name=\"Processed DataFrame\", name=\"processed_df\", method=\"process_csv\"),\r\n        Output(display_name=\"Unique MIPs\", name=\"unique_mips\", method=\"get_unique_mips\"),\r\n        Output(display_name=\"Unique Experiments\", name=\"unique_experiments\", method=\"get_unique_experiments\"),\r\n    ]\r\n\r\n    def _process_dataframe(self):\r\n        \"\"\"Helper method to process the dataframe and cache it for multiple outputs\"\"\"\r\n        if not hasattr(self, '_cached_df'):\r\n            if sum(bool(field) for field in [self.csv_file, self.csv_path]) != 1:\r\n                raise ValueError(\"Please provide exactly one of: CSV file or file path.\")\r\n            \r\n            try:\r\n                # Read the CSV file based on input type\r\n                if self.csv_file:\r\n                    df = pd.read_csv(self.csv_file)\r\n                else:\r\n                    if not Path(self.csv_path).exists():\r\n                        raise FileNotFoundError(f\"File not found: {self.csv_path}\")\r\n                    df = pd.read_csv(self.csv_path)\r\n                \r\n                # Process the DataFrame as before\r\n                df['collection'] = 'giss_cmip6'\r\n                df['org'] = 'NASA-GISS'\r\n                \r\n                # Select and rename columns\r\n                df = df[['collection', 'MIP', 'org', 'model', 'experiment', 'variant', \r\n                         'tableID', 'variable', 'grid', 'version', 'start_YM', 'end_YM', 'filename']]\r\n                df.columns = ['collection', 'MIP', 'org', 'model', 'experiment', 'variant', \r\n                             'temporal resolution', 'variable', 'grid', 'version', 'start year', 'end year', 'filename']\r\n                \r\n                # Rest of the processing...\r\n                df = df.astype(str)\r\n                \r\n                def generate_url(x):\r\n                    cols = '/'.join([val for val in x])\r\n                    return 'https://portal.nccs.nasa.gov/datashare/' + cols\r\n                \r\n                url_col_names = df.columns[:-3].to_list() + ['filename']\r\n                urldf = df[url_col_names]\r\n                df['URL'] = urldf.apply(lambda x: generate_url(x), axis=1)\r\n                \r\n                def safe_year_convert(x):\r\n                    try:\r\n                        return int(x[:4])\r\n                    except ValueError:\r\n                        return np.nan\r\n                \r\n                df['start year'] = df['start year'].apply(safe_year_convert)\r\n                df['end year'] = df['end year'].apply(safe_year_convert)\r\n                \r\n                df = df.sort_values(df.columns.to_list(), ascending=True).drop_duplicates(\r\n                    subset=set(df.columns.to_list()) - set(['version', 'filename', 'URL']),\r\n                    ignore_index=True, keep='last')\r\n                \r\n                def clean_resolution(reso):\r\n                    resos = ['hr', 'day', 'mon']\r\n                    for q in resos:\r\n                        if q in reso:\r\n                            return q\r\n                    return 'NA'\r\n                \r\n                df['temporal resolution'] = df.apply(lambda x: clean_resolution(x['temporal resolution']), axis=1)\r\n                \r\n                self._cached_df = df\r\n                \r\n            except Exception as e:\r\n                raise ValueError(f\"Error processing CSV: {str(e)}\")\r\n        \r\n        return self._cached_df\r\n\r\n    def process_csv(self) -> Data:\r\n        try:\r\n            df = self._process_dataframe()\r\n            self.status = f\"DataFrame processed successfully. Shape: {df.shape}\"\r\n            return Data(data={\"df\": df})\r\n        except Exception as e:\r\n            error_message = f\"Error processing CSV: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})\r\n\r\n    def get_unique_mips(self) -> list[Data]:\r\n        \"\"\"Return a list of Data objects containing unique MIP values\"\"\"\r\n        try:\r\n            df = self._process_dataframe()\r\n            unique_mips = df['MIP'].unique().tolist()\r\n            return [Data(data={\"MIP\": mip}) for mip in sorted(unique_mips)]\r\n        except Exception as e:\r\n            error_message = f\"Error getting unique MIPs: {str(e)}\"\r\n            self.status = error_message\r\n            return [Data(data={\"error\": error_message})]\r\n\r\n    def get_unique_experiments(self) -> list[Data]:\r\n        \"\"\"Return a list of Data objects containing unique experiment values\"\"\"\r\n        try:\r\n            df = self._process_dataframe()\r\n            unique_experiments = df['experiment'].unique().tolist()\r\n            return [Data(data={\"experiment\": exp}) for exp in sorted(unique_experiments)]\r\n        except Exception as e:\r\n            error_message = f\"Error getting unique experiments: {str(e)}\"\r\n            self.status = error_message\r\n            return [Data(data={\"error\": error_message})]"
              },
              "csv_file": {
                "_input_type": "FileInput",
                "advanced": false,
                "display_name": "CSV File",
                "dynamic": false,
                "fileTypes": [
                  "csv"
                ],
                "file_path": "7a67f6b4-7f06-44c2-bac9-af8d8a0c053a/49344e85-cb8a-4c2f-8b93-9baf06c9f1d0.csv",
                "info": "Upload the CSV file containing CMIP6 dataset information.",
                "list": false,
                "load_from_db": false,
                "name": "csv_file",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "csv_path": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "CSV File Path",
                "dynamic": false,
                "info": "Provide the path to the CSV file as pure text",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "csv_path",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            }
          },
          "type": "CMIP6DatasetProcessorComponent"
        },
        "dragging": false,
        "height": 432,
        "id": "CMIP6DatasetProcessorComponent-LKKLu",
        "measured": {
          "height": 432,
          "width": 320
        },
        "position": {
          "x": 1872.5355247834764,
          "y": -2794.5015234631765
        },
        "positionAbsolute": {
          "x": 2135.035516520518,
          "y": -2749.5015248796835
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "CMIP6VariableProcessorFromZip-9CfEc",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Processes CMIP6 variable information JSON files from a zip file and generates embeddings.",
            "display_name": "CMIP6 Variable Processor (Zip)",
            "documentation": "",
            "edited": true,
            "field_order": [
              "zip_file",
              "zip_path",
              "dataset_info",
              "embeddings"
            ],
            "frozen": false,
            "icon": "file-zip",
            "lf_version": "1.4.1",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "CMIP6 Variable Info",
                "hidden": false,
                "method": "process_zip_file",
                "name": "variable_info",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import zipfile\r\nimport json\r\nimport pandas as pd\r\nimport numpy as np\r\nfrom pathlib import Path\r\nfrom langflow.custom import Component\r\nfrom langflow.io import FileInput, HandleInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass CMIP6VariableProcessorFromZip(Component):\r\n    display_name = \"CMIP6 Variable Processor (Zip)\"\r\n    description = \"Processes CMIP6 variable information JSON files from a zip file and generates embeddings.\"\r\n    icon = \"file-zip\"\r\n    \r\n    inputs = [\r\n        FileInput(\r\n            name=\"zip_file\",\r\n            display_name=\"Zip File\",\r\n            file_types=[\"zip\"],\r\n            info=\"Upload a zip file containing CMIP6 JSON files.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"zip_path\",\r\n            display_name=\"Zip File Path\",\r\n            info=\"Provide the path to the zip file as pure text\",\r\n        ),\r\n        HandleInput(\r\n            name=\"dataset_info\",\r\n            display_name=\"Dataset Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Processed CMIP6 dataset information for filtering variables.\",\r\n        ),\r\n        HandleInput(\r\n            name=\"embeddings\",\r\n            display_name=\"Embeddings\",\r\n            input_types=[\"Embeddings\"],\r\n            info=\"Embeddings component for generating embeddings.\",\r\n        ),\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(display_name=\"CMIP6 Variable Info\", name=\"variable_info\", method=\"process_zip_file\"),\r\n    ]\r\n\r\n    def process_zip_file(self) -> Data:\r\n        # Validate inputs\r\n        if sum(bool(field) for field in [self.zip_file, self.zip_path]) != 1:\r\n            raise ValueError(\"Please provide exactly one of: zip file or file path.\")\r\n\r\n        try:\r\n            # Get the correct file path\r\n            if self.zip_file:\r\n                file_path = self.resolve_path(self.zip_file)\r\n            else:\r\n                file_path = self.zip_path\r\n                if not Path(file_path).exists():\r\n                    raise FileNotFoundError(f\"File not found: {file_path}\")\r\n\r\n            # Process the zip file\r\n            jdfs = []\r\n            with zipfile.ZipFile(file_path, 'r') as zip_ref:\r\n                for file_name in zip_ref.namelist():\r\n                    if file_name.endswith('.json') and 'Tables' in file_name:\r\n                        self.log(f\"Processing file: {file_name}\")\r\n                        with zip_ref.open(file_name) as file:\r\n                            content = file.read()\r\n                            d = json.loads(content.decode('utf-8'))\r\n                            try:\r\n                                jdf = pd.DataFrame.from_dict(d['variable_entry'], orient='index')\r\n                                jdf['temporal resolution'] = file_name.split('_')[-1].split('.')[0]\r\n                                jdfs.append(jdf)\r\n                            except KeyError:\r\n                                self.log(f\"Skipping {file_name} due to formatting issue\")\r\n\r\n            if not jdfs:\r\n                raise ValueError(\"No valid JSON files were found in the zip file\")\r\n\r\n            # Create the combined DataFrame\r\n            varsdf = pd.concat(jdfs)\r\n            varsdf.rename(columns={'out_name': 'variable'}, inplace=True)\r\n            varsdf = varsdf.loc[:, ['long_name', 'comment', 'variable']]\r\n            varsdf.drop_duplicates(inplace=True)\r\n            \r\n            # Create extended comment\r\n            varsdf['extended_comment'] = varsdf.apply(\r\n                lambda x: f\"{x['long_name']} ({x['variable']}): {x['comment']}\", \r\n                axis=1\r\n            )\r\n            \r\n            # Filter variables based on the dataset_info\r\n            if isinstance(self.dataset_info, Data) and 'df' in self.dataset_info.data:\r\n                df = pd.DataFrame(self.dataset_info.data['df'])\r\n                varsdf = varsdf[varsdf['variable'].isin(df['variable'].unique())]\r\n            else:\r\n                self.log(\"Warning: No dataset info provided for filtering variables.\")\r\n\r\n            # Generate embeddings\r\n            varsdf.loc[varsdf['extended_comment'].isna(), 'extended_comment'] = ''\r\n            varsdf['embeds'] = list(np.asarray(\r\n                self.embeddings.embed_documents(varsdf['extended_comment'].tolist())\r\n            ))\r\n\r\n            self.status = f\"Variable info processed and embeddings generated successfully. Shape: {varsdf.shape}\"\r\n            return Data(data={\"variable_info\": varsdf})\r\n\r\n        except Exception as e:\r\n            error_message = f\"Error processing zip file or generating embeddings: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})"
              },
              "dataset_info": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Dataset Info",
                "dynamic": false,
                "info": "Processed CMIP6 dataset information for filtering variables.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "name": "dataset_info",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "embeddings": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Embeddings",
                "dynamic": false,
                "info": "Embeddings component for generating embeddings.",
                "input_types": [
                  "Embeddings"
                ],
                "list": false,
                "name": "embeddings",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "zip_file": {
                "_input_type": "FileInput",
                "advanced": false,
                "display_name": "Zip File",
                "dynamic": false,
                "fileTypes": [
                  "zip"
                ],
                "file_path": "7a67f6b4-7f06-44c2-bac9-af8d8a0c053a/cad080f1-6361-41e1-b2ba-7e7f0d175d99.zip",
                "info": "Upload a zip file containing CMIP6 JSON files.",
                "list": false,
                "load_from_db": false,
                "name": "zip_file",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "zip_path": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Zip File Path",
                "dynamic": false,
                "info": "Provide the path to the zip file as pure text",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "zip_path",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            }
          },
          "type": "CMIP6VariableProcessorFromZip"
        },
        "dragging": false,
        "height": 366,
        "id": "CMIP6VariableProcessorFromZip-9CfEc",
        "measured": {
          "height": 366,
          "width": 320
        },
        "position": {
          "x": 3249.743385806226,
          "y": -2877.5011036218298
        },
        "positionAbsolute": {
          "x": 3249.743385806226,
          "y": -2877.5011036218298
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "variable_matcher-tAMdg",
          "node": {
            "base_classes": [
              "Data",
              "Tool"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Filters CMIP6 variables based on exact variable name matches.",
            "display_name": "CMIP6 Variable Matcher",
            "documentation": "",
            "edited": true,
            "field_order": [
              "variable_info",
              "variable_name"
            ],
            "frozen": false,
            "icon": "match",
            "lf_version": "1.4.1",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Matched Variables",
                "hidden": false,
                "method": "match_variables",
                "name": "matched_variables",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Tool",
                "hidden": true,
                "method": "build_tool",
                "name": "tool",
                "selected": "Tool",
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import List, Dict, Any\r\nfrom pydantic import BaseModel, Field\r\nimport pandas as pd\r\n\r\nfrom langflow.base.langchain_utilities.model import LCToolComponent\r\nfrom langflow.io import HandleInput, MessageTextInput, IntInput, Output\r\nfrom langflow.schema import Data\r\nfrom langflow.field_typing import Tool\r\nfrom langchain.tools import StructuredTool\r\n\r\nclass VariableMatcherToolComponent(LCToolComponent):\r\n    display_name = \"CMIP6 Variable Matcher\"\r\n    description = \"Filters CMIP6 variables based on exact variable name matches.\"\r\n    icon = \"match\"\r\n    name = \"variable_matcher\"\r\n    \r\n    inputs = [\r\n        HandleInput(\r\n            name=\"variable_info\",\r\n            display_name=\"Variable Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Processed CMIP6 variable information from the previous component.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"variable_name\",\r\n            display_name=\"Variable Name\",\r\n            info=\"The exact variable name to filter for (e.g., 'tas').\",\r\n        ),\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(display_name=\"Matched Variables\", name=\"matched_variables\", method=\"match_variables\"),\r\n        Output(display_name=\"Tool\", name=\"tool\", method=\"build_tool\"),\r\n    ]\r\n\r\n    class VariableMatcherSchema(BaseModel):\r\n        variable_name: str = Field(\r\n            ..., \r\n            description=\"The exact variable name to filter for (e.g., 'tas')\"\r\n        )\r\n\r\n    def _process_matches(self, variable_name: str) -> List[Dict[str, Any]]:\r\n        \"\"\"Internal method to filter variables by exact name match\"\"\"\r\n        if not isinstance(self.variable_info, Data) or 'variable_info' not in self.variable_info.data:\r\n            raise ValueError(\"Invalid variable info input. Expected Data object with 'variable_info' key.\")\r\n        \r\n        varsdf = self.variable_info.data['variable_info']\r\n        \r\n        try:\r\n            # Filter for exact matches\r\n            filtered_df = varsdf[varsdf['variable'].str.lower() == variable_name.lower()]\r\n            \r\n            if filtered_df.empty:\r\n                return [{\"message\": f\"No matches found for variable '{variable_name}'\"}]\r\n            \r\n            # Convert results to list of dictionaries\r\n            results = [\r\n                {\r\n                    'variable': row['variable'],\r\n                    'long_name': row['long_name'],\r\n                    'comment': row['comment'],\r\n                }\r\n                for _, row in filtered_df.iterrows()\r\n            ]\r\n            \r\n            return results\r\n\r\n        except Exception as e:\r\n            return [{\"error\": f\"Error filtering variables: {str(e)}\"}]\r\n\r\n    def match_variables(self) -> List[Data]:\r\n        \"\"\"Method for component output\"\"\"\r\n        try:\r\n            results = self._process_matches(self.variable_name)\r\n            data_list = [Data(data=result) for result in results]\r\n            self.status = data_list\r\n            return data_list\r\n            \r\n        except Exception as e:\r\n            error_message = f\"Error matching variables: {str(e)}\"\r\n            self.status = error_message\r\n            return [Data(data={\"error\": error_message})]\r\n\r\n    def build_tool(self) -> Tool:\r\n        \"\"\"Build and return the tool\"\"\"\r\n        return StructuredTool.from_function(\r\n            name=\"variable_matcher\",\r\n            description=\"Filter CMIP6 variables by exact variable name match. \"\r\n                      \"Input should be the exact variable name (e.g., 'tas').\",\r\n            func=self._tool_function,\r\n            args_schema=self.VariableMatcherSchema,\r\n        )\r\n\r\n    def _tool_function(self, variable_name: str) -> List[Dict[str, Any]]:\r\n        \"\"\"Function to be called by the tool\"\"\"\r\n        try:\r\n            return self._process_matches(variable_name)\r\n        except Exception as e:\r\n            return [{\"error\": f\"Error matching variables: {str(e)}\"}]"
              },
              "variable_info": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Variable Info",
                "dynamic": false,
                "info": "Processed CMIP6 variable information from the previous component.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "name": "variable_info",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "variable_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Variable Name",
                "dynamic": false,
                "info": "The exact variable name to filter for (e.g., 'tas').",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "variable_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            }
          },
          "type": "variable_matcher"
        },
        "dragging": false,
        "height": 300,
        "id": "variable_matcher-tAMdg",
        "measured": {
          "height": 300,
          "width": 320
        },
        "position": {
          "x": 5643.319471179704,
          "y": -1459.7994934350872
        },
        "positionAbsolute": {
          "x": 5643.319471179704,
          "y": -1459.7994934350872
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Generate embeddings using OpenAI models.",
          "display_name": "OpenAI Embeddings",
          "id": "OpenAIEmbeddings-XvpND",
          "node": {
            "base_classes": [
              "Embeddings"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate embeddings using OpenAI models.",
            "display_name": "OpenAI Embeddings",
            "documentation": "",
            "edited": false,
            "field_order": [
              "default_headers",
              "default_query",
              "chunk_size",
              "client",
              "deployment",
              "embedding_ctx_length",
              "max_retries",
              "model",
              "model_kwargs",
              "openai_api_key",
              "openai_api_base",
              "openai_api_type",
              "openai_api_version",
              "openai_organization",
              "openai_proxy",
              "request_timeout",
              "show_progress_bar",
              "skip_empty",
              "tiktoken_model_name",
              "tiktoken_enable",
              "dimensions"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Embeddings",
                "hidden": false,
                "method": "build_embeddings",
                "name": "embeddings",
                "options": null,
                "required_inputs": [
                  "openai_api_key"
                ],
                "selected": "Embeddings",
                "tool_mode": true,
                "types": [
                  "Embeddings"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "chunk_size": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Chunk Size",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "chunk_size",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1000
              },
              "client": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Client",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "client",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_openai import OpenAIEmbeddings\n\nfrom langflow.base.embeddings.model import LCEmbeddingsModel\nfrom langflow.base.models.openai_constants import OPENAI_EMBEDDING_MODEL_NAMES\nfrom langflow.field_typing import Embeddings\nfrom langflow.io import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, MessageTextInput, SecretStrInput\n\n\nclass OpenAIEmbeddingsComponent(LCEmbeddingsModel):\n    display_name = \"OpenAI Embeddings\"\n    description = \"Generate embeddings using OpenAI models.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIEmbeddings\"\n\n    inputs = [\n        DictInput(\n            name=\"default_headers\",\n            display_name=\"Default Headers\",\n            advanced=True,\n            info=\"Default headers to use for the API request.\",\n        ),\n        DictInput(\n            name=\"default_query\",\n            display_name=\"Default Query\",\n            advanced=True,\n            info=\"Default query parameters to use for the API request.\",\n        ),\n        IntInput(name=\"chunk_size\", display_name=\"Chunk Size\", advanced=True, value=1000),\n        MessageTextInput(name=\"client\", display_name=\"Client\", advanced=True),\n        MessageTextInput(name=\"deployment\", display_name=\"Deployment\", advanced=True),\n        IntInput(name=\"embedding_ctx_length\", display_name=\"Embedding Context Length\", advanced=True, value=1536),\n        IntInput(name=\"max_retries\", display_name=\"Max Retries\", value=3, advanced=True),\n        DropdownInput(\n            name=\"model\",\n            display_name=\"Model\",\n            advanced=False,\n            options=OPENAI_EMBEDDING_MODEL_NAMES,\n            value=\"text-embedding-3-small\",\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        SecretStrInput(name=\"openai_api_key\", display_name=\"OpenAI API Key\", value=\"OPENAI_API_KEY\", required=True),\n        MessageTextInput(name=\"openai_api_base\", display_name=\"OpenAI API Base\", advanced=True),\n        MessageTextInput(name=\"openai_api_type\", display_name=\"OpenAI API Type\", advanced=True),\n        MessageTextInput(name=\"openai_api_version\", display_name=\"OpenAI API Version\", advanced=True),\n        MessageTextInput(\n            name=\"openai_organization\",\n            display_name=\"OpenAI Organization\",\n            advanced=True,\n        ),\n        MessageTextInput(name=\"openai_proxy\", display_name=\"OpenAI Proxy\", advanced=True),\n        FloatInput(name=\"request_timeout\", display_name=\"Request Timeout\", advanced=True),\n        BoolInput(name=\"show_progress_bar\", display_name=\"Show Progress Bar\", advanced=True),\n        BoolInput(name=\"skip_empty\", display_name=\"Skip Empty\", advanced=True),\n        MessageTextInput(\n            name=\"tiktoken_model_name\",\n            display_name=\"TikToken Model Name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tiktoken_enable\",\n            display_name=\"TikToken Enable\",\n            advanced=True,\n            value=True,\n            info=\"If False, you must have transformers installed.\",\n        ),\n        IntInput(\n            name=\"dimensions\",\n            display_name=\"Dimensions\",\n            info=\"The number of dimensions the resulting output embeddings should have. \"\n            \"Only supported by certain models.\",\n            advanced=True,\n        ),\n    ]\n\n    def build_embeddings(self) -> Embeddings:\n        return OpenAIEmbeddings(\n            client=self.client or None,\n            model=self.model,\n            dimensions=self.dimensions or None,\n            deployment=self.deployment or None,\n            api_version=self.openai_api_version or None,\n            base_url=self.openai_api_base or None,\n            openai_api_type=self.openai_api_type or None,\n            openai_proxy=self.openai_proxy or None,\n            embedding_ctx_length=self.embedding_ctx_length,\n            api_key=self.openai_api_key or None,\n            organization=self.openai_organization or None,\n            allowed_special=\"all\",\n            disallowed_special=\"all\",\n            chunk_size=self.chunk_size,\n            max_retries=self.max_retries,\n            timeout=self.request_timeout or None,\n            tiktoken_enabled=self.tiktoken_enable,\n            tiktoken_model_name=self.tiktoken_model_name or None,\n            show_progress_bar=self.show_progress_bar,\n            model_kwargs=self.model_kwargs,\n            skip_empty=self.skip_empty,\n            default_headers=self.default_headers or None,\n            default_query=self.default_query or None,\n        )\n"
              },
              "default_headers": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Default Headers",
                "dynamic": false,
                "info": "Default headers to use for the API request.",
                "list": false,
                "list_add_label": "Add More",
                "name": "default_headers",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "default_query": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Default Query",
                "dynamic": false,
                "info": "Default query parameters to use for the API request.",
                "list": false,
                "list_add_label": "Add More",
                "name": "default_query",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "deployment": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Deployment",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "deployment",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "dimensions": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Dimensions",
                "dynamic": false,
                "info": "The number of dimensions the resulting output embeddings should have. Only supported by certain models.",
                "list": false,
                "list_add_label": "Add More",
                "name": "dimensions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "embedding_ctx_length": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Embedding Context Length",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "embedding_ctx_length",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1536
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 3
              },
              "model": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model",
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "name": "model",
                "options": [
                  "text-embedding-3-small",
                  "text-embedding-3-large",
                  "text-embedding-ada-002"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "text-embedding-3-large"
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "openai_api_base": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "",
                "input_types": [],
                "load_from_db": false,
                "name": "openai_api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "openai_api_type": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI API Type",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_type",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_api_version": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI API Version",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_version",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_organization": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI Organization",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_organization",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "openai_proxy": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "OpenAI Proxy",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_proxy",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "request_timeout": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Request Timeout",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "request_timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": ""
              },
              "show_progress_bar": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Show Progress Bar",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "show_progress_bar",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "skip_empty": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Skip Empty",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "skip_empty",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "tiktoken_enable": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "TikToken Enable",
                "dynamic": false,
                "info": "If False, you must have transformers installed.",
                "list": false,
                "list_add_label": "Add More",
                "name": "tiktoken_enable",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "tiktoken_model_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "TikToken Model Name",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tiktoken_model_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "OpenAIEmbeddings"
        },
        "dragging": false,
        "height": 318,
        "id": "OpenAIEmbeddings-XvpND",
        "measured": {
          "height": 318,
          "width": 320
        },
        "position": {
          "x": 2888.1600442024533,
          "y": -2819.285701514933
        },
        "positionAbsolute": {
          "x": 2888.1600442024533,
          "y": -2819.285701514933
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "TemporalResolutionFilterComponent-ZtcSN",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Filters CMIP6 datasets based on temporal resolution and matched variables.",
            "display_name": "Temporal Resolution Filter",
            "documentation": "",
            "edited": true,
            "field_order": [
              "dataset_info",
              "matched_variables",
              "resolution"
            ],
            "frozen": false,
            "icon": "filter",
            "lf_version": "1.4.1",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Filtered Datasets",
                "hidden": false,
                "method": "filter_datasets",
                "name": "filtered_datasets",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\r\nfrom langflow.io import HandleInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass TemporalResolutionFilterComponent(Component):\r\n    display_name = \"Temporal Resolution Filter\"\r\n    description = \"Filters CMIP6 datasets based on temporal resolution and matched variables.\"\r\n    icon = \"filter\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"dataset_info\",\r\n            display_name=\"Dataset Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Processed CMIP6 dataset information from the CMIP6 Dataset Processor.\",\r\n        ),\r\n        HandleInput(\r\n            name=\"matched_variables\",\r\n            display_name=\"Matched Variables\",\r\n            input_types=[\"Data\"],\r\n            info=\"Matched variables from the CMIP6 Variable Matcher.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"resolution\",\r\n            display_name=\"Temporal Resolution\",\r\n            info=\"Enter the desired temporal resolution (e.g., hr, day, mon, fx).\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Filtered Datasets\", name=\"filtered_datasets\", method=\"filter_datasets\"),\r\n    ]\r\n\r\n    def filter_datasets(self) -> Data:\r\n        if not isinstance(self.dataset_info, Data) or 'df' not in self.dataset_info.data:\r\n            raise ValueError(\"Invalid dataset info input. Expected Data object with 'df' key.\")\r\n\r\n        if not isinstance(self.matched_variables, list) or not all(isinstance(x, Data) for x in self.matched_variables):\r\n            raise ValueError(\"Invalid matched variables input. Expected list of Data objects.\")\r\n\r\n        df = self.dataset_info.data['df']\r\n\r\n        if 'temporal resolution' not in df.columns or 'variable' not in df.columns:\r\n            raise ValueError(\"Expected 'temporal resolution' and 'variable' columns in dataset info DataFrame.\")\r\n\r\n        try:\r\n            resolution = self.resolution.strip().lower()\r\n            \r\n            # Get the list of matched variable names\r\n            matched_var_names = [v.data['variable'] for v in self.matched_variables if 'variable' in v.data]\r\n            \r\n            # Filter the dataset\r\n            filtered_df = df[\r\n                (df['temporal resolution'] == resolution) &\r\n                (df['variable'].isin(matched_var_names))\r\n            ]\r\n            \r\n            self.status = f\"Filtered {len(filtered_df)} datasets with {resolution} temporal resolution and matching variables.\"\r\n            return Data(data={\"filtered_df\": filtered_df})\r\n\r\n        except Exception as e:\r\n            error_message = f\"Error filtering datasets: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})"
              },
              "dataset_info": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Dataset Info",
                "dynamic": false,
                "info": "Processed CMIP6 dataset information from the CMIP6 Dataset Processor.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "name": "dataset_info",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "matched_variables": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Matched Variables",
                "dynamic": false,
                "info": "Matched variables from the CMIP6 Variable Matcher.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "name": "matched_variables",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "resolution": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Temporal Resolution",
                "dynamic": false,
                "info": "Enter the desired temporal resolution (e.g., hr, day, mon, fx).",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "resolution",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            }
          },
          "type": "TemporalResolutionFilterComponent"
        },
        "dragging": false,
        "height": 348,
        "id": "TemporalResolutionFilterComponent-ZtcSN",
        "measured": {
          "height": 348,
          "width": 320
        },
        "position": {
          "x": 6114.570741928117,
          "y": -1225.2071671185627
        },
        "positionAbsolute": {
          "x": 6114.570741928117,
          "y": -1225.2071671185627
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "YearRangeFilterComponent-o9DZU",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Filters CMIP6 datasets based on a specified year range.",
            "display_name": "Year Range Filter",
            "documentation": "",
            "edited": true,
            "field_order": [
              "dataset_info",
              "year_range"
            ],
            "frozen": false,
            "icon": "calendar",
            "lf_version": "1.4.1",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Filtered Datasets",
                "hidden": false,
                "method": "filter_datasets",
                "name": "filtered_datasets",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\r\nfrom langflow.io import HandleInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass YearRangeFilterComponent(Component):\r\n    display_name = \"Year Range Filter\"\r\n    description = \"Filters CMIP6 datasets based on a specified year range.\"\r\n    icon = \"calendar\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"dataset_info\",\r\n            display_name=\"Dataset Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Processed CMIP6 dataset information from the previous filter.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"year_range\",\r\n            display_name=\"Year Range\",\r\n            info=\"The year range for filtering (format: START-END, e.g., '1980-2014' or '1000-NA' or 'NA-2100').\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Filtered Datasets\", name=\"filtered_datasets\", method=\"filter_datasets\"),\r\n    ]\r\n\r\n    def parse_year_range(self, year_range: str):\r\n        start, end = year_range.split('-')\r\n        start = int(start) if start.lower() != 'na' else None\r\n        end = int(end) if end.lower() != 'na' else None\r\n        return start, end\r\n\r\n    def filter_datasets(self) -> Data:\r\n        if not isinstance(self.dataset_info, Data) or 'filtered_df' not in self.dataset_info.data:\r\n            raise ValueError(\"Invalid dataset info input. Expected Data object with 'filtered_df' key.\")\r\n\r\n        df = self.dataset_info.data['filtered_df']\r\n\r\n        if 'start year' not in df.columns or 'end year' not in df.columns:\r\n            raise ValueError(\"Expected 'start year' and 'end year' columns in dataset info DataFrame.\")\r\n\r\n        try:\r\n            start_year, end_year = self.parse_year_range(self.year_range.strip())\r\n            \r\n            if start_year is not None:\r\n                df = df[df['end year'] >= start_year]\r\n            if end_year is not None:\r\n                df = df[df['start year'] <= end_year]\r\n            \r\n            year_range_str = f\"{start_year if start_year else 'NA'}-{end_year if end_year else 'NA'}\"\r\n            self.status = f\"Filtered datasets within the year range {year_range_str}. {len(df)} datasets remain.\"\r\n            return Data(data={\"filtered_df\": df})\r\n\r\n        except ValueError:\r\n            error_message = \"Invalid year range input. Please enter a valid range (e.g., '1980-2014' or '1000-NA' or 'NA-2100').\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})\r\n        except Exception as e:\r\n            error_message = f\"Error filtering datasets: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})"
              },
              "dataset_info": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Dataset Info",
                "dynamic": false,
                "info": "Processed CMIP6 dataset information from the previous filter.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "name": "dataset_info",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "year_range": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Year Range",
                "dynamic": false,
                "info": "The year range for filtering (format: START-END, e.g., '1980-2014' or '1000-NA' or 'NA-2100').",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "year_range",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            }
          },
          "type": "YearRangeFilterComponent"
        },
        "dragging": false,
        "height": 300,
        "id": "YearRangeFilterComponent-o9DZU",
        "measured": {
          "height": 300,
          "width": 320
        },
        "position": {
          "x": 6572.064522169262,
          "y": -1009.1006848302384
        },
        "positionAbsolute": {
          "x": 6572.064522169262,
          "y": -1009.1006848302384
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "URLExtractorComponent-ijoej",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts URLs from filtered CMIP6 datasets.",
            "display_name": "URL Extractor",
            "documentation": "",
            "edited": true,
            "field_order": [
              "dataset_info",
              "max_urls"
            ],
            "frozen": false,
            "icon": "link",
            "lf_version": "1.4.1",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Extracted URLs",
                "hidden": false,
                "method": "extract_urls",
                "name": "extracted_urls",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\r\nfrom langflow.io import HandleInput, IntInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass URLExtractorComponent(Component):\r\n    display_name = \"URL Extractor\"\r\n    description = \"Extracts URLs from filtered CMIP6 datasets.\"\r\n    icon = \"link\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"dataset_info\",\r\n            display_name=\"Filtered Dataset Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Filtered CMIP6 dataset information from the previous filters.\",\r\n        ),\r\n        IntInput(\r\n            name=\"max_urls\",\r\n            display_name=\"Maximum URLs\",\r\n            info=\"Maximum number of URLs to extract (0 for all).\",\r\n            value=5,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Extracted URLs\", name=\"extracted_urls\", method=\"extract_urls\"),\r\n    ]\r\n\r\n    def extract_urls(self) -> Data:\r\n        if not isinstance(self.dataset_info, Data) or 'filtered_df' not in self.dataset_info.data:\r\n            raise ValueError(\"Invalid dataset info input. Expected Data object with 'filtered_df' key.\")\r\n\r\n        df = self.dataset_info.data['filtered_df']\r\n\r\n        if 'URL' not in df.columns:\r\n            raise ValueError(\"Expected 'URL' column in dataset info DataFrame.\")\r\n\r\n        try:\r\n            if self.max_urls > 0:\r\n                urls = df['URL'].head(self.max_urls).tolist()\r\n            else:\r\n                urls = df['URL'].tolist()\r\n\r\n            result = []\r\n            for i, url in enumerate(urls, 1):\r\n                result.append(Data(data={\r\n                    \"url\": url,\r\n                    \"index\": i,\r\n                    \"filename\": url.split('/')[-1]\r\n                }))\r\n\r\n            self.status = result\r\n            return result\r\n\r\n        except Exception as e:\r\n            error_message = f\"Error extracting URLs: {str(e)}\"\r\n            self.status = error_message\r\n            return [Data(data={\"error\": error_message})]"
              },
              "dataset_info": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Filtered Dataset Info",
                "dynamic": false,
                "info": "Filtered CMIP6 dataset information from the previous filters.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "name": "dataset_info",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "max_urls": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Maximum URLs",
                "dynamic": false,
                "info": "Maximum number of URLs to extract (0 for all).",
                "list": false,
                "load_from_db": false,
                "name": "max_urls",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              }
            }
          },
          "type": "URLExtractorComponent"
        },
        "dragging": false,
        "height": 279,
        "id": "URLExtractorComponent-ijoej",
        "measured": {
          "height": 279,
          "width": 320
        },
        "position": {
          "x": 6990.787869759375,
          "y": -749.5272132244486
        },
        "positionAbsolute": {
          "x": 6990.787869759375,
          "y": -749.5272132244486
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Date Range Prompt",
          "id": "Prompt-8LuT6",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "current_date"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "hidden": false,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "current_date": {
                "advanced": false,
                "display_name": "current_date",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "current_date",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "You are a climate scientist specializing in CMIP6 datasets.\n\nTask: Inspect the user’s CMIP6 query and decide whether it specifies or requires a time period. Reply with exactly one string in one of the following formats — and nothing else:\n\n• YYYY-YYYY if both start and end years are stated (e.g. 1960-1970)  \n• YYYY-NA  if only a start year is stated (e.g. 2100-NA)  \n• NA-YYYY  if only an end year is stated (e.g. NA-1900)  \n• NA-NA   if no years are stated or required  \n\nRules  \n1. Return only the year-range string; no extra words, punctuation, or line breaks.  \n2. Use four-digit years.  \n3. Ignore vague terms such as “historical” or “future” unless an explicit year appears.\n\nInputs  \nToday’s date: {current_date}  \nCMIP6 query: \n"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "Prompt"
        },
        "dragging": false,
        "height": 429,
        "id": "Prompt-8LuT6",
        "measured": {
          "height": 429,
          "width": 320
        },
        "position": {
          "x": 2958.8303696056846,
          "y": 756.253103250497
        },
        "positionAbsolute": {
          "x": 3264.4647752945025,
          "y": -123.01349579960996
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Generates text using OpenAI LLMs.",
          "display_name": "RangeSelector",
          "id": "OpenAIModel-if9V0",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "hidden": true,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": [
                  "api_key"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import (\n    OPENAI_MODEL_NAMES,\n    OPENAI_REASONING_MODEL_NAMES,\n)\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\nfrom langflow.logging import logger\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[1],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        parameters = {\n            \"api_key\": SecretStr(self.api_key).get_secret_value() if self.api_key else None,\n            \"model_name\": self.model_name,\n            \"max_tokens\": self.max_tokens or None,\n            \"model_kwargs\": self.model_kwargs or {},\n            \"base_url\": self.openai_api_base or \"https://api.openai.com/v1\",\n            \"seed\": self.seed,\n            \"max_retries\": self.max_retries,\n            \"timeout\": self.timeout,\n            \"temperature\": self.temperature if self.temperature is not None else 0.1,\n        }\n\n        logger.info(f\"Model name: {self.model_name}\")\n        if self.model_name in OPENAI_REASONING_MODEL_NAMES:\n            logger.info(\"Getting reasoning model parameters\")\n            parameters.pop(\"temperature\")\n            parameters.pop(\"seed\")\n        output = ChatOpenAI(**parameters)\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_REASONING_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = False\n            build_config[\"seed\"][\"show\"] = False\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = True\n            build_config[\"seed\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4.5-preview",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "o1"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4o"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              }
            },
            "tool_mode": false
          },
          "type": "OpenAIModel"
        },
        "dragging": false,
        "height": 232,
        "id": "OpenAIModel-if9V0",
        "measured": {
          "height": 232,
          "width": 320
        },
        "position": {
          "x": 3411.8270290674873,
          "y": 702.0583351952305
        },
        "positionAbsolute": {
          "x": 3619.843933794377,
          "y": -29.190755612016034
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Temporal Resolution Prompt",
          "id": "Prompt-zCUQk",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": []
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "hidden": false,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "You are an expert climate scientist. Is the following CMIP6-related query best answered using data gathered at which of the following resolutions: \n\n- 'hr': hour\n- 'day': day\n- 'mon': month\n- 'NA': not applicable, none of the above, or unclear\n\n\nRespond with only the short term of one following corresponding to your choice and nothing else. \n\nIf a query does not specify any given temporal resolution, like the query \"plot average temperature\", then choose \noption NA\n\n\nQuery: \n"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "Prompt"
        },
        "dragging": false,
        "height": 343,
        "id": "Prompt-zCUQk",
        "measured": {
          "height": 343,
          "width": 320
        },
        "position": {
          "x": 2969.3535872567454,
          "y": 90.92530897822377
        },
        "positionAbsolute": {
          "x": 3266.07640414577,
          "y": -598.5560148810174
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Generates text using OpenAI LLMs.",
          "display_name": "TemporalSelector",
          "id": "OpenAIModel-bRtf6",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "hidden": true,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": [
                  "api_key"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import (\n    OPENAI_MODEL_NAMES,\n    OPENAI_REASONING_MODEL_NAMES,\n)\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\nfrom langflow.logging import logger\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[1],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        parameters = {\n            \"api_key\": SecretStr(self.api_key).get_secret_value() if self.api_key else None,\n            \"model_name\": self.model_name,\n            \"max_tokens\": self.max_tokens or None,\n            \"model_kwargs\": self.model_kwargs or {},\n            \"base_url\": self.openai_api_base or \"https://api.openai.com/v1\",\n            \"seed\": self.seed,\n            \"max_retries\": self.max_retries,\n            \"timeout\": self.timeout,\n            \"temperature\": self.temperature if self.temperature is not None else 0.1,\n        }\n\n        logger.info(f\"Model name: {self.model_name}\")\n        if self.model_name in OPENAI_REASONING_MODEL_NAMES:\n            logger.info(\"Getting reasoning model parameters\")\n            parameters.pop(\"temperature\")\n            parameters.pop(\"seed\")\n        output = ChatOpenAI(**parameters)\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_REASONING_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = False\n            build_config[\"seed\"][\"show\"] = False\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = True\n            build_config[\"seed\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4.5-preview",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "o1"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4o-mini"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              }
            },
            "tool_mode": false
          },
          "type": "OpenAIModel"
        },
        "dragging": false,
        "height": 232,
        "id": "OpenAIModel-bRtf6",
        "measured": {
          "height": 232,
          "width": 320
        },
        "position": {
          "x": 3428.4529872423373,
          "y": 3.343485103028188
        },
        "positionAbsolute": {
          "x": 3613.7156540479637,
          "y": -566.2205990195372
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Variables Prompt",
          "id": "Prompt-jcZAy",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": []
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "hidden": false,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "You are a climate scientist and expert on the CMIP6 dataset. Given a colleague's query, find CMIP6 **variables** most likely to help answer the query. \n\nTo find these variables: \n\n1. summarize the variable-related keywords in the query (e.g. \"rain\", not analysis words like \"plot\") using words that are useful for describing the CMIP 6 datasets. For instance, instead of \"weather month\", say temperature precipitation wind\", because \"month\" is not relevant to the variable choice and temperature precipitation wind\" is more specific than \"weather\". \nIf the query relates to whether a variable surpasses some threshold, you may wish to search for the \"min\" or \"max\" versions of variables.\n\n2. connect your list of summary words into one comma separated string.\n\nAdd as much as relevant, don't be shy\n\nUse the tool to check the variables, and at the end output the actual needed query. \n\nYour output should be only the variable name that you found most accurate for the query. No explanations\n"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "Prompt"
        },
        "dragging": false,
        "height": 343,
        "id": "Prompt-jcZAy",
        "measured": {
          "height": 343,
          "width": 320
        },
        "position": {
          "x": 2979.2711590798904,
          "y": -689.9182805542017
        },
        "positionAbsolute": {
          "x": 3262.920008885303,
          "y": -1045.856817683067
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Convert Data into plain text following a specified template.",
          "display_name": "Parse Data",
          "id": "ParseData-HxL7X",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "display_name": "Data to Message",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "legacy": true,
            "lf_version": "1.4.1",
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "parse_data",
                "name": "text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "hidden": null,
                "method": "parse_data_as_list",
                "name": "data_list",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{url}"
              }
            },
            "tool_mode": false
          },
          "type": "ParseData"
        },
        "dragging": false,
        "height": 299,
        "id": "ParseData-HxL7X",
        "measured": {
          "height": 299,
          "width": 320
        },
        "position": {
          "x": 7405.218374802683,
          "y": -653.5235787135279
        },
        "positionAbsolute": {
          "x": 7405.218374802683,
          "y": -653.5235787135279
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Display a chat message in the Playground.",
          "display_name": "Dataset Selector",
          "id": "ChatOutput-yoJ5n",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "🤖"
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n\n                # Replace pipe characters to avoid markdown table issues\n                processed_data = data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n\n                processed_data = processed_data.map(\n                    lambda x: str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x\n                )\n\n                return processed_data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Dataset Selector"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "ChatOutput"
        },
        "dragging": false,
        "height": 232,
        "id": "ChatOutput-yoJ5n",
        "measured": {
          "height": 232,
          "width": 320
        },
        "position": {
          "x": 9260.557632510401,
          "y": -206.49315649455684
        },
        "positionAbsolute": {
          "x": 9056.991656519713,
          "y": -491.37815579242806
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Convert Data into plain text following a specified template.",
          "display_name": "Parse Data",
          "id": "ParseData-RW53y",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "display_name": "Data to Message",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "legacy": true,
            "lf_version": "1.4.1",
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "parse_data",
                "name": "text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "hidden": null,
                "method": "parse_data_as_list",
                "name": "data_list",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User Query: {user_query} \n\n** System Results: **\n\nMIP: {mip} \nExperiment: {experiment}\nVariable: {variable}\nDate Range: {date_range} \nTemporal Resolution: {temporal_resolution} \nSelected URL: {url}"
              }
            },
            "tool_mode": false
          },
          "type": "ParseData"
        },
        "dragging": false,
        "height": 299,
        "id": "ParseData-RW53y",
        "measured": {
          "height": 299,
          "width": 320
        },
        "position": {
          "x": 8418.934715902697,
          "y": -722.7017028430375
        },
        "positionAbsolute": {
          "x": 8306.776545605306,
          "y": -1016.2922074450323
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Convert Data into plain text following a specified template.",
          "display_name": "Experiment",
          "id": "ParseData-93N1M",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "display_name": "Data to Message",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "legacy": true,
            "lf_version": "1.4.1",
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "parse_data",
                "name": "text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "hidden": null,
                "method": "parse_data_as_list",
                "name": "data_list",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{experiment}"
              }
            },
            "tool_mode": false
          },
          "type": "ParseData"
        },
        "dragging": false,
        "height": 299,
        "id": "ParseData-93N1M",
        "measured": {
          "height": 299,
          "width": 320
        },
        "position": {
          "x": 2248.534786736429,
          "y": -2484.1016056520384
        },
        "positionAbsolute": {
          "x": 2511.0347784734704,
          "y": -2439.1016070685455
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Convert Data into plain text following a specified template.",
          "display_name": "MIP",
          "id": "ParseData-PqYbG",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "display_name": "Data to Message",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "legacy": true,
            "lf_version": "1.4.1",
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "parse_data",
                "name": "text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "hidden": null,
                "method": "parse_data_as_list",
                "name": "data_list",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{MIP}"
              }
            },
            "tool_mode": false
          },
          "type": "ParseData"
        },
        "dragging": false,
        "height": 299,
        "id": "ParseData-PqYbG",
        "measured": {
          "height": 299,
          "width": 320
        },
        "position": {
          "x": 2240.9185604789304,
          "y": -2841.495318074562
        },
        "positionAbsolute": {
          "x": 2503.418552215972,
          "y": -2796.495319491069
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Date Range Prompt",
          "id": "Prompt-1pnVb",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "mip_list"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "hidden": false,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "mip_list": {
                "advanced": false,
                "display_name": "mip_list",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "mip_list",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "You are an expert climate scientist working with CMIP6.\n\nHere is a list of the MIPs you work with:\n<MIP_LIST>\n{mip_list}\n</MIP_LIST>\n\nBased on the following query, which of the above MIPs would you use? Return ONLY the name of the MIP and nothing else. If the choice of MIP does not matter, return 'None'.\n\nQuery: \n"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "Prompt"
        },
        "dragging": false,
        "height": 429,
        "id": "Prompt-1pnVb",
        "measured": {
          "height": 429,
          "width": 320
        },
        "position": {
          "x": 3066.7095849846714,
          "y": -2121.1837901805916
        },
        "positionAbsolute": {
          "x": 3267.897612365564,
          "y": -2095.6402967966023
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Generates text using OpenAI LLMs.",
          "display_name": "MIPSelector",
          "id": "OpenAIModel-HOKWH",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "hidden": true,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": [
                  "api_key"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import (\n    OPENAI_MODEL_NAMES,\n    OPENAI_REASONING_MODEL_NAMES,\n)\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\nfrom langflow.logging import logger\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[1],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        parameters = {\n            \"api_key\": SecretStr(self.api_key).get_secret_value() if self.api_key else None,\n            \"model_name\": self.model_name,\n            \"max_tokens\": self.max_tokens or None,\n            \"model_kwargs\": self.model_kwargs or {},\n            \"base_url\": self.openai_api_base or \"https://api.openai.com/v1\",\n            \"seed\": self.seed,\n            \"max_retries\": self.max_retries,\n            \"timeout\": self.timeout,\n            \"temperature\": self.temperature if self.temperature is not None else 0.1,\n        }\n\n        logger.info(f\"Model name: {self.model_name}\")\n        if self.model_name in OPENAI_REASONING_MODEL_NAMES:\n            logger.info(\"Getting reasoning model parameters\")\n            parameters.pop(\"temperature\")\n            parameters.pop(\"seed\")\n        output = ChatOpenAI(**parameters)\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_REASONING_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = False\n            build_config[\"seed\"][\"show\"] = False\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = True\n            build_config[\"seed\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4.5-preview",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "o1"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4o"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              }
            },
            "tool_mode": false
          },
          "type": "OpenAIModel"
        },
        "dragging": false,
        "height": 232,
        "id": "OpenAIModel-HOKWH",
        "measured": {
          "height": 232,
          "width": 320
        },
        "position": {
          "x": 3507.6166995175395,
          "y": -2180.537594308919
        },
        "positionAbsolute": {
          "x": 3630.1633108226492,
          "y": -2019.7750795794166
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Date Range Prompt",
          "id": "Prompt-Kxye7",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "EXPERIMENT_LIST"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "prompts",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "hidden": false,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": null,
            "template": {
              "EXPERIMENT_LIST": {
                "advanced": false,
                "display_name": "EXPERIMENT_LIST",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "EXPERIMENT_LIST",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "You are an expert climate scientist working with CMIP6.\n\nHere is a list of the experiments you work with:\n<EXPERIMENT_LIST>\n{EXPERIMENT_LIST}\n</EXPERIMENT_LIST>\nBased on the following query, which of the above experiments would you use? Return ONLY the name of the experiment and nothing else. If the choice of experiment does not matter, return 'None'.\n\nQuery:"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "Prompt"
        },
        "dragging": false,
        "height": 429,
        "id": "Prompt-Kxye7",
        "measured": {
          "height": 429,
          "width": 320
        },
        "position": {
          "x": 3086.650358346017,
          "y": -1444.1489584485796
        },
        "positionAbsolute": {
          "x": 3267.2895934065823,
          "y": -1570.378785358372
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Generates text using OpenAI LLMs.",
          "display_name": "MIPSelector",
          "id": "OpenAIModel-svP8u",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "hidden": true,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": [
                  "api_key"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import (\n    OPENAI_MODEL_NAMES,\n    OPENAI_REASONING_MODEL_NAMES,\n)\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\nfrom langflow.logging import logger\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[1],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        parameters = {\n            \"api_key\": SecretStr(self.api_key).get_secret_value() if self.api_key else None,\n            \"model_name\": self.model_name,\n            \"max_tokens\": self.max_tokens or None,\n            \"model_kwargs\": self.model_kwargs or {},\n            \"base_url\": self.openai_api_base or \"https://api.openai.com/v1\",\n            \"seed\": self.seed,\n            \"max_retries\": self.max_retries,\n            \"timeout\": self.timeout,\n            \"temperature\": self.temperature if self.temperature is not None else 0.1,\n        }\n\n        logger.info(f\"Model name: {self.model_name}\")\n        if self.model_name in OPENAI_REASONING_MODEL_NAMES:\n            logger.info(\"Getting reasoning model parameters\")\n            parameters.pop(\"temperature\")\n            parameters.pop(\"seed\")\n        output = ChatOpenAI(**parameters)\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_REASONING_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = False\n            build_config[\"seed\"][\"show\"] = False\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = True\n            build_config[\"seed\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4.5-preview",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "o1"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4o"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              }
            },
            "tool_mode": false
          },
          "type": "OpenAIModel"
        },
        "dragging": false,
        "height": 232,
        "id": "OpenAIModel-svP8u",
        "measured": {
          "height": 232,
          "width": 320
        },
        "position": {
          "x": 3500.8966416506055,
          "y": -1476.7372919892196
        },
        "positionAbsolute": {
          "x": 3627.126468560398,
          "y": -1485.4427972933431
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "note-wytew",
          "node": {
            "description": "# Experiment Selector",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 663,
        "id": "note-wytew",
        "measured": {
          "height": 663,
          "width": 1225
        },
        "position": {
          "x": 2910.4912847300743,
          "y": -1541.9989870687425
        },
        "positionAbsolute": {
          "x": 3244.3440273878914,
          "y": -1620.348533861517
        },
        "resizing": false,
        "selected": false,
        "style": {
          "height": 369,
          "width": 600
        },
        "type": "noteNode",
        "width": 1225
      },
      {
        "data": {
          "id": "note-A40Wg",
          "node": {
            "description": "# MIP Selector",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 620,
        "id": "note-A40Wg",
        "measured": {
          "height": 620,
          "width": 1290
        },
        "position": {
          "x": 2898.4121743037845,
          "y": -2218.702660930874
        },
        "positionAbsolute": {
          "x": 3251.2064453977755,
          "y": -2156.8080171949077
        },
        "resizing": false,
        "selected": false,
        "style": {
          "height": 324,
          "width": 600
        },
        "type": "noteNode",
        "width": 1290
      },
      {
        "data": {
          "id": "note-z7zA5",
          "node": {
            "description": "# Variables Selector",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 665,
        "id": "note-z7zA5",
        "measured": {
          "height": 665,
          "width": 1465
        },
        "position": {
          "x": 2903.2235651114934,
          "y": -791.9289155758449
        },
        "positionAbsolute": {
          "x": 3251.2235651114934,
          "y": -1111.928915575845
        },
        "resizing": false,
        "selected": false,
        "style": {
          "height": 349,
          "width": 600
        },
        "type": "noteNode",
        "width": 1465
      },
      {
        "data": {
          "id": "note-MKwXD",
          "node": {
            "description": "# Temporal Selector",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 620,
        "id": "note-MKwXD",
        "measured": {
          "height": 620,
          "width": 1231
        },
        "position": {
          "x": 2900.2062700807796,
          "y": -44.931222492274
        },
        "positionAbsolute": {
          "x": 3241.700118210881,
          "y": -672.7835776147137
        },
        "resizing": false,
        "selected": false,
        "style": {
          "height": 324,
          "width": 600
        },
        "type": "noteNode",
        "width": 1231
      },
      {
        "data": {
          "id": "note-eOJ79",
          "node": {
            "description": "# Range Selector",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "neutral"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 642,
        "id": "note-eOJ79",
        "measured": {
          "height": 642,
          "width": 1240
        },
        "position": {
          "x": 2898.92772627184,
          "y": 642.3109057774732
        },
        "positionAbsolute": {
          "x": 3242.4078436029895,
          "y": -193.87950720208156
        },
        "resizing": false,
        "selected": false,
        "style": {
          "height": 324,
          "width": 600
        },
        "type": "noteNode",
        "width": 1240
      },
      {
        "data": {
          "id": "note-ruv2S",
          "node": {
            "description": "# Load CMIP6 Datasets",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "blue"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 344,
        "id": "note-ruv2S",
        "measured": {
          "height": 344,
          "width": 600
        },
        "position": {
          "x": 1841.9218063933981,
          "y": -2885.3587666657827
        },
        "positionAbsolute": {
          "x": 2104.4217981304396,
          "y": -2840.3587680822898
        },
        "resizing": false,
        "selected": false,
        "style": {
          "height": 344,
          "width": 600
        },
        "type": "noteNode",
        "width": 600
      },
      {
        "data": {
          "id": "note-jvWeA",
          "node": {
            "description": "# Load CMIP6 JSON Tables",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "blue"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 324,
        "id": "note-jvWeA",
        "measured": {
          "height": 324,
          "width": 600
        },
        "position": {
          "x": 2876.2126877207456,
          "y": -2921.831798449466
        },
        "positionAbsolute": {
          "x": 2876.2126877207456,
          "y": -2921.831798449466
        },
        "resizing": false,
        "selected": false,
        "style": {
          "height": 324,
          "width": 600
        },
        "type": "noteNode",
        "width": 600
      },
      {
        "data": {
          "id": "note-WagBQ",
          "node": {
            "description": "# Chat Start",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "lime"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 324,
        "id": "note-WagBQ",
        "measured": {
          "height": 324,
          "width": 324
        },
        "position": {
          "x": 185.09802996781463,
          "y": -1113.8315504183497
        },
        "positionAbsolute": {
          "x": 411.4411617951864,
          "y": -1118.1843029534914
        },
        "selected": false,
        "type": "noteNode",
        "width": 324
      },
      {
        "data": {
          "id": "MIPFilterComponent-XWg03",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Filters CMIP6 datasets based on the predicted MIP.",
            "display_name": "MIP Filter",
            "documentation": "",
            "edited": true,
            "field_order": [
              "dataset_info",
              "mip_value"
            ],
            "frozen": false,
            "icon": "filter",
            "lf_version": "1.4.1",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Filtered Datasets",
                "hidden": false,
                "method": "filter_datasets_by_mip",
                "name": "filtered_datasets",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "# MIPFilterComponent.py\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import HandleInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass MIPFilterComponent(Component):\r\n    display_name = \"MIP Filter\"\r\n    description = \"Filters CMIP6 datasets based on the predicted MIP.\"\r\n    icon = \"filter\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"dataset_info\",\r\n            display_name=\"Dataset Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Processed CMIP6 dataset information from the previous component.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"mip_value\",\r\n            display_name=\"MIP Value\",\r\n            info=\"The MIP value predicted by the LLM.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Filtered Datasets\", name=\"filtered_datasets\", method=\"filter_datasets_by_mip\"),\r\n    ]\r\n\r\n    def filter_datasets_by_mip(self) -> Data:\r\n        if not isinstance(self.dataset_info, Data) or 'df' not in self.dataset_info.data:\r\n            raise ValueError(\"Invalid dataset info input. Expected Data object with 'df' key.\")\r\n\r\n        df = self.dataset_info.data['df']\r\n\r\n        if 'MIP' not in df.columns:\r\n            raise ValueError(\"Expected 'MIP' column in dataset info DataFrame.\")\r\n\r\n        try:\r\n            mip_value = self.mip_value.strip()\r\n            if mip_value.lower() == 'none':\r\n                # No filtering; pass all datasets\r\n                filtered_df = df\r\n                self.status = \"No MIP filtering applied.\"\r\n            else:\r\n                # Filter the dataframe\r\n                filtered_df = df[df['MIP'] == mip_value]\r\n\r\n                if filtered_df.empty:\r\n                    self.status = f\"No datasets found for MIP '{mip_value}'.\"\r\n                else:\r\n                    self.status = f\"Filtered datasets by MIP '{mip_value}'. Remaining datasets: {len(filtered_df)}\"\r\n\r\n            return Data(data={\"filtered_df\": filtered_df})\r\n\r\n        except Exception as e:\r\n            error_message = f\"Error filtering datasets by MIP: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})\r\n"
              },
              "dataset_info": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Dataset Info",
                "dynamic": false,
                "info": "Processed CMIP6 dataset information from the previous component.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "name": "dataset_info",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "mip_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "MIP Value",
                "dynamic": false,
                "info": "The MIP value predicted by the LLM.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "mip_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            }
          },
          "type": "MIPFilterComponent"
        },
        "dragging": false,
        "height": 300,
        "id": "MIPFilterComponent-XWg03",
        "measured": {
          "height": 300,
          "width": 320
        },
        "position": {
          "x": 4308.5991434316675,
          "y": -2286.042075504498
        },
        "positionAbsolute": {
          "x": 4308.5991434316675,
          "y": -2286.042075504498
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "ExperimentFilterComponent-dIkmu",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Filters CMIP6 datasets based on the predicted Experiment.",
            "display_name": "Experiment Filter",
            "documentation": "",
            "edited": true,
            "field_order": [
              "dataset_info",
              "experiment_value"
            ],
            "frozen": false,
            "icon": "filter",
            "lf_version": "1.4.1",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Filtered Datasets",
                "hidden": false,
                "method": "filter_datasets_by_experiment",
                "name": "filtered_datasets",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "# ExperimentFilterComponent.py\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import HandleInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass ExperimentFilterComponent(Component):\r\n    display_name = \"Experiment Filter\"\r\n    description = \"Filters CMIP6 datasets based on the predicted Experiment.\"\r\n    icon = \"filter\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"dataset_info\",\r\n            display_name=\"Dataset Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Dataset information from the previous component (after MIP filtering).\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"experiment_value\",\r\n            display_name=\"Experiment Value\",\r\n            info=\"The Experiment value predicted by the LLM.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Filtered Datasets\", name=\"filtered_datasets\", method=\"filter_datasets_by_experiment\"),\r\n    ]\r\n\r\n    def filter_datasets_by_experiment(self) -> Data:\r\n        if not isinstance(self.dataset_info, Data) or 'filtered_df' not in self.dataset_info.data:\r\n            raise ValueError(\"Invalid dataset info input. Expected Data object with 'filtered_df' key.\")\r\n\r\n        df = self.dataset_info.data['filtered_df']\r\n\r\n        if 'experiment' not in df.columns:\r\n            raise ValueError(\"Expected 'experiment' column in dataset info DataFrame.\")\r\n\r\n        try:\r\n            experiment_value = self.experiment_value.strip()\r\n            if experiment_value.lower() == 'none':\r\n                # No filtering; pass all datasets\r\n                filtered_df = df\r\n                self.status = \"No Experiment filtering applied.\"\r\n            else:\r\n                # Filter the dataframe\r\n                filtered_df = df[df['experiment'] == experiment_value]\r\n\r\n                if filtered_df.empty:\r\n                    self.status = f\"No datasets found for Experiment '{experiment_value}'.\"\r\n                else:\r\n                    self.status = f\"Filtered datasets by Experiment '{experiment_value}'. Remaining datasets: {len(filtered_df)}\"\r\n\r\n            return Data(data={\"filtered_df\": filtered_df})\r\n\r\n        except Exception as e:\r\n            error_message = f\"Error filtering datasets by Experiment: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})\r\n"
              },
              "dataset_info": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Dataset Info",
                "dynamic": false,
                "info": "Dataset information from the previous component (after MIP filtering).",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "name": "dataset_info",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "experiment_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Experiment Value",
                "dynamic": false,
                "info": "The Experiment value predicted by the LLM.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "experiment_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            }
          },
          "type": "ExperimentFilterComponent"
        },
        "dragging": false,
        "height": 300,
        "id": "ExperimentFilterComponent-dIkmu",
        "measured": {
          "height": 300,
          "width": 320
        },
        "position": {
          "x": 4720.720971626717,
          "y": -1965.9139769291764
        },
        "positionAbsolute": {
          "x": 4720.720971626717,
          "y": -1965.9139769291764
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "FilteredVariableInfoComponent-vET89",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Filters variable info based on variables present in filtered datasets.",
            "display_name": "Filtered Variable Info",
            "documentation": "",
            "edited": true,
            "field_order": [
              "variable_info",
              "filtered_datasets"
            ],
            "frozen": false,
            "icon": "filter",
            "lf_version": "1.4.1",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Filtered Variable Info",
                "hidden": false,
                "method": "filter_variable_info",
                "name": "filtered_variable_info",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "# FilteredVariableInfoComponent.py\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import HandleInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass FilteredVariableInfoComponent(Component):\r\n    display_name = \"Filtered Variable Info\"\r\n    description = \"Filters variable info based on variables present in filtered datasets.\"\r\n    icon = \"filter\"\r\n\r\n    inputs = [\r\n        HandleInput(\r\n            name=\"variable_info\",\r\n            display_name=\"Variable Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Original CMIP6 variable information.\",\r\n        ),\r\n        HandleInput(\r\n            name=\"filtered_datasets\",\r\n            display_name=\"Filtered Datasets\",\r\n            input_types=[\"Data\"],\r\n            info=\"Filtered datasets after MIP and Experiment filters.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(\r\n            display_name=\"Filtered Variable Info\",\r\n            name=\"filtered_variable_info\",\r\n            method=\"filter_variable_info\",\r\n        ),\r\n    ]\r\n\r\n    def filter_variable_info(self) -> Data:\r\n        if not isinstance(self.variable_info, Data) or 'variable_info' not in self.variable_info.data:\r\n            raise ValueError(\"Invalid variable info input. Expected Data object with 'variable_info' key.\")\r\n\r\n        if not isinstance(self.filtered_datasets, Data) or 'filtered_df' not in self.filtered_datasets.data:\r\n            raise ValueError(\"Invalid filtered datasets input. Expected Data object with 'filtered_df' key.\")\r\n\r\n        variable_info_df = self.variable_info.data['variable_info']\r\n        filtered_df = self.filtered_datasets.data['filtered_df']\r\n\r\n        try:\r\n            # Get the list of variables present in the filtered datasets\r\n            variables_in_filtered_datasets = filtered_df['variable'].unique().tolist()\r\n\r\n            # Filter variable info to only include these variables\r\n            filtered_variable_info_df = variable_info_df[variable_info_df['variable'].isin(variables_in_filtered_datasets)]\r\n\r\n            self.status = f\"Filtered variable info. Remaining variables: {len(filtered_variable_info_df)}\"\r\n            return Data(data={\"variable_info\": filtered_variable_info_df})\r\n\r\n        except Exception as e:\r\n            error_message = f\"Error filtering variable info: {str(e)}\"\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})\r\n"
              },
              "filtered_datasets": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Filtered Datasets",
                "dynamic": false,
                "info": "Filtered datasets after MIP and Experiment filters.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "name": "filtered_datasets",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "variable_info": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Variable Info",
                "dynamic": false,
                "info": "Original CMIP6 variable information.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "name": "variable_info",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            }
          },
          "type": "FilteredVariableInfoComponent"
        },
        "dragging": false,
        "height": 262,
        "id": "FilteredVariableInfoComponent-vET89",
        "measured": {
          "height": 262,
          "width": 320
        },
        "position": {
          "x": 5150.778223745258,
          "y": -1649.2561807049508
        },
        "positionAbsolute": {
          "x": 5150.778223745258,
          "y": -1649.2561807049508
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "variable_matcher-GNxID",
          "node": {
            "base_classes": [
              "Data",
              "Tool"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Matches CMIP6 variables based on LLM output using cosine similarity.",
            "display_name": "CMIP Variable Tool Check",
            "documentation": "",
            "edited": true,
            "field_order": [
              "variable_info",
              "embeddings",
              "llm_output",
              "top_n"
            ],
            "frozen": false,
            "icon": "match",
            "lf_version": "1.4.1",
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Matched Variables",
                "hidden": true,
                "method": "match_variables",
                "name": "matched_variables",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "Tool",
                "hidden": false,
                "method": "build_tool",
                "name": "tool",
                "selected": "Tool",
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import numpy as np\r\nfrom typing import List, Dict, Any\r\nfrom pydantic import BaseModel, Field\r\n\r\nfrom langflow.base.langchain_utilities.model import LCToolComponent\r\nfrom langflow.io import HandleInput, MessageTextInput, IntInput, Output\r\nfrom langflow.schema import Data\r\nfrom langflow.field_typing import Tool\r\nfrom langchain.tools import StructuredTool\r\n\r\nclass VariableMatcherToolComponent(LCToolComponent):\r\n    display_name = \"CMIP6 Variable Matcher\"\r\n    description = \"Matches CMIP6 variables based on LLM output using cosine similarity.\"\r\n    icon = \"match\"\r\n    name = \"variable_matcher\"\r\n    variable_embeddings = None\r\n    variables_data = None\r\n    \r\n    inputs = [\r\n        HandleInput(\r\n            name=\"variable_info\",\r\n            display_name=\"Variable Info\",\r\n            input_types=[\"Data\"],\r\n            info=\"Processed CMIP6 variable information from the previous component.\",\r\n        ),\r\n        HandleInput(\r\n            name=\"embeddings\",\r\n            display_name=\"Embeddings\",\r\n            input_types=[\"Embeddings\"],\r\n            info=\"Embeddings component for generating query embeddings.\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"llm_output\",\r\n            display_name=\"LLM Output\",\r\n            info=\"Output from the LLM containing variable-related keywords. Can be a single string or comma-separated list.\",\r\n        ),\r\n        IntInput(\r\n            name=\"top_n\",\r\n            display_name=\"Number of Results\",\r\n            info=\"Number of top matching variables to return.\",\r\n            value=5,\r\n        ),\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(display_name=\"Matched Variables\", name=\"matched_variables\", method=\"match_variables\"),\r\n        Output(display_name=\"Tool\", name=\"tool\", method=\"build_tool\"),\r\n    ]\r\n\r\n    class VariableMatcherSchema(BaseModel):\r\n        keywords: str = Field(\r\n            ..., \r\n            description=\"Keywords or description of the variable(s) to search for. Can be a comma-separated list.\"\r\n        )\r\n        top_n: int = Field(\r\n            5, \r\n            description=\"Number of top matching variables to return.\"\r\n        )\r\n\r\n    def cosine_similarity(self, a, b):\r\n        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\r\n\r\n    def _process_matches(self, keywords: str, top_n: int) -> List[Dict[str, Any]]:\r\n        \"\"\"Internal method to process variable matches\"\"\"\r\n        if not isinstance(self.variable_info, Data) or 'variable_info' not in self.variable_info.data:\r\n            raise ValueError(\"Invalid variable info input. Expected Data object with 'variable_info' key.\")\r\n        \r\n        varsdf = self.variable_info.data['variable_info']\r\n        \r\n        if 'embeds' not in varsdf.columns:\r\n            raise ValueError(\"Expected 'embeds' column in variable info DataFrame.\")\r\n\r\n        # Initialize variable embeddings if not already done\r\n        if self.variable_embeddings is None:\r\n            self.variable_embeddings = np.array(varsdf['embeds'].tolist())\r\n            self.variables_data = varsdf.drop('embeds', axis=1)\r\n\r\n        # Split keywords\r\n        keyword_list = [kw.strip() for kw in keywords.split(',')]\r\n        \r\n        # Generate embeddings for each keyword\r\n        keyword_embeddings = [self.embeddings.embed_query(kw) for kw in keyword_list]\r\n        \r\n        # Use the average embedding as the query\r\n        query_embedding = np.mean(keyword_embeddings, axis=0)\r\n        \r\n        # Calculate cosine similarity\r\n        similarities = np.array([\r\n            self.cosine_similarity(query_embedding, vec) \r\n            for vec in self.variable_embeddings\r\n        ])\r\n        \r\n        # Get top N matches\r\n        top_indices = np.argsort(similarities)[-top_n:][::-1]\r\n        \r\n        # Prepare results\r\n        results = self.variables_data.iloc[top_indices].copy()\r\n        results['similarity_score'] = similarities[top_indices]\r\n        \r\n        # Convert to list of dictionaries\r\n        return [\r\n            {\r\n                'variable': row['variable'],\r\n                'long_name': row['long_name'],\r\n                'comment': row['comment'],\r\n                'similarity_score': float(row['similarity_score'])\r\n            }\r\n            for _, row in results.iterrows()\r\n        ]\r\n\r\n    def match_variables(self) -> List[Data]:\r\n        \"\"\"Method for component output\"\"\"\r\n        try:\r\n            results = self._process_matches(self.llm_output, self.top_n)\r\n            data_list = [Data(data=result) for result in results]\r\n            self.status = data_list\r\n            return data_list\r\n            \r\n        except Exception as e:\r\n            error_message = f\"Error matching variables: {str(e)}\"\r\n            self.status = error_message\r\n            return [Data(data={\"error\": error_message})]\r\n\r\n    def build_tool(self) -> Tool:\r\n        \"\"\"Build and return the tool\"\"\"\r\n        return StructuredTool.from_function(\r\n            name=\"variable_matcher\",\r\n            description=\"Match CMIP6 variables based on keywords using semantic similarity. \"\r\n                      \"Input should be keywords or descriptions of the variables you're looking for.\",\r\n            func=self._tool_function,\r\n            args_schema=self.VariableMatcherSchema,\r\n        )\r\n\r\n    def _tool_function(self, keywords: str, top_n: int = 5) -> List[Dict[str, Any]]:\r\n        \"\"\"Function to be called by the tool\"\"\"\r\n        try:\r\n            return self._process_matches(keywords, top_n)\r\n        except Exception as e:\r\n            return [{\"error\": f\"Error matching variables: {str(e)}\"}]"
              },
              "embeddings": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Embeddings",
                "dynamic": false,
                "info": "Embeddings component for generating query embeddings.",
                "input_types": [
                  "Embeddings"
                ],
                "list": false,
                "name": "embeddings",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "llm_output": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "LLM Output",
                "dynamic": false,
                "info": "Output from the LLM containing variable-related keywords. Can be a single string or comma-separated list.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "llm_output",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "top_n": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Number of Results",
                "dynamic": false,
                "info": "Number of top matching variables to return.",
                "list": false,
                "load_from_db": false,
                "name": "top_n",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "variable_info": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Variable Info",
                "dynamic": false,
                "info": "Processed CMIP6 variable information from the previous component.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "name": "variable_info",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            }
          },
          "type": "variable_matcher"
        },
        "dragging": false,
        "height": 347,
        "id": "variable_matcher-GNxID",
        "measured": {
          "height": 347,
          "width": 320
        },
        "position": {
          "x": 3340.6606701817623,
          "y": -647.6229712833099
        },
        "positionAbsolute": {
          "x": 3666.3057680460593,
          "y": -1060.990373856476
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "CurrentDateComponent-aEEHi",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Returns the current date and time in the selected timezone.",
            "display_name": "Current Date",
            "documentation": "",
            "edited": true,
            "field_order": [
              "timezone"
            ],
            "frozen": false,
            "icon": "clock",
            "lf_version": "1.4.1",
            "official": false,
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Current Date",
                "method": "get_current_date",
                "name": "current_date",
                "selected": "Message",
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from datetime import datetime\r\nfrom zoneinfo import ZoneInfo\r\nfrom typing import List\r\n\r\nfrom langflow.custom import Component\r\nfrom langflow.io import DropdownInput, Output\r\nfrom langflow.schema.message import Message\r\n\r\nclass CurrentDateComponent(Component):\r\n    display_name = \"Current Date 🕰️\"\r\n    description = \"Returns the current date and time in the selected timezone.\"\r\n    icon = \"clock\"\r\n\r\n    inputs = [\r\n        DropdownInput(\r\n            name=\"timezone\",\r\n            display_name=\"Timezone\",\r\n            options=[\r\n                \"UTC\",\r\n                \"US/Eastern\",\r\n                \"US/Central\",\r\n                \"US/Mountain\",\r\n                \"US/Pacific\",\r\n                \"Europe/London\",\r\n                \"Europe/Paris\",\r\n                \"Asia/Tokyo\",\r\n                \"Australia/Sydney\",\r\n                \"America/Sao_Paulo\",\r\n                \"America/Cuiaba\",\r\n            ],\r\n            value=\"UTC\",\r\n            info=\"Select the timezone for the current date and time.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Current Date\", name=\"current_date\", method=\"get_current_date\"),\r\n    ]\r\n\r\n    def get_current_date(self) -> Message:\r\n        try:\r\n            tz = ZoneInfo(self.timezone)\r\n            current_date = datetime.now(tz).strftime(\"%Y-%m-%d %H:%M:%S %Z\")\r\n            result = f\"Current date and time in {self.timezone}: {current_date}\"\r\n            self.status = result\r\n            return Message(text=result)\r\n        except Exception as e:\r\n            error_message = f\"Error: {str(e)}\"\r\n            self.status = error_message\r\n            return Message(text=error_message)"
              },
              "timezone": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "display_name": "Timezone",
                "dynamic": false,
                "info": "Select the timezone for the current date and time.",
                "name": "timezone",
                "options": [
                  "UTC",
                  "US/Eastern",
                  "US/Central",
                  "US/Mountain",
                  "US/Pacific",
                  "Europe/London",
                  "Europe/Paris",
                  "Asia/Tokyo",
                  "Australia/Sydney",
                  "America/Sao_Paulo",
                  "America/Cuiaba"
                ],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "America/Sao_Paulo"
              }
            }
          },
          "showNode": false,
          "type": "CurrentDateComponent"
        },
        "dragging": false,
        "height": 65,
        "id": "CurrentDateComponent-aEEHi",
        "measured": {
          "height": 65,
          "width": 192
        },
        "position": {
          "x": 2571.602228717859,
          "y": 1136.8249245474012
        },
        "positionAbsolute": {
          "x": 3005.1083801447135,
          "y": 93.71069763839861
        },
        "selected": false,
        "type": "genericNode",
        "width": 192
      },
      {
        "data": {
          "id": "note-sQXVw",
          "node": {
            "description": "# Dataset Filtering Process",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "lime"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 334,
        "id": "note-sQXVw",
        "measured": {
          "height": 334,
          "width": 600
        },
        "position": {
          "x": 4280.8973999719465,
          "y": -2415.3972398695923
        },
        "positionAbsolute": {
          "x": 4280.8973999719465,
          "y": -2415.3972398695923
        },
        "resizing": false,
        "selected": false,
        "style": {
          "height": 334,
          "width": 600
        },
        "type": "noteNode",
        "width": 600
      },
      {
        "data": {
          "id": "note-v1lQi",
          "node": {
            "description": "# Final Message Analysis ",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "lime"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 324,
        "id": "note-v1lQi",
        "measured": {
          "height": 324,
          "width": 600
        },
        "position": {
          "x": 8390.931182587896,
          "y": -827.8094451606194
        },
        "positionAbsolute": {
          "x": 8278.773012290505,
          "y": -1121.3999497626141
        },
        "resizing": false,
        "selected": false,
        "style": {
          "height": 324,
          "width": 600
        },
        "type": "noteNode",
        "width": 600
      },
      {
        "data": {
          "id": "Agent-y4GVw",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Define the agent's instructions, then enter a task to complete using tools.",
            "display_name": "Agent",
            "documentation": "",
            "edited": false,
            "field_order": [
              "agent_llm",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout",
              "system_prompt",
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "memory",
              "sender",
              "sender_name",
              "n_messages",
              "session_id",
              "order",
              "template",
              "add_current_date_tool"
            ],
            "frozen": false,
            "icon": "bot",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Response",
                "hidden": false,
                "method": "message_response",
                "name": "response",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "add_current_date_tool": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Current Date",
                "dynamic": false,
                "info": "If true, will add a tool to the agent that returns the current date.",
                "list": false,
                "list_add_label": "Add More",
                "name": "add_current_date_tool",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "agent_llm": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Provider",
                "dynamic": false,
                "info": "The provider of the language model that the agent will use to generate responses.",
                "input_types": [],
                "name": "agent_llm",
                "options": [
                  "Amazon Bedrock",
                  "Anthropic",
                  "Azure OpenAI",
                  "Google Generative AI",
                  "Groq",
                  "NVIDIA",
                  "OpenAI",
                  "SambaNova",
                  "Custom"
                ],
                "options_metadata": [
                  {
                    "icon": "Amazon"
                  },
                  {
                    "icon": "Anthropic"
                  },
                  {
                    "icon": "Azure"
                  },
                  {
                    "icon": "GoogleGenerativeAI"
                  },
                  {
                    "icon": "Groq"
                  },
                  {
                    "icon": "NVIDIA"
                  },
                  {
                    "icon": "OpenAI"
                  },
                  {
                    "icon": "SambaNova"
                  },
                  {
                    "icon": "brain"
                  }
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "OpenAI"
              },
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_core.tools import StructuredTool\n\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.base.agents.events import ExceptionWithMessageError\nfrom langflow.base.models.model_input_constants import (\n    ALL_PROVIDER_FIELDS,\n    MODEL_DYNAMIC_UPDATE_FIELDS,\n    MODEL_PROVIDERS_DICT,\n    MODELS_METADATA,\n)\nfrom langflow.base.models.model_utils import get_model_name\nfrom langflow.components.helpers import CurrentDateComponent\nfrom langflow.components.helpers.memory import MemoryComponent\nfrom langflow.components.langchain_utilities.tool_calling import ToolCallingAgentComponent\nfrom langflow.custom.utils import update_component_build_config\nfrom langflow.io import BoolInput, DropdownInput, MultilineInput, Output\nfrom langflow.logging import logger\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.schema.message import Message\n\n\ndef set_advanced_true(component_input):\n    component_input.advanced = True\n    return component_input\n\n\nclass AgentComponent(ToolCallingAgentComponent):\n    display_name: str = \"Agent\"\n    description: str = \"Define the agent's instructions, then enter a task to complete using tools.\"\n    icon = \"bot\"\n    beta = False\n    name = \"Agent\"\n\n    memory_inputs = [set_advanced_true(component_input) for component_input in MemoryComponent().inputs]\n\n    inputs = [\n        DropdownInput(\n            name=\"agent_llm\",\n            display_name=\"Model Provider\",\n            info=\"The provider of the language model that the agent will use to generate responses.\",\n            options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n            value=\"OpenAI\",\n            real_time_refresh=True,\n            input_types=[],\n            options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())] + [{\"icon\": \"brain\"}],\n        ),\n        *MODEL_PROVIDERS_DICT[\"OpenAI\"][\"inputs\"],\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"Agent Instructions\",\n            info=\"System Prompt: Initial instructions and context provided to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n            advanced=False,\n        ),\n        *LCToolsAgentComponent._base_inputs,\n        *memory_inputs,\n        BoolInput(\n            name=\"add_current_date_tool\",\n            display_name=\"Current Date\",\n            advanced=True,\n            info=\"If true, will add a tool to the agent that returns the current date.\",\n            value=True,\n        ),\n    ]\n    outputs = [Output(name=\"response\", display_name=\"Response\", method=\"message_response\")]\n\n    async def message_response(self) -> Message:\n        try:\n            # Get LLM model and validate\n            llm_model, display_name = self.get_llm()\n            if llm_model is None:\n                msg = \"No language model selected. Please choose a model to proceed.\"\n                raise ValueError(msg)\n            self.model_name = get_model_name(llm_model, display_name=display_name)\n\n            # Get memory data\n            self.chat_history = await self.get_memory_data()\n\n            # Add current date tool if enabled\n            if self.add_current_date_tool:\n                if not isinstance(self.tools, list):  # type: ignore[has-type]\n                    self.tools = []\n                current_date_tool = (await CurrentDateComponent(**self.get_base_args()).to_toolkit()).pop(0)\n                if not isinstance(current_date_tool, StructuredTool):\n                    msg = \"CurrentDateComponent must be converted to a StructuredTool\"\n                    raise TypeError(msg)\n                self.tools.append(current_date_tool)\n\n            # Validate tools\n            if not self.tools:\n                msg = \"Tools are required to run the agent. Please add at least one tool.\"\n                raise ValueError(msg)\n\n            # Set up and run agent\n            self.set(\n                llm=llm_model,\n                tools=self.tools,\n                chat_history=self.chat_history,\n                input_value=self.input_value,\n                system_prompt=self.system_prompt,\n            )\n            agent = self.create_agent_runnable()\n            return await self.run_agent(agent)\n\n        except (ValueError, TypeError, KeyError) as e:\n            logger.error(f\"{type(e).__name__}: {e!s}\")\n            raise\n        except ExceptionWithMessageError as e:\n            logger.error(f\"ExceptionWithMessageError occurred: {e}\")\n            raise\n        except Exception as e:\n            logger.error(f\"Unexpected error: {e!s}\")\n            raise\n\n    async def get_memory_data(self):\n        memory_kwargs = {\n            component_input.name: getattr(self, f\"{component_input.name}\") for component_input in self.memory_inputs\n        }\n        # filter out empty values\n        memory_kwargs = {k: v for k, v in memory_kwargs.items() if v}\n\n        return await MemoryComponent(**self.get_base_args()).set(**memory_kwargs).retrieve_messages()\n\n    def get_llm(self):\n        if not isinstance(self.agent_llm, str):\n            return self.agent_llm, None\n\n        try:\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if not provider_info:\n                msg = f\"Invalid model provider: {self.agent_llm}\"\n                raise ValueError(msg)\n\n            component_class = provider_info.get(\"component_class\")\n            display_name = component_class.display_name\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\", \"\")\n\n            return self._build_llm_model(component_class, inputs, prefix), display_name\n\n        except Exception as e:\n            logger.error(f\"Error building {self.agent_llm} language model: {e!s}\")\n            msg = f\"Failed to initialize language model: {e!s}\"\n            raise ValueError(msg) from e\n\n    def _build_llm_model(self, component, inputs, prefix=\"\"):\n        model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n        return component.set(**model_kwargs).build_model()\n\n    def set_component_params(self, component):\n        provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n        if provider_info:\n            inputs = provider_info.get(\"inputs\")\n            prefix = provider_info.get(\"prefix\")\n            model_kwargs = {input_.name: getattr(self, f\"{prefix}{input_.name}\") for input_ in inputs}\n\n            return component.set(**model_kwargs)\n        return component\n\n    def delete_fields(self, build_config: dotdict, fields: dict | list[str]) -> None:\n        \"\"\"Delete specified fields from build_config.\"\"\"\n        for field in fields:\n            build_config.pop(field, None)\n\n    def update_input_types(self, build_config: dotdict) -> dotdict:\n        \"\"\"Update input types for all fields in build_config.\"\"\"\n        for key, value in build_config.items():\n            if isinstance(value, dict):\n                if value.get(\"input_types\") is None:\n                    build_config[key][\"input_types\"] = []\n            elif hasattr(value, \"input_types\") and value.input_types is None:\n                value.input_types = []\n        return build_config\n\n    async def update_build_config(\n        self, build_config: dotdict, field_value: str, field_name: str | None = None\n    ) -> dotdict:\n        # Iterate over all providers in the MODEL_PROVIDERS_DICT\n        # Existing logic for updating build_config\n        if field_name in (\"agent_llm\",):\n            build_config[\"agent_llm\"][\"value\"] = field_value\n            provider_info = MODEL_PROVIDERS_DICT.get(field_value)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call the component class's update_build_config method\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n\n            provider_configs: dict[str, tuple[dict, list[dict]]] = {\n                provider: (\n                    MODEL_PROVIDERS_DICT[provider][\"fields\"],\n                    [\n                        MODEL_PROVIDERS_DICT[other_provider][\"fields\"]\n                        for other_provider in MODEL_PROVIDERS_DICT\n                        if other_provider != provider\n                    ],\n                )\n                for provider in MODEL_PROVIDERS_DICT\n            }\n            if field_value in provider_configs:\n                fields_to_add, fields_to_delete = provider_configs[field_value]\n\n                # Delete fields from other providers\n                for fields in fields_to_delete:\n                    self.delete_fields(build_config, fields)\n\n                # Add provider-specific fields\n                if field_value == \"OpenAI\" and not any(field in build_config for field in fields_to_add):\n                    build_config.update(fields_to_add)\n                else:\n                    build_config.update(fields_to_add)\n                # Reset input types for agent_llm\n                build_config[\"agent_llm\"][\"input_types\"] = []\n            elif field_value == \"Custom\":\n                # Delete all provider fields\n                self.delete_fields(build_config, ALL_PROVIDER_FIELDS)\n                # Update with custom component\n                custom_component = DropdownInput(\n                    name=\"agent_llm\",\n                    display_name=\"Language Model\",\n                    options=[*sorted(MODEL_PROVIDERS_DICT.keys()), \"Custom\"],\n                    value=\"Custom\",\n                    real_time_refresh=True,\n                    input_types=[\"LanguageModel\"],\n                    options_metadata=[MODELS_METADATA[key] for key in sorted(MODELS_METADATA.keys())]\n                    + [{\"icon\": \"brain\"}],\n                )\n                build_config.update({\"agent_llm\": custom_component.to_dict()})\n            # Update input types for all fields\n            build_config = self.update_input_types(build_config)\n\n            # Validate required keys\n            default_keys = [\n                \"code\",\n                \"_type\",\n                \"agent_llm\",\n                \"tools\",\n                \"input_value\",\n                \"add_current_date_tool\",\n                \"system_prompt\",\n                \"agent_description\",\n                \"max_iterations\",\n                \"handle_parsing_errors\",\n                \"verbose\",\n            ]\n            missing_keys = [key for key in default_keys if key not in build_config]\n            if missing_keys:\n                msg = f\"Missing required keys in build_config: {missing_keys}\"\n                raise ValueError(msg)\n        if (\n            isinstance(self.agent_llm, str)\n            and self.agent_llm in MODEL_PROVIDERS_DICT\n            and field_name in MODEL_DYNAMIC_UPDATE_FIELDS\n        ):\n            provider_info = MODEL_PROVIDERS_DICT.get(self.agent_llm)\n            if provider_info:\n                component_class = provider_info.get(\"component_class\")\n                component_class = self.set_component_params(component_class)\n                prefix = provider_info.get(\"prefix\")\n                if component_class and hasattr(component_class, \"update_build_config\"):\n                    # Call each component class's update_build_config method\n                    # remove the prefix from the field_name\n                    if isinstance(field_name, str) and isinstance(prefix, str):\n                        field_name = field_name.replace(prefix, \"\")\n                    build_config = await update_component_build_config(\n                        component_class, build_config, field_value, \"model_name\"\n                    )\n        return dotdict({k: v.to_dict() if hasattr(v, \"to_dict\") else v for k, v in build_config.items()})\n"
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "list": false,
                "list_add_label": "Add More",
                "name": "handle_parsing_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 15
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "memory": {
                "_input_type": "HandleInput",
                "advanced": true,
                "display_name": "External Memory",
                "dynamic": false,
                "info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
                "input_types": [
                  "Memory"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "memory",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "To see the model names, first choose a provider. Then, enter your API key and click the refresh button next to the model name.",
                "load_from_db": false,
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4.5-preview",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "o1"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": false,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4o-mini"
              },
              "n_messages": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Number of Messages",
                "dynamic": false,
                "info": "Number of messages to retrieve.",
                "list": false,
                "list_add_label": "Add More",
                "name": "n_messages",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "order": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Order",
                "dynamic": false,
                "info": "Order of the messages.",
                "name": "order",
                "options": [
                  "Ascending",
                  "Descending"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ascending"
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Filter by sender type.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User",
                  "Machine and User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine and User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Filter by sender name.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "system_prompt": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Agent Instructions",
                "dynamic": false,
                "info": "System Prompt: Initial instructions and context provided to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_prompt",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are a helpful assistant that can use tools to answer questions and perform tasks."
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{sender_name}: {text}"
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "type": "Agent"
        },
        "dragging": false,
        "height": 385,
        "id": "Agent-y4GVw",
        "measured": {
          "height": 385,
          "width": 320
        },
        "position": {
          "x": 3723.5987473550076,
          "y": -765.7208915189365
        },
        "positionAbsolute": {
          "x": 4048.5987473550076,
          "y": -1060.7208915189365
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "ChatOutput-7TzLL",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": true,
                "method": "message_response",
                "name": "message",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "🧪"
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n\n                # Replace pipe characters to avoid markdown table issues\n                processed_data = data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n\n                processed_data = processed_data.map(\n                    lambda x: str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x\n                )\n\n                return processed_data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Experiment"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "height": 65,
        "id": "ChatOutput-7TzLL",
        "measured": {
          "height": 65,
          "width": 192
        },
        "position": {
          "x": 3928.0791922988237,
          "y": -983.8740254059369
        },
        "positionAbsolute": {
          "x": 4023.225274127163,
          "y": -1387.9401682772288
        },
        "selected": false,
        "type": "genericNode",
        "width": 192
      },
      {
        "data": {
          "id": "ChatOutput-Q0tph",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": true,
                "method": "message_response",
                "name": "message",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "🧪"
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n\n                # Replace pipe characters to avoid markdown table issues\n                processed_data = data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n\n                processed_data = processed_data.map(\n                    lambda x: str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x\n                )\n\n                return processed_data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "MIP"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "height": 65,
        "id": "ChatOutput-Q0tph",
        "measured": {
          "height": 65,
          "width": 192
        },
        "position": {
          "x": 3987.2453501496643,
          "y": -1678.6186106874195
        },
        "positionAbsolute": {
          "x": 3990.090987621923,
          "y": -1849.081183813862
        },
        "selected": false,
        "type": "genericNode",
        "width": 192
      },
      {
        "data": {
          "id": "ChatOutput-rhTKs",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": true,
                "method": "message_response",
                "name": "message",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "🧪"
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n\n                # Replace pipe characters to avoid markdown table issues\n                processed_data = data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n\n                processed_data = processed_data.map(\n                    lambda x: str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x\n                )\n\n                return processed_data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Variable"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "height": 65,
        "id": "ChatOutput-rhTKs",
        "measured": {
          "height": 65,
          "width": 192
        },
        "position": {
          "x": 4159.546713934231,
          "y": -235.22596268678723
        },
        "positionAbsolute": {
          "x": 4420.290209494043,
          "y": -760.6068921644619
        },
        "selected": false,
        "type": "genericNode",
        "width": 192
      },
      {
        "data": {
          "id": "ChatOutput-1ZFPQ",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": true,
                "method": "message_response",
                "name": "message",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "🧪"
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n\n                # Replace pipe characters to avoid markdown table issues\n                processed_data = data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n\n                processed_data = processed_data.map(\n                    lambda x: str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x\n                )\n\n                return processed_data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Temporal Resolution"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "height": 65,
        "id": "ChatOutput-1ZFPQ",
        "measured": {
          "height": 65,
          "width": 192
        },
        "position": {
          "x": 3924.6253419630852,
          "y": 501.29100720541186
        },
        "positionAbsolute": {
          "x": 3975.5057365391876,
          "y": -420.05443882834027
        },
        "selected": false,
        "type": "genericNode",
        "width": 192
      },
      {
        "data": {
          "id": "ChatOutput-KKC4E",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": true,
                "method": "message_response",
                "name": "message",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "🧪"
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n\n                # Replace pipe characters to avoid markdown table issues\n                processed_data = data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n\n                processed_data = processed_data.map(\n                    lambda x: str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x\n                )\n\n                return processed_data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Date Range"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatOutput"
        },
        "dragging": false,
        "height": 65,
        "id": "ChatOutput-KKC4E",
        "measured": {
          "height": 65,
          "width": 192
        },
        "position": {
          "x": 3934.0025325694296,
          "y": 1204.7900124718415
        },
        "positionAbsolute": {
          "x": 4001.302322677998,
          "y": 136.59348434065427
        },
        "selected": false,
        "type": "genericNode",
        "width": 192
      },
      {
        "data": {
          "id": "CustomComponent-NeKJ6",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Read search configuration from a JSON file, clear its contents, or return empty values if the file doesn't exist",
            "display_name": "Read or Clear URL from JSON",
            "documentation": "",
            "edited": true,
            "field_order": [
              "file_name",
              "clear_file"
            ],
            "frozen": false,
            "icon": "file-json",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Configuration Data",
                "hidden": false,
                "method": "read_or_clear_config",
                "name": "config_data",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "clear_file": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Clear File",
                "dynamic": false,
                "info": "If set to true, the file contents will be cleared instead of read",
                "list": false,
                "name": "clear_file",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\r\nfrom langflow.io import MessageTextInput, BoolInput, Output\r\nfrom langflow.schema import Data\r\nimport json\r\nimport os\r\n\r\nclass ReadOrClearConfigComponent(Component):\r\n    display_name = \"Read or Clear Search Configuration\"\r\n    description = \"Read search configuration from a JSON file, clear its contents, or return empty values if the file doesn't exist\"\r\n    icon = \"file-json\"\r\n    \r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"file_name\",\r\n            display_name=\"File Name\",\r\n            info=\"The name of the JSON file to read or clear (without .json extension)\",\r\n            value=\"search_config\"\r\n        ),\r\n        BoolInput(\r\n            name=\"clear_file\",\r\n            display_name=\"Clear File\",\r\n            info=\"If set to true, the file contents will be cleared instead of read\",\r\n            value=False\r\n        ),\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(name=\"config_data\", display_name=\"Configuration Data\", method=\"read_or_clear_config\"),\r\n    ]\r\n\r\n    def get_empty_config(self):\r\n        return {\r\n            \"url\": \"\",\r\n            \"temporal_resolution\": \"\",\r\n            \"date_range\": \"\",\r\n            \"mip\": \"\",\r\n            \"experiment\": \"\",\r\n            \"variable\": \"\",\r\n            \"user_query\": \"\"\r\n        }\r\n\r\n    def read_or_clear_config(self) -> Data:\r\n        try:\r\n            file_name = f\"{self.file_name}.json\" if self.file_name else \"search_config.json\"\r\n            \r\n            if self.clear_file:\r\n                # Clear the file with empty values for all fields\r\n                empty_config = self.get_empty_config()\r\n                with open(file_name, 'w') as json_file:\r\n                    json.dump(empty_config, json_file, indent=2)\r\n                self.log(f\"File {file_name} has been cleared\")\r\n                return Data(data={**empty_config, \"file_name\": file_name, \"action\": \"cleared\"})\r\n            else:\r\n                # Read the file or return empty config if it doesn't exist\r\n                if not os.path.exists(file_name):\r\n                    self.log(f\"File {file_name} not found. Returning empty configuration.\")\r\n                    empty_config = self.get_empty_config()\r\n                    return Data(data={\r\n                        **empty_config,\r\n                        \"file_name\": file_name,\r\n                        \"action\": \"file_not_found\"\r\n                    })\r\n                \r\n                with open(file_name, 'r') as json_file:\r\n                    data = json.load(json_file)\r\n                \r\n                # Ensure all expected fields are present, use empty string if missing\r\n                config = {\r\n                    \"url\": data.get('url', ''),\r\n                    \"temporal_resolution\": data.get('temporal_resolution', ''),\r\n                    \"date_range\": data.get('date_range', ''),\r\n                    \"mip\": data.get('mip', ''),\r\n                    \"experiment\": data.get('experiment', ''),\r\n                    \"variable\": data.get('variable', ''),\r\n                    \"user_query\": data.get('user_query', ''),\r\n                    \"run_id\": data.get('run_id', '')\r\n                }\r\n                \r\n                self.log(f\"Configuration read from {file_name}\")\r\n                \r\n                return Data(data={\r\n                    **config,\r\n                    \"file_name\": file_name,\r\n                    \"action\": \"read\"\r\n                })\r\n        \r\n        except json.JSONDecodeError:\r\n            error_message = f\"Error decoding JSON from {file_name}. File may be empty or contain invalid JSON.\"\r\n            self.log(error_message)\r\n            empty_config = self.get_empty_config()\r\n            return Data(data={\r\n                **empty_config,\r\n                \"file_name\": file_name,\r\n                \"action\": \"json_error\",\r\n                \"error\": error_message\r\n            })\r\n        \r\n        except Exception as e:\r\n            error_message = f\"An error occurred: {str(e)}\"\r\n            self.log(error_message)\r\n            self.status = error_message\r\n            empty_config = self.get_empty_config()\r\n            return Data(data={\r\n                **empty_config,\r\n                \"file_name\": file_name,\r\n                \"action\": \"error\",\r\n                \"error\": error_message\r\n            })"
              },
              "file_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "File Name",
                "dynamic": false,
                "info": "The name of the JSON file to read or clear (without .json extension)",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "file_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "url_data"
              }
            },
            "tool_mode": false
          },
          "type": "CustomComponent"
        },
        "dragging": false,
        "height": 316,
        "id": "CustomComponent-NeKJ6",
        "measured": {
          "height": 316,
          "width": 320
        },
        "position": {
          "x": 748.4483547550294,
          "y": -844.7087524890126
        },
        "positionAbsolute": {
          "x": 842.0325342605774,
          "y": -711.9498001671886
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "CustomComponent-e7Nca",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Route Data objects based on the presence of a URL, including additional message.",
            "display_name": "URL Message Router",
            "documentation": "",
            "edited": true,
            "field_order": [
              "message",
              "input_data"
            ],
            "frozen": false,
            "icon": "git-branch",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "URL Absent",
                "hidden": false,
                "method": "route_url_absent",
                "name": "url_absent",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "cache": true,
                "display_name": "URL Present",
                "hidden": false,
                "method": "route_url_present",
                "name": "url_present",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\r\nfrom langflow.io import DataInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\n\r\nclass URLDataRouterComponent(Component):\r\n    display_name = \"URL Data Router\"\r\n    description = \"Route Data objects based on the presence of a URL, including additional message.\"\r\n    icon = \"git-branch\"\r\n    \r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"message\",\r\n            display_name=\"Message\",\r\n            info=\"Additional message to be added to the Data object\",\r\n            required=True,\r\n        ),\r\n        DataInput(\r\n            name=\"input_data\",\r\n            display_name=\"Input Data\",\r\n            info=\"The Data object to be routed\",\r\n            required=True,\r\n        ),\r\n        \r\n    ]\r\n    \r\n    outputs = [\r\n        Output(display_name=\"URL Absent\", name=\"url_absent\", method=\"route_url_absent\"),\r\n        Output(display_name=\"URL Present\", name=\"url_present\", method=\"route_url_present\"),\r\n    ]\r\n\r\n    def validate_input(self):\r\n        if not isinstance(self.input_data, Data):\r\n            raise ValueError(\"Input is not a Data object\")\r\n\r\n    def url_exists(self):\r\n        url = self.input_data.data.get('url', '')\r\n        return url and isinstance(url, str) and url.strip()\r\n\r\n    def _add_message_to_data(self) -> Data:\r\n        \"\"\"Add the message to the Data object\"\"\"\r\n        if isinstance(self.input_data.data, dict):\r\n            data_dict = self.input_data.data.copy()\r\n            data_dict['message'] = self.message\r\n            return Data(data=data_dict)\r\n        return self.input_data\r\n\r\n    def route_url_present(self) -> Data:\r\n        try:\r\n            self.validate_input()\r\n            \r\n            if self.url_exists():\r\n                return self._add_message_to_data()\r\n            else:\r\n                self.stop(\"url_present\")\r\n                return None\r\n                \r\n        except Exception as e:\r\n            error_message = f\"An error occurred in URL Present route: {str(e)}\"\r\n            self.log(error_message)\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})\r\n\r\n    def route_url_absent(self) -> Data:\r\n        try:\r\n            self.validate_input()\r\n            \r\n            if not self.url_exists():\r\n                return self._add_message_to_data()\r\n            else:\r\n                self.stop(\"url_absent\")\r\n                return None\r\n                \r\n        except Exception as e:\r\n            error_message = f\"An error occurred in URL Absent route: {str(e)}\"\r\n            self.log(error_message)\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})"
              },
              "input_data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Input Data",
                "dynamic": false,
                "info": "The Data object to be routed",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "name": "input_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "message": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Message",
                "dynamic": false,
                "info": "Additional message to be added to the Data object",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "message",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "CustomComponent"
        },
        "dragging": false,
        "height": 348,
        "id": "CustomComponent-e7Nca",
        "measured": {
          "height": 348,
          "width": 320
        },
        "position": {
          "x": 1338.5764875995933,
          "y": -1064.6024254896874
        },
        "positionAbsolute": {
          "x": 1338.5764875995933,
          "y": -1064.6024254896874
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "CustomComponent-qUYAm",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Save search configuration parameters including URL, temporal resolution, date range, MIP, experiment, variable, and user query to a JSON file",
            "display_name": "Save Search Configuration",
            "documentation": "",
            "edited": true,
            "field_order": [
              "url",
              "temporal_resolution",
              "date_range",
              "mip",
              "experiment",
              "variable",
              "user_query",
              "file_name"
            ],
            "frozen": false,
            "icon": "save",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Saved Data",
                "hidden": false,
                "method": "save_config",
                "name": "saved_data",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\r\nfrom langflow.io import MessageTextInput, Output\r\nfrom langflow.schema import Data\r\nimport json\r\nimport os\r\n\r\nclass SaveConfigComponent(Component):\r\n    display_name = \"Save Search Configuration\"\r\n    description = \"Save search configuration parameters including URL, temporal resolution, date range, MIP, experiment, variable, and user query to a JSON file\"\r\n    icon = \"save\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"url\",\r\n            display_name=\"URL\",\r\n            info=\"The URL to save in the JSON file\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"temporal_resolution\",\r\n            display_name=\"Temporal Resolution\",\r\n            info=\"The temporal resolution of the data\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"date_range\",\r\n            display_name=\"Date Range\",\r\n            info=\"The date range for the data\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"mip\",\r\n            display_name=\"MIP\",\r\n            info=\"The MIP (Model Intercomparison Project) identifier\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"experiment\",\r\n            display_name=\"Experiment\",\r\n            info=\"The experiment name or identifier\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"variable\",\r\n            display_name=\"Variable\",\r\n            info=\"The variable name or identifier\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"user_query\",\r\n            display_name=\"User Query\",\r\n            info=\"The original user query\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"file_name\",\r\n            display_name=\"File Name\",\r\n            info=\"The name of the JSON file to save (without .json extension)\",\r\n            advanced=True,\r\n            value=\"search_config\"\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(name=\"saved_data\", display_name=\"Saved Data\", method=\"save_config\"),\r\n    ]\r\n\r\n    def save_config(self) -> Data:\r\n        try:\r\n            # Validate required fields\r\n            if not self.url:\r\n                url = \"No Match\"\r\n            else:\r\n                url = self.url\r\n            # Prepare the data dictionary\r\n            data = {\r\n                \"url\": url,\r\n                \"temporal_resolution\": self.temporal_resolution,\r\n                \"date_range\": self.date_range,\r\n                \"mip\": self.mip,\r\n                \"experiment\": self.experiment,\r\n                \"variable\": self.variable,\r\n                \"user_query\": self.user_query,\r\n                \"run_id\": self.graph.run_id,\r\n                \"session_id\": self.graph.session_id\r\n            }\r\n\r\n            # Clean the data dictionary by removing None values\r\n            data = {k: v for k, v in data.items() if v is not None}\r\n\r\n            # Prepare file name\r\n            file_name = f\"{self.file_name}.json\" if self.file_name else \"search_config.json\"\r\n\r\n            # Save to JSON file\r\n            with open(file_name, 'w') as json_file:\r\n                json.dump(data, json_file, indent=2)\r\n\r\n            self.log(f\"Configuration saved to {file_name}\")\r\n            \r\n            return Data(data=data)\r\n\r\n        except Exception as e:\r\n            error_message = f\"An error occurred while saving the configuration: {str(e)}\"\r\n            self.log(error_message)\r\n            self.status = error_message\r\n            return Data(data={\"error\": error_message})"
              },
              "date_range": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Date Range",
                "dynamic": false,
                "info": "The date range for the data",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "date_range",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "experiment": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Experiment",
                "dynamic": false,
                "info": "The experiment name or identifier",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "experiment",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "file_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "File Name",
                "dynamic": false,
                "info": "The name of the JSON file to save (without .json extension)",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "file_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "url_data"
              },
              "mip": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "MIP",
                "dynamic": false,
                "info": "The MIP (Model Intercomparison Project) identifier",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "mip",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temporal_resolution": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Temporal Resolution",
                "dynamic": false,
                "info": "The temporal resolution of the data",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "temporal_resolution",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "url": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "URL",
                "dynamic": false,
                "info": "The URL to save in the JSON file",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "url",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "user_query": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "User Query",
                "dynamic": false,
                "info": "The original user query",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "user_query",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "variable": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Variable",
                "dynamic": false,
                "info": "The variable name or identifier",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "variable",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "CustomComponent"
        },
        "dragging": false,
        "height": 808,
        "id": "CustomComponent-qUYAm",
        "measured": {
          "height": 808,
          "width": 320
        },
        "position": {
          "x": 7874.958115072654,
          "y": -421.95751106592076
        },
        "positionAbsolute": {
          "x": 7848.567957355622,
          "y": -408.7624322074041
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "StructuredOutputComponent-qkVXR",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "category": "helpers",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Transforms LLM responses into **structured data formats**. Ideal for extracting specific information or creating consistent outputs.",
            "display_name": "Structured Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "llm",
              "input_value",
              "schema_name",
              "output_schema",
              "multiple"
            ],
            "frozen": false,
            "icon": "braces",
            "key": "StructuredOutputComponent",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Structured Output",
                "hidden": false,
                "method": "build_structured_output",
                "name": "structured_output",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.575901449065324,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import cast\n\nfrom pydantic import BaseModel, Field, create_model\n\nfrom langflow.base.models.chat_result import get_chat_result\nfrom langflow.custom import Component\nfrom langflow.field_typing.constants import LanguageModel\nfrom langflow.helpers.base_model import build_model_from_schema\nfrom langflow.io import BoolInput, HandleInput, MessageTextInput, Output, StrInput, TableInput\nfrom langflow.schema.data import Data\n\n\nclass StructuredOutputComponent(Component):\n    display_name = \"Structured Output\"\n    description = (\n        \"Transforms LLM responses into **structured data formats**. Ideal for extracting specific information \"\n        \"or creating consistent outputs.\"\n    )\n    icon = \"braces\"\n\n    inputs = [\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            info=\"The language model to use to generate the structured output.\",\n            input_types=[\"LanguageModel\"],\n        ),\n        MessageTextInput(name=\"input_value\", display_name=\"Input message\"),\n        StrInput(\n            name=\"schema_name\",\n            display_name=\"Schema Name\",\n            info=\"Provide a name for the output data schema.\",\n        ),\n        TableInput(\n            name=\"output_schema\",\n            display_name=\"Output Schema\",\n            info=\"Define the structure and data types for the model's output.\",\n            table_schema=[\n                {\n                    \"name\": \"name\",\n                    \"display_name\": \"Name\",\n                    \"type\": \"str\",\n                    \"description\": \"Specify the name of the output field.\",\n                },\n                {\n                    \"name\": \"description\",\n                    \"display_name\": \"Description\",\n                    \"type\": \"str\",\n                    \"description\": \"Describe the purpose of the output field.\",\n                },\n                {\n                    \"name\": \"type\",\n                    \"display_name\": \"Type\",\n                    \"type\": \"str\",\n                    \"description\": (\n                        \"Indicate the data type of the output field \" \"(e.g., str, int, float, bool, list, dict).\"\n                    ),\n                    \"default\": \"text\",\n                },\n                {\n                    \"name\": \"multiple\",\n                    \"display_name\": \"Multiple\",\n                    \"type\": \"boolean\",\n                    \"description\": \"Set to True if this output field should be a list of the specified type.\",\n                    \"default\": \"False\",\n                },\n            ],\n        ),\n        BoolInput(\n            name=\"multiple\",\n            display_name=\"Generate Multiple\",\n            info=\"Set to True if the model should generate a list of outputs instead of a single output.\",\n        ),\n    ]\n\n    outputs = [\n        Output(name=\"structured_output\", display_name=\"Structured Output\", method=\"build_structured_output\"),\n    ]\n\n    def build_structured_output(self) -> Data:\n        if not hasattr(self.llm, \"with_structured_output\"):\n            msg = \"Language model does not support structured output.\"\n            raise TypeError(msg)\n        if not self.output_schema:\n            msg = \"Output schema cannot be empty\"\n            raise ValueError(msg)\n\n        _output_model = build_model_from_schema(self.output_schema)\n        if self.multiple:\n            output_model = create_model(\n                self.schema_name,\n                objects=(list[_output_model], Field(description=f\"A list of {self.schema_name}.\")),  # type: ignore[valid-type]\n            )\n        else:\n            output_model = _output_model\n        try:\n            llm_with_structured_output = cast(LanguageModel, self.llm).with_structured_output(schema=output_model)  # type: ignore[valid-type, attr-defined]\n\n        except NotImplementedError as exc:\n            msg = f\"{self.llm.__class__.__name__} does not support structured output.\"\n            raise TypeError(msg) from exc\n        config_dict = {\n            \"run_name\": self.display_name,\n            \"project_name\": self.get_project_name(),\n            \"callbacks\": self.get_langchain_callbacks(),\n        }\n        output = get_chat_result(runnable=llm_with_structured_output, input_value=self.input_value, config=config_dict)\n        if isinstance(output, BaseModel):\n            output_dict = output.model_dump()\n        else:\n            msg = f\"Output should be a Pydantic BaseModel, got {type(output)} ({output})\"\n            raise TypeError(msg)\n        return Data(data=output_dict)\n"
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input message",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "llm": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "The language model to use to generate the structured output.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "name": "llm",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "multiple": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Generate Multiple",
                "dynamic": false,
                "info": "Set to True if the model should generate a list of outputs instead of a single output.",
                "list": false,
                "name": "multiple",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "output_schema": {
                "_input_type": "TableInput",
                "advanced": false,
                "display_name": "Output Schema",
                "dynamic": false,
                "info": "Define the structure and data types for the model's output.",
                "is_list": true,
                "name": "output_schema",
                "placeholder": "",
                "required": false,
                "show": true,
                "table_schema": {
                  "columns": [
                    {
                      "description": "Specify the name of the output field.",
                      "display_name": "Name",
                      "filterable": true,
                      "formatter": "text",
                      "name": "name",
                      "sortable": true,
                      "type": "text"
                    },
                    {
                      "description": "Describe the purpose of the output field.",
                      "display_name": "Description",
                      "filterable": true,
                      "formatter": "text",
                      "name": "description",
                      "sortable": true,
                      "type": "text"
                    },
                    {
                      "default": "text",
                      "description": "Indicate the data type of the output field (e.g., str, int, float, bool, list, dict).",
                      "display_name": "Type",
                      "filterable": true,
                      "formatter": "text",
                      "name": "type",
                      "sortable": true,
                      "type": "text"
                    },
                    {
                      "default": "False",
                      "description": "Set to True if this output field should be a list of the specified type.",
                      "display_name": "Multiple",
                      "filterable": true,
                      "formatter": "text",
                      "name": "multiple",
                      "sortable": true,
                      "type": "boolean"
                    }
                  ]
                },
                "title_case": false,
                "trace_as_metadata": true,
                "type": "table",
                "value": [
                  {
                    "description": "The Overall sentiment the user provided on the feedback",
                    "multiple": "False",
                    "name": "search_result_sentiment",
                    "type": "text"
                  },
                  {
                    "description": "Sentiment for Variable Selection",
                    "multiple": "False",
                    "name": "variable_sentiment",
                    "type": "text"
                  },
                  {
                    "description": "Sentiment for Experiment Selection",
                    "multiple": "False",
                    "name": "experiment_sentiment",
                    "type": "text"
                  },
                  {
                    "description": "Sentiment for MIP Selection",
                    "multiple": "False",
                    "name": "mip_sentiment",
                    "type": "text"
                  },
                  {
                    "description": "Sentiment for Date Range Selection",
                    "multiple": "False",
                    "name": "date_range_sentiment",
                    "type": "text"
                  },
                  {
                    "description": "Sentiment for Temporal Resolution Selection",
                    "multiple": "False",
                    "name": "temporal_resolution_sentiment",
                    "type": "text"
                  },
                  {
                    "description": "A description containing any extra feedback from the user",
                    "multiple": "False",
                    "name": "extra_feedback",
                    "type": "text"
                  },
                  {
                    "description": "Sentiment for URL Selection",
                    "multiple": "False",
                    "name": "url_sentiment",
                    "type": "text"
                  },
                  {
                    "description": "Feedback on the result for CMIP Search system ",
                    "multiple": "False",
                    "name": "search_result_feedback",
                    "type": "text"
                  }
                ]
              },
              "schema_name": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Schema Name",
                "dynamic": false,
                "info": "Provide a name for the output data schema.",
                "list": false,
                "load_from_db": false,
                "name": "schema_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "user_feedback"
              }
            },
            "tool_mode": false
          },
          "type": "StructuredOutputComponent"
        },
        "dragging": false,
        "height": 538,
        "id": "StructuredOutputComponent-qkVXR",
        "measured": {
          "height": 538,
          "width": 320
        },
        "position": {
          "x": 2624.815772367211,
          "y": 2178.654695083162
        },
        "positionAbsolute": {
          "x": 2944.815772367211,
          "y": 658.6546950831621
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Generates text using OpenAI LLMs.",
          "display_name": "OpenAI",
          "id": "OpenAIModel-4cK1Z",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "hidden": false,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": [
                  "api_key"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import (\n    OPENAI_MODEL_NAMES,\n    OPENAI_REASONING_MODEL_NAMES,\n)\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\nfrom langflow.logging import logger\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[1],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        parameters = {\n            \"api_key\": SecretStr(self.api_key).get_secret_value() if self.api_key else None,\n            \"model_name\": self.model_name,\n            \"max_tokens\": self.max_tokens or None,\n            \"model_kwargs\": self.model_kwargs or {},\n            \"base_url\": self.openai_api_base or \"https://api.openai.com/v1\",\n            \"seed\": self.seed,\n            \"max_retries\": self.max_retries,\n            \"timeout\": self.timeout,\n            \"temperature\": self.temperature if self.temperature is not None else 0.1,\n        }\n\n        logger.info(f\"Model name: {self.model_name}\")\n        if self.model_name in OPENAI_REASONING_MODEL_NAMES:\n            logger.info(\"Getting reasoning model parameters\")\n            parameters.pop(\"temperature\")\n            parameters.pop(\"seed\")\n        output = ChatOpenAI(**parameters)\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_REASONING_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = False\n            build_config[\"seed\"][\"show\"] = False\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = True\n            build_config[\"seed\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4.5-preview",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "o1"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4o-mini"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              }
            },
            "tool_mode": false
          },
          "type": "OpenAIModel"
        },
        "dragging": false,
        "height": 366,
        "id": "OpenAIModel-4cK1Z",
        "measured": {
          "height": 366,
          "width": 320
        },
        "position": {
          "x": 2234.0029115001016,
          "y": 1952.8283899428855
        },
        "positionAbsolute": {
          "x": 2536.7724366090497,
          "y": 570.6721890712987
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Create a prompt template with dynamic variables.",
          "display_name": "Prompt",
          "id": "Prompt-xcvV3",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "search_config"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "icon": "prompts",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "hidden": false,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "search_config": {
                "advanced": false,
                "display_name": "search_config",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "search_config",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "<Instructions>\nYou are analyzing feedback for a CMIP dataset search system. The search configurations and the user's feedback are provided below. Your task is to classify the sentiment (positive, negative, or neutral) for each configuration and summarize all reasoning or additional comments into an \"Extra Feedback\" section.\n\n<SearchConfig>\n{search_config}\n</SearchConfig>\n\nSteps to follow:\n1. For each configuration (MIP, Experiment, Variable, Date Range, Temporal Resolution, Selected URL):\n   - If the user comments on the configuration, classify the sentiment as **positive**, **negative**, or **neutral**.\n   - If no feedback is provided for the configuration, classify it as **neutral**.\n2. Summarize any reasoning, specific comments, or suggestions from the user into the \"Extra Feedback\" section.\n3. Determine the overall sentiment:\n   - If most configurations are positive, classify the overall sentiment as **positive**.\n   - If most configurations are negative, classify the overall sentiment as **negative**.\n   - If feedback is mixed or mostly neutral, classify the overall sentiment as **neutral**.\n\nYour response should be structured as follows:\n<analysis>\n**MIP**: [Positive/Negative/Neutral]  \n**Experiment**: [Positive/Negative/Neutral]  \n**Variable**: [Positive/Negative/Neutral]  \n**Date Range**: [Positive/Negative/Neutral]  \n**Temporal Resolution**: [Positive/Negative/Neutral]  \n**Selected URL**: [Positive/Negative/Neutral]  \n\n**Overall Sentiment**: [Positive/Negative/Neutral]  \n\n**Extra Feedback**: [Summarize all reasoning, detailed comments, or suggestions here. If none provided, write \"None provided.\"]\n</analysis>\n\nOnly include the above analysis and summary in your response. Do not include any commentary or conversational elements outside of this structure. This is specifically for analyzing CMIP dataset search feedback.\n</Instructions>\n\n\nHere is the user's feedback:"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "Prompt"
        },
        "dragging": false,
        "height": 343,
        "id": "Prompt-xcvV3",
        "measured": {
          "height": 343,
          "width": 320
        },
        "position": {
          "x": 1811.4392185281686,
          "y": 2235.452038691765
        },
        "positionAbsolute": {
          "x": 2131.4392185281686,
          "y": 715.4520386917652
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Convert Data objects into Messages using any {field_name} from input data.",
          "display_name": "Data to Message",
          "id": "ParseData-N0nOq",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "display_name": "Data to Message",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "legacy": true,
            "lf_version": "1.4.1",
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "parse_data",
                "name": "text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "hidden": null,
                "method": "parse_data_as_list",
                "name": "data_list",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User Query: {user_query} \nMIP: {mip} \nExperiment: {experiment}\nVariable: {variable}\nDate Range: {date_range} \nTemporal Resolution: {temporal_resolution} \nSelected URL: {url}"
              }
            },
            "tool_mode": false
          },
          "type": "ParseData"
        },
        "dragging": false,
        "height": 299,
        "id": "ParseData-N0nOq",
        "measured": {
          "height": 299,
          "width": 320
        },
        "position": {
          "x": 1437.5639942178286,
          "y": 2205.894590236615
        },
        "positionAbsolute": {
          "x": 1757.5639942178286,
          "y": 685.8945902366149
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "CustomComponent-6cLV6",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Receives any Data input and clears the specified JSON configuration file",
            "display_name": "Read or Clear URL from JSON",
            "documentation": "",
            "edited": true,
            "field_order": [
              "trigger_data",
              "file_name"
            ],
            "frozen": false,
            "icon": "trash-2",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Cleared Status",
                "hidden": false,
                "method": "clear_config",
                "name": "cleared_status",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\r\nfrom langflow.io import DataInput, MessageTextInput, Output\r\nfrom langflow.schema import Data\r\nimport json\r\n\r\nclass ClearConfigTriggerComponent(Component):\r\n    display_name = \"Clear Config Trigger\"\r\n    description = \"Receives any Data input and clears the specified JSON configuration file\"\r\n    icon = \"trash-2\"\r\n    \r\n    inputs = [\r\n        DataInput(\r\n            name=\"trigger_data\",\r\n            display_name=\"Trigger Data\",\r\n            info=\"Any Data input that will trigger the clearing operation (content is ignored)\",\r\n        ),\r\n        MessageTextInput(\r\n            name=\"file_name\",\r\n            display_name=\"File Name\",\r\n            info=\"The name of the JSON file to clear (without .json extension)\",\r\n            advanced=True,\r\n            value=\"search_config\"\r\n        ),\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(name=\"cleared_status\", display_name=\"Cleared Status\", method=\"clear_config\"),\r\n    ]\r\n\r\n    def get_empty_config(self):\r\n        return {\r\n            \"url\": \"\",\r\n            \"temporal_resolution\": \"\",\r\n            \"date_range\": \"\",\r\n            \"mip\": \"\",\r\n            \"experiment\": \"\",\r\n            \"variable\": \"\",\r\n            \"user_query\": \"\"\r\n        }\r\n\r\n    def clear_config(self) -> Data:\r\n        try:\r\n            # Add .json extension if not provided\r\n            file_name = f\"{self.file_name}.json\" if self.file_name else \"search_config.json\"\r\n            \r\n            # Clear the file with empty values\r\n            empty_config = self.get_empty_config()\r\n            with open(file_name, 'w') as json_file:\r\n                json.dump(empty_config, json_file, indent=2)\r\n            \r\n            self.log(f\"Configuration file {file_name} has been cleared\")\r\n            self.status = f\"Successfully cleared {file_name}\"\r\n            \r\n            return Data(data={\r\n                \"file_name\": file_name,\r\n                \"status\": \"cleared\",\r\n                \"success\": True\r\n            })\r\n            \r\n        except Exception as e:\r\n            error_message = f\"Error clearing configuration file: {str(e)}\"\r\n            self.log(error_message)\r\n            self.status = error_message\r\n            \r\n            return Data(data={\r\n                \"file_name\": file_name,\r\n                \"status\": \"error\",\r\n                \"success\": False,\r\n                \"error\": error_message\r\n            })"
              },
              "file_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "File Name",
                "dynamic": false,
                "info": "The name of the JSON file to clear (without .json extension)",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "file_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "url_data"
              },
              "trigger_data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Trigger Data",
                "dynamic": false,
                "info": "Any Data input that will trigger the clearing operation (content is ignored)",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "name": "trigger_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "CustomComponent"
        },
        "dragging": false,
        "height": 300,
        "id": "CustomComponent-6cLV6",
        "measured": {
          "height": 300,
          "width": 320
        },
        "position": {
          "x": 3007.2576649232615,
          "y": 2334.6815012683637
        },
        "positionAbsolute": {
          "x": 3327.2576649232615,
          "y": 814.6815012683637
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "ChatOutput-OIba3",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Display a chat message in the Playground.",
            "display_name": "Chat Output",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "data_template",
              "background_color",
              "chat_icon",
              "text_color",
              "clean_data"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "method": "message_response",
                "name": "message",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "clean_data": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Basic Clean Data",
                "dynamic": false,
                "info": "Whether to clean the data",
                "list": false,
                "list_add_label": "Add More",
                "name": "clean_data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from collections.abc import Generator\nfrom typing import Any\n\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.schema.message import Message\nfrom langflow.schema.properties import Source\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_AI,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"MessagesSquare\"\n    name = \"ChatOutput\"\n    minimized = True\n\n    inputs = [\n        HandleInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n            input_types=[\"Data\", \"DataFrame\", \"Message\"],\n            required=True,\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"clean_data\",\n            display_name=\"Basic Clean Data\",\n            value=True,\n            info=\"Whether to clean the data\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"message\",\n            method=\"message_response\",\n        ),\n    ]\n\n    def _build_source(self, id_: str | None, display_name: str | None, source: str | None) -> Source:\n        source_dict = {}\n        if id_:\n            source_dict[\"id\"] = id_\n        if display_name:\n            source_dict[\"display_name\"] = display_name\n        if source:\n            # Handle case where source is a ChatOpenAI object\n            if hasattr(source, \"model_name\"):\n                source_dict[\"source\"] = source.model_name\n            elif hasattr(source, \"model\"):\n                source_dict[\"source\"] = str(source.model)\n            else:\n                source_dict[\"source\"] = str(source)\n        return Source(**source_dict)\n\n    async def message_response(self) -> Message:\n        # First convert the input to string if needed\n        text = self.convert_to_string()\n        # Get source properties\n        source, icon, display_name, source_id = self.get_properties_from_source_component()\n        background_color = self.background_color\n        text_color = self.text_color\n        if self.chat_icon:\n            icon = self.chat_icon\n\n        # Create or use existing Message object\n        if isinstance(self.input_value, Message):\n            message = self.input_value\n            # Update message properties\n            message.text = text\n        else:\n            message = Message(text=text)\n\n        # Set message properties\n        message.sender = self.sender\n        message.sender_name = self.sender_name\n        message.session_id = self.session_id\n        message.flow_id = self.graph.flow_id if hasattr(self, \"graph\") else None\n        message.properties.source = self._build_source(source_id, display_name, source)\n        message.properties.icon = icon\n        message.properties.background_color = background_color\n        message.properties.text_color = text_color\n\n        # Store message if needed\n        if self.session_id and self.should_store_message:\n            stored_message = await self.send_message(message)\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n\n    def _validate_input(self) -> None:\n        \"\"\"Validate the input data and raise ValueError if invalid.\"\"\"\n        if self.input_value is None:\n            msg = \"Input data cannot be None\"\n            raise ValueError(msg)\n        if isinstance(self.input_value, list) and not all(\n            isinstance(item, Message | Data | DataFrame | str) for item in self.input_value\n        ):\n            invalid_types = [\n                type(item).__name__\n                for item in self.input_value\n                if not isinstance(item, Message | Data | DataFrame | str)\n            ]\n            msg = f\"Expected Data or DataFrame or Message or str, got {invalid_types}\"\n            raise TypeError(msg)\n        if not isinstance(\n            self.input_value,\n            Message | Data | DataFrame | str | list | Generator | type(None),\n        ):\n            type_name = type(self.input_value).__name__\n            msg = f\"Expected Data or DataFrame or Message or str, Generator or None, got {type_name}\"\n            raise TypeError(msg)\n\n    def _safe_convert(self, data: Any) -> str:\n        \"\"\"Safely convert input data to string.\"\"\"\n        try:\n            if isinstance(data, str):\n                return data\n            if isinstance(data, Message):\n                return data.get_text()\n            if isinstance(data, Data):\n                if data.get_text() is None:\n                    msg = \"Empty Data object\"\n                    raise ValueError(msg)\n                return data.get_text()\n            if isinstance(data, DataFrame):\n                if self.clean_data:\n                    # Remove empty rows\n                    data = data.dropna(how=\"all\")\n                    # Remove empty lines in each cell\n                    data = data.replace(r\"^\\s*$\", \"\", regex=True)\n                    # Replace multiple newlines with a single newline\n                    data = data.replace(r\"\\n+\", \"\\n\", regex=True)\n\n                # Replace pipe characters to avoid markdown table issues\n                processed_data = data.replace(r\"\\|\", r\"\\\\|\", regex=True)\n\n                processed_data = processed_data.map(\n                    lambda x: str(x).replace(\"\\n\", \"<br/>\") if isinstance(x, str) else x\n                )\n\n                return processed_data.to_markdown(index=False)\n            return str(data)\n        except (ValueError, TypeError, AttributeError) as e:\n            msg = f\"Error converting data: {e!s}\"\n            raise ValueError(msg) from e\n\n    def convert_to_string(self) -> str | Generator[Any, None, None]:\n        \"\"\"Convert input data to string with proper error handling.\"\"\"\n        self._validate_input()\n        if isinstance(self.input_value, list):\n            return \"\\n\".join([self._safe_convert(item) for item in self.input_value])\n        if isinstance(self.input_value, Generator):\n            return self.input_value\n        return self._safe_convert(self.input_value)\n"
              },
              "data_template": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Data Template",
                "dynamic": false,
                "info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "data_template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{text}"
              },
              "input_value": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Message to be passed as output.",
                "input_types": [
                  "Data",
                  "DataFrame",
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Machine"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "AI"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "ChatOutput"
        },
        "dragging": false,
        "height": 232,
        "id": "ChatOutput-OIba3",
        "measured": {
          "height": 232,
          "width": 320
        },
        "position": {
          "x": 4106.523488687803,
          "y": 2481.0325344311314
        },
        "positionAbsolute": {
          "x": 4426.523488687803,
          "y": 961.0325344311311
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "OpenAIModel-YQJsh",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "hidden": true,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": [
                  "api_key"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import (\n    OPENAI_MODEL_NAMES,\n    OPENAI_REASONING_MODEL_NAMES,\n)\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\nfrom langflow.logging import logger\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[1],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        parameters = {\n            \"api_key\": SecretStr(self.api_key).get_secret_value() if self.api_key else None,\n            \"model_name\": self.model_name,\n            \"max_tokens\": self.max_tokens or None,\n            \"model_kwargs\": self.model_kwargs or {},\n            \"base_url\": self.openai_api_base or \"https://api.openai.com/v1\",\n            \"seed\": self.seed,\n            \"max_retries\": self.max_retries,\n            \"timeout\": self.timeout,\n            \"temperature\": self.temperature if self.temperature is not None else 0.1,\n        }\n\n        logger.info(f\"Model name: {self.model_name}\")\n        if self.model_name in OPENAI_REASONING_MODEL_NAMES:\n            logger.info(\"Getting reasoning model parameters\")\n            parameters.pop(\"temperature\")\n            parameters.pop(\"seed\")\n        output = ChatOpenAI(**parameters)\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_REASONING_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = False\n            build_config[\"seed\"][\"show\"] = False\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = True\n            build_config[\"seed\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "load_from_db": false,
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4.5-preview",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "o1"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4o-mini"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              }
            },
            "tool_mode": false
          },
          "type": "OpenAIModel"
        },
        "dragging": false,
        "height": 318,
        "id": "OpenAIModel-YQJsh",
        "measured": {
          "height": 318,
          "width": 320
        },
        "position": {
          "x": 3735.277214312021,
          "y": 2359.260784020286
        },
        "positionAbsolute": {
          "x": 4055.277214312021,
          "y": 839.2607840202859
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Convert Data objects into Messages using any {field_name} from input data.",
          "display_name": "Data to Message",
          "id": "ParseData-7GGUs",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "display_name": "Data to Message",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "legacy": true,
            "lf_version": "1.4.1",
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "parse_data",
                "name": "text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "hidden": null,
                "method": "parse_data_as_list",
                "name": "data_list",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "The user has provided feedback on the system's performance. \n\nYour task is to acknowledge the feedback, thank the user, and let them know that the system is ready to receive a new search query for CMIP datasets. \n\nDo not include any additional comments or engage in further conversation."
              }
            },
            "tool_mode": false
          },
          "type": "ParseData"
        },
        "dragging": false,
        "height": 299,
        "id": "ParseData-7GGUs",
        "measured": {
          "height": 299,
          "width": 320
        },
        "position": {
          "x": 3371.7220403030774,
          "y": 2350.9406450199954
        },
        "positionAbsolute": {
          "x": 3691.7220403030774,
          "y": 830.9406450199953
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "CustomComponent-MD44N",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Save search configuration to Supabase database with unique ID and timestamp",
            "display_name": "Save Search Configuration",
            "documentation": "",
            "edited": true,
            "field_order": [
              "supabase_url",
              "supabase_key",
              "table_name",
              "config_data"
            ],
            "frozen": false,
            "icon": "Supabase",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Saved Record",
                "method": "save_config",
                "name": "saved_record",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Dict\r\nfrom supabase import create_client, Client\r\nfrom langflow.custom import Component\r\nfrom langflow.io import SecretStrInput, MessageTextInput, DataInput, Output\r\nfrom langflow.schema import Data\r\nfrom loguru import logger\r\nfrom datetime import datetime\r\nimport uuid\r\n\r\nclass SaveConfigToDBComponent(Component):\r\n    display_name = \"Supabase Save Configuration\"\r\n    description = \"Save search configuration to Supabase database with unique ID and timestamp\"\r\n    icon = \"Supabase\"\r\n    \r\n    inputs = [\r\n        SecretStrInput(\r\n            name=\"supabase_url\",\r\n            display_name=\"Supabase URL\",\r\n            info=\"Your Supabase project URL\",\r\n            required=True,\r\n        ),\r\n        SecretStrInput(\r\n            name=\"supabase_key\",\r\n            display_name=\"Supabase Key\",\r\n            info=\"Your Supabase API key\",\r\n            required=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"table_name\",\r\n            display_name=\"Table Name\",\r\n            info=\"The name of the table to save the configuration to\",\r\n            required=True,\r\n        ),\r\n        DataInput(\r\n            name=\"config_data\",\r\n            display_name=\"Configuration Data\",\r\n            info=\"The configuration data to save\",\r\n            required=True,\r\n        ),\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(name=\"saved_record\", display_name=\"Saved Record\", method=\"save_config\"),\r\n    ]\r\n\r\n    def _init_client(self) -> Client:\r\n        \"\"\"Initialize Supabase client\"\"\"\r\n        try:\r\n            return create_client(self.supabase_url, self.supabase_key)\r\n        except Exception as e:\r\n            error_msg = f\"Error initializing Supabase client: {str(e)}\"\r\n            logger.error(error_msg)\r\n            raise ValueError(error_msg)\r\n\r\n    def _prepare_record(self) -> Dict:\r\n        \"\"\"Prepare the record to be saved with additional fields\"\"\"\r\n        # Generate unique ID\r\n        unique_id = str(uuid.uuid4())\r\n        \r\n        # Get current timestamp in ISO format\r\n        timestamp = datetime.utcnow().isoformat()\r\n\r\n        # Start with the original configuration data\r\n        if isinstance(self.config_data, Data):\r\n            record = self.config_data.data\r\n        else:\r\n            record = self.config_data\r\n\r\n        # Add the additional fields\r\n        record.update({\r\n            \"id\": unique_id,\r\n            \"created_at\": timestamp,\r\n        })\r\n\r\n        return record\r\n\r\n    def save_config(self) -> Data:\r\n        \"\"\"Save the configuration to the database\"\"\"\r\n        try:\r\n            client = self._init_client()\r\n            \r\n            # Prepare the record with all required fields\r\n            record = self._prepare_record()\r\n            \r\n            # Insert the record into the database\r\n            response = client.table(self.table_name).insert(record).execute()\r\n            \r\n            if not response.data:\r\n                raise ValueError(\"No data returned from insert operation\")\r\n            \r\n            # Return the saved record\r\n            saved_data = Data(data=response.data[0])\r\n            self.status = saved_data\r\n            \r\n            logger.info(f\"Configuration saved successfully with ID: {record['id']}\")\r\n            return saved_data\r\n            \r\n        except Exception as e:\r\n            error_msg = f\"Error saving configuration: {str(e)}\"\r\n            logger.error(error_msg)\r\n            return Data(data={\"error\": error_msg})"
              },
              "config_data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Configuration Data",
                "dynamic": false,
                "info": "The configuration data to save",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "name": "config_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "supabase_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Supabase Key",
                "dynamic": false,
                "info": "Your Supabase API key",
                "input_types": [
                  "Message"
                ],
                "load_from_db": false,
                "name": "supabase_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "supabase_url": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Supabase URL",
                "dynamic": false,
                "info": "Your Supabase project URL",
                "input_types": [
                  "Message"
                ],
                "load_from_db": false,
                "name": "supabase_url",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "table_name": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Table Name",
                "dynamic": false,
                "info": "The name of the table to save the configuration to",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "table_name",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "search_configs"
              }
            },
            "tool_mode": false
          },
          "type": "CustomComponent"
        },
        "dragging": false,
        "height": 472,
        "id": "CustomComponent-MD44N",
        "measured": {
          "height": 472,
          "width": 320
        },
        "position": {
          "x": 8402.572317693806,
          "y": 20.860264043362406
        },
        "positionAbsolute": {
          "x": 8290.414147396416,
          "y": -272.7302405586324
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Convert Data objects into Messages using any {field_name} from input data.",
          "display_name": "Data to Message",
          "id": "ParseData-8bP1x",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "display_name": "Data to Message",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "legacy": true,
            "lf_version": "1.4.1",
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "parse_data",
                "name": "text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "hidden": null,
                "method": "parse_data_as_list",
                "name": "data_list",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{run_id}"
              }
            },
            "tool_mode": false
          },
          "type": "ParseData"
        },
        "dragging": false,
        "height": 299,
        "id": "ParseData-8bP1x",
        "measured": {
          "height": 299,
          "width": 320
        },
        "position": {
          "x": 2225.1993783093367,
          "y": 2667.9816086809524
        },
        "positionAbsolute": {
          "x": 2545.1993783093367,
          "y": 1147.9816086809524
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "CustomComponent-fDa6H",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Save search result sentiment feedback and link it to the search configuration",
            "display_name": "Supabase Save Sentiment Feedback",
            "documentation": "",
            "edited": true,
            "field_order": [
              "supabase_url",
              "supabase_key",
              "sentiment_data",
              "search_run_id"
            ],
            "frozen": false,
            "icon": "Supabase",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "output_types": [],
            "outputs": [
              {
                "cache": true,
                "display_name": "Saved Feedback",
                "method": "save_sentiment",
                "name": "saved_feedback",
                "selected": "Data",
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Dict\r\nfrom supabase import create_client, Client\r\nfrom langflow.custom import Component\r\nfrom langflow.io import SecretStrInput, DataInput, Output, MessageTextInput\r\nfrom langflow.schema import Data\r\nfrom loguru import logger\r\nfrom datetime import datetime\r\nimport uuid\r\n\r\nclass SaveSentimentFeedbackComponent(Component):\r\n    display_name = \"Supabase Save Sentiment Feedback\"\r\n    description = \"Save search result sentiment feedback and link it to the search configuration\"\r\n    icon = \"Supabase\"\r\n    \r\n    inputs = [\r\n        SecretStrInput(\r\n            name=\"supabase_url\",\r\n            display_name=\"Supabase URL\",\r\n            info=\"Your Supabase project URL\",\r\n            required=True,\r\n        ),\r\n        SecretStrInput(\r\n            name=\"supabase_key\",\r\n            display_name=\"Supabase Key\",\r\n            info=\"Your Supabase API key\",\r\n            required=True,\r\n        ),\r\n        DataInput(\r\n            name=\"sentiment_data\",\r\n            display_name=\"Sentiment Data\",\r\n            info=\"The sentiment feedback data\",\r\n            required=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"search_run_id\",\r\n            display_name=\"Search Run ID\",\r\n            info=\"The ID of the search configuration to link to\",\r\n            required=True,\r\n        )\r\n    ]\r\n    \r\n    outputs = [\r\n        Output(name=\"saved_feedback\", display_name=\"Saved Feedback\", method=\"save_sentiment\"),\r\n    ]\r\n\r\n    def _init_client(self) -> Client:\r\n        \"\"\"Initialize Supabase client\"\"\"\r\n        try:\r\n            return create_client(self.supabase_url, self.supabase_key)\r\n        except Exception as e:\r\n            error_msg = f\"Error initializing Supabase client: {str(e)}\"\r\n            logger.error(error_msg)\r\n            raise ValueError(error_msg)\r\n\r\n    def _prepare_sentiment_record(self) -> Dict:\r\n        \"\"\"Prepare the sentiment feedback record\"\"\"\r\n        # Generate unique ID\r\n        feedback_id = str(uuid.uuid4())\r\n        timestamp = datetime.utcnow().isoformat()\r\n\r\n        if not isinstance(self.sentiment_data, Data):\r\n            raise ValueError(\"Sentiment data must be a Data object\")\r\n\r\n        sentiment_dict = self.sentiment_data.data\r\n        \r\n        # Create the feedback record\r\n        record = {\r\n            \"id\": feedback_id,\r\n            \"created_at\": timestamp,\r\n            \"search_config_run_id\": self.search_run_id,\r\n            \r\n            # Sentiment fields\r\n            \"search_result_sentiment\": sentiment_dict.get(\"search_result_sentiment\"),\r\n            \"variable_sentiment\": sentiment_dict.get(\"variable_sentiment\"),\r\n            \"experiment_sentiment\": sentiment_dict.get(\"experiment_sentiment\"),\r\n            \"mip_sentiment\": sentiment_dict.get(\"mip_sentiment\"),\r\n            \"date_range_sentiment\": sentiment_dict.get(\"date_range_sentiment\"),\r\n            \"temporal_resolution_sentiment\": sentiment_dict.get(\"temporal_resolution_sentiment\"),\r\n            \"url_sentiment\": sentiment_dict.get(\"url_sentiment\"),\r\n            \"extra_feedback\": sentiment_dict.get(\"extra_feedback\")\r\n        }\r\n\r\n        return record\r\n\r\n    def save_sentiment(self) -> Data:\r\n        \"\"\"Save the sentiment feedback to the database\"\"\"\r\n        try:\r\n            client = self._init_client()\r\n            \r\n            # First verify the search_run_id exists\r\n            verify = client.table(\"search_configs\") \\\r\n                          .select(\"id\") \\\r\n                          .eq(\"run_id\", self.search_run_id) \\\r\n                          .execute()\r\n            \r\n            if not verify.data:\r\n                raise ValueError(f\"No search configuration found with run_id: {self.search_run_id}\")\r\n            \r\n            # Prepare and save the sentiment record\r\n            record = self._prepare_sentiment_record()\r\n            \r\n            # Insert the record into the sentiment_feedback table\r\n            response = client.table(\"sentiment_feedback\").insert(record).execute()\r\n            \r\n            if not response.data:\r\n                raise ValueError(\"No data returned from insert operation\")\r\n            \r\n            # Return the saved record\r\n            saved_data = Data(data=response.data[0])\r\n            self.status = saved_data\r\n            \r\n            logger.info(f\"Sentiment feedback saved successfully with ID: {record['id']}\")\r\n            return saved_data\r\n            \r\n        except Exception as e:\r\n            error_msg = f\"Error saving sentiment feedback: {str(e)}\"\r\n            logger.error(error_msg)\r\n            return Data(data={\r\n                \"error\": error_msg,\r\n                \"status\": \"error\",\r\n                \"success\": False\r\n            })"
              },
              "search_run_id": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Search Run ID",
                "dynamic": false,
                "info": "The ID of the search configuration to link to",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "name": "search_run_id",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sentiment_data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Sentiment Data",
                "dynamic": false,
                "info": "The sentiment feedback data",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "name": "sentiment_data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "supabase_key": {
                "_input_type": "SecretStrInput",
                "advanced": true,
                "display_name": "Supabase Key",
                "dynamic": false,
                "info": "Your Supabase API key",
                "input_types": [
                  "Message"
                ],
                "load_from_db": false,
                "name": "supabase_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "supabase_url": {
                "_input_type": "SecretStrInput",
                "advanced": true,
                "display_name": "Supabase URL",
                "dynamic": false,
                "info": "Your Supabase project URL",
                "input_types": [
                  "Message"
                ],
                "load_from_db": false,
                "name": "supabase_url",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "CustomComponent"
        },
        "dragging": false,
        "height": 300,
        "id": "CustomComponent-fDa6H",
        "measured": {
          "height": 300,
          "width": 320
        },
        "position": {
          "x": 3004.8757113100205,
          "y": 2723.747914173646
        },
        "positionAbsolute": {
          "x": 3324.8757113100205,
          "y": 1203.7479141736462
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "ParseData-8ShCt",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "display_name": "Data to Message",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "legacy": true,
            "lf_version": "1.4.1",
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "parse_data",
                "name": "text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "hidden": null,
                "method": "parse_data_as_list",
                "name": "data_list",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{message}"
              }
            },
            "tool_mode": false
          },
          "type": "ParseData"
        },
        "dragging": false,
        "height": 299,
        "id": "ParseData-8ShCt",
        "measured": {
          "height": 299,
          "width": 320
        },
        "position": {
          "x": 2182.7901587518872,
          "y": -779.1752901601595
        },
        "positionAbsolute": {
          "x": 2117.4988669157246,
          "y": -1519.1432643033322
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "description": "Convert Data objects into Messages using any {field_name} from input data.",
          "display_name": "Data to Message",
          "id": "ParseData-S98qC",
          "node": {
            "base_classes": [
              "Data",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Convert Data objects into Messages using any {field_name} from input data.",
            "display_name": "Data to Message",
            "documentation": "",
            "edited": false,
            "field_order": [
              "data",
              "template",
              "sep"
            ],
            "frozen": false,
            "icon": "message-square",
            "legacy": true,
            "lf_version": "1.4.1",
            "metadata": {
              "legacy_name": "Parse Data"
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "parse_data",
                "name": "text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Data List",
                "hidden": null,
                "method": "parse_data_as_list",
                "name": "data_list",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom import Component\nfrom langflow.helpers.data import data_to_text, data_to_text_list\nfrom langflow.io import DataInput, MultilineInput, Output, StrInput\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\n\n\nclass ParseDataComponent(Component):\n    display_name = \"Data to Message\"\n    description = \"Convert Data objects into Messages using any {field_name} from input data.\"\n    icon = \"message-square\"\n    name = \"ParseData\"\n    legacy = True\n    metadata = {\n        \"legacy_name\": \"Parse Data\",\n    }\n\n    inputs = [\n        DataInput(\n            name=\"data\",\n            display_name=\"Data\",\n            info=\"The data to convert to text.\",\n            is_list=True,\n            required=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {data} or any other key in the Data.\",\n            value=\"{text}\",\n            required=True,\n        ),\n        StrInput(name=\"sep\", display_name=\"Separator\", advanced=True, value=\"\\n\"),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Message\",\n            name=\"text\",\n            info=\"Data as a single Message, with each input Data separated by Separator\",\n            method=\"parse_data\",\n        ),\n        Output(\n            display_name=\"Data List\",\n            name=\"data_list\",\n            info=\"Data as a list of new Data, each having `text` formatted by Template\",\n            method=\"parse_data_as_list\",\n        ),\n    ]\n\n    def _clean_args(self) -> tuple[list[Data], str, str]:\n        data = self.data if isinstance(self.data, list) else [self.data]\n        template = self.template\n        sep = self.sep\n        return data, template, sep\n\n    def parse_data(self) -> Message:\n        data, template, sep = self._clean_args()\n        result_string = data_to_text(template, data, sep)\n        self.status = result_string\n        return Message(text=result_string)\n\n    def parse_data_as_list(self) -> list[Data]:\n        data, template, _ = self._clean_args()\n        text_list, data_list = data_to_text_list(template, data)\n        for item, text in zip(data_list, text_list, strict=True):\n            item.set_text(text)\n        self.status = data_list\n        return data_list\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "The data to convert to text.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "sep": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "Separator",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sep",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "\n"
              },
              "template": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "The template to use for formatting the data. It can contain the keys {text}, {data} or any other key in the Data.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "template",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "{message}"
              }
            },
            "tool_mode": false
          },
          "type": "ParseData"
        },
        "dragging": false,
        "height": 299,
        "id": "ParseData-S98qC",
        "measured": {
          "height": 299,
          "width": 320
        },
        "position": {
          "x": 1818.3553338277848,
          "y": 1841.2217627400928
        },
        "positionAbsolute": {
          "x": 2126.8683505670833,
          "y": 349.9392208918457
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "Prompt-CaGwo",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": []
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt",
            "documentation": "",
            "edited": false,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "icon": "prompts",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt Message",
                "hidden": false,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "You are assisting in gathering feedback for a CMIP Dataset selector system. The user will provide a query, and the system will generate selections based on the query. \n\nYour task is to present the results of the system's selection and ask for feedback to help improve the system. \n\nDo not attempt to answer the user's query or provide additional information beyond the system's output.\n\nEG: \n\nPlease provide feedback on the following:\n1. **Positive Feedback**: What aspects of the selection are accurate or meet your expectations?\n2. **Negative Feedback**: What aspects of the selection are inaccurate, irrelevant, or do not meet your expectations?\n3. **Neutral Feedback**: Are there any aspects that are acceptable but could be improved?\n4. **Additional Suggestions**: Do you have any other comments or recommendations that could help improve the system's search and selection process?\n\nYour feedback will be used to fine-tune the system and enhance its performance. \n\n\n"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "type": "Prompt"
        },
        "dragging": false,
        "height": 258,
        "id": "Prompt-CaGwo",
        "measured": {
          "height": 258,
          "width": 320
        },
        "position": {
          "x": 8421.515745665716,
          "y": -375.82298519743745
        },
        "positionAbsolute": {
          "x": 8309.357575368325,
          "y": -669.4134897994322
        },
        "selected": false,
        "type": "genericNode",
        "width": 320
      },
      {
        "data": {
          "id": "note-Oo4rd",
          "node": {
            "description": "# User Feedback System",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note"
        },
        "dragging": false,
        "height": 324,
        "id": "note-Oo4rd",
        "measured": {
          "height": 324,
          "width": 600
        },
        "position": {
          "x": 1721.0292122345072,
          "y": 1765.7497887305908
        },
        "positionAbsolute": {
          "x": 2041.0292122345072,
          "y": 245.7497887305908
        },
        "resizing": false,
        "selected": false,
        "style": {
          "height": 324,
          "width": 600
        },
        "type": "noteNode",
        "width": 600
      },
      {
        "data": {
          "id": "note-BPd5V",
          "node": {
            "description": "# Dataset Search System",
            "display_name": "",
            "documentation": "",
            "template": {}
          },
          "type": "note"
        },
        "dragging": false,
        "height": 324,
        "id": "note-BPd5V",
        "measured": {
          "height": 324,
          "width": 600
        },
        "position": {
          "x": 2104.875717919937,
          "y": -864.1805557375855
        },
        "positionAbsolute": {
          "x": 2039.5844260837744,
          "y": -1604.1485298807581
        },
        "resizing": false,
        "selected": false,
        "style": {
          "height": 324,
          "width": 600
        },
        "type": "noteNode",
        "width": 600
      },
      {
        "data": {
          "id": "note-aUSoq",
          "node": {
            "description": "# Save Search Config",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "blue"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 324,
        "id": "note-aUSoq",
        "measured": {
          "height": 324,
          "width": 421
        },
        "position": {
          "x": 7842.0084292551865,
          "y": -480.80259983764756
        },
        "positionAbsolute": {
          "x": 7842.0084292551865,
          "y": -480.80259983764756
        },
        "resizing": false,
        "selected": false,
        "style": {
          "height": 324,
          "width": 421
        },
        "type": "noteNode",
        "width": 421
      },
      {
        "data": {
          "id": "note-XNoNm",
          "node": {
            "description": "## Load System State",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "blue"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 324,
        "id": "note-XNoNm",
        "measured": {
          "height": 324,
          "width": 324
        },
        "position": {
          "x": 729.416426707991,
          "y": -917.4409140647097
        },
        "positionAbsolute": {
          "x": 825.17698253957,
          "y": -771.6237037867004
        },
        "resizing": false,
        "selected": false,
        "type": "noteNode",
        "width": 324
      },
      {
        "data": {
          "id": "OpenAIModel-ajc6r",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "models",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generates text using OpenAI LLMs.",
            "display_name": "OpenAI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_tokens",
              "model_kwargs",
              "json_mode",
              "model_name",
              "openai_api_base",
              "api_key",
              "temperature",
              "seed",
              "max_retries",
              "timeout"
            ],
            "frozen": false,
            "icon": "OpenAI",
            "key": "OpenAIModel",
            "legacy": false,
            "lf_version": "1.4.1",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "hidden": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": [],
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "hidden": null,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": [
                  "api_key"
                ],
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.001,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "OpenAI API Key",
                "dynamic": false,
                "info": "The OpenAI API Key to use for the OpenAI model.",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import (\n    OPENAI_MODEL_NAMES,\n    OPENAI_REASONING_MODEL_NAMES,\n)\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, IntInput, SecretStrInput, SliderInput, StrInput\nfrom langflow.logging import logger\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(\n            name=\"model_kwargs\",\n            display_name=\"Model Kwargs\",\n            advanced=True,\n            info=\"Additional keyword arguments to pass to the model.\",\n        ),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[1],\n            combobox=True,\n            real_time_refresh=True,\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n            required=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            show=True,\n        ),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        IntInput(\n            name=\"max_retries\",\n            display_name=\"Max Retries\",\n            info=\"The maximum number of retries to make when generating.\",\n            advanced=True,\n            value=5,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            info=\"The timeout for requests to OpenAI completion API.\",\n            advanced=True,\n            value=700,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        parameters = {\n            \"api_key\": SecretStr(self.api_key).get_secret_value() if self.api_key else None,\n            \"model_name\": self.model_name,\n            \"max_tokens\": self.max_tokens or None,\n            \"model_kwargs\": self.model_kwargs or {},\n            \"base_url\": self.openai_api_base or \"https://api.openai.com/v1\",\n            \"seed\": self.seed,\n            \"max_retries\": self.max_retries,\n            \"timeout\": self.timeout,\n            \"temperature\": self.temperature if self.temperature is not None else 0.1,\n        }\n\n        logger.info(f\"Model name: {self.model_name}\")\n        if self.model_name in OPENAI_REASONING_MODEL_NAMES:\n            logger.info(\"Getting reasoning model parameters\")\n            parameters.pop(\"temperature\")\n            parameters.pop(\"seed\")\n        output = ChatOpenAI(**parameters)\n        if self.json_mode:\n            output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n\n    def update_build_config(self, build_config: dict, field_value: Any, field_name: str | None = None) -> dict:\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_REASONING_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = False\n            build_config[\"seed\"][\"show\"] = False\n        if field_name in {\"base_url\", \"model_name\", \"api_key\"} and field_value in OPENAI_MODEL_NAMES:\n            build_config[\"temperature\"][\"show\"] = True\n            build_config[\"seed\"][\"show\"] = True\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "json_mode": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "JSON Mode",
                "dynamic": false,
                "info": "If True, it will output JSON regardless of passing a schema.",
                "list": false,
                "list_add_label": "Add More",
                "name": "json_mode",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "max_retries": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Retries",
                "dynamic": false,
                "info": "The maximum number of retries to make when generating.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_retries",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_tokens": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_tokens",
                "placeholder": "",
                "range_spec": {
                  "max": 128000,
                  "min": 0,
                  "step": 0.1,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_kwargs": {
                "_input_type": "DictInput",
                "advanced": true,
                "display_name": "Model Kwargs",
                "dynamic": false,
                "info": "Additional keyword arguments to pass to the model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "model_kwargs",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "dict",
                "value": {}
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "",
                "name": "model_name",
                "options": [
                  "gpt-4o-mini",
                  "gpt-4o",
                  "gpt-4.1",
                  "gpt-4.1-mini",
                  "gpt-4.1-nano",
                  "gpt-4.5-preview",
                  "gpt-4-turbo",
                  "gpt-4-turbo-preview",
                  "gpt-4",
                  "gpt-3.5-turbo",
                  "o1"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gpt-4o-mini"
              },
              "openai_api_base": {
                "_input_type": "StrInput",
                "advanced": true,
                "display_name": "OpenAI API Base",
                "dynamic": false,
                "info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "openai_api_base",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "seed": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Seed",
                "dynamic": false,
                "info": "The seed controls the reproducibility of the job.",
                "list": false,
                "list_add_label": "Add More",
                "name": "seed",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 1
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout for requests to OpenAI completion API.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 700
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "OpenAIModel"
        },
        "dragging": false,
        "id": "OpenAIModel-ajc6r",
        "measured": {
          "height": 608,
          "width": 320
        },
        "position": {
          "x": 8844.93949929075,
          "y": -486.4901136508031
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "note-evz3K",
          "node": {
            "description": "#  🔀 System Router",
            "display_name": "",
            "documentation": "",
            "template": {
              "backgroundColor": "transparent"
            }
          },
          "type": "note"
        },
        "dragging": false,
        "height": 406,
        "id": "note-evz3K",
        "measured": {
          "height": 406,
          "width": 324
        },
        "position": {
          "x": 1342.2484909395218,
          "y": -1118.5505983189896
        },
        "resizing": false,
        "selected": false,
        "type": "noteNode",
        "width": 324
      }
    ],
    "viewport": {
      "x": -444.9614850637754,
      "y": 604.551371829126,
      "zoom": 0.3031433190274753
    }
  },
  "description": "Multi-System Climate Selector Pipeline. \n\nYour First query is to select the Dataset. \nYour second query is to provide feedback about the system itself. \n\nThen the system is reset and you can start again.\n",
  "endpoint_name": "nasa-dataset-selector-02-1-2",
  "id": "f8dc7f86-04b0-47e1-90ec-bf99152d2026",
  "is_component": false,
  "last_tested_version": "1.4.1",
  "name": "Dataset Retrieval - v1.0.4",
  "tags": []
}